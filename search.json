[{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"load-packages","dir":"Articles","previous_headings":"Setup","what":"Load Packages","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"","code":"library(ETAS.inlabru) library(ggplot2)  library(rnaturalearth) library(terra) library(sf) library(ggspatial) library(rnaturalearthdata) library(dplyr) library(lubridate)  ## This is just the EPSG equivalent of WGS84 crs_wgs84 <- st_crs('EPSG:4326')"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"load-an-earthquake-catalogue","dir":"Articles","previous_headings":"","what":"Load an earthquake catalogue","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"Earthquake data stored -called earthquake catalogues. Many different catalogues exists region easy way decide one better. , provide HOmogenized instRUmental Seismic (HORUS) catalogue 1960 2020. can downloaded http://horus.bo.ingv./. subset (see data-raw/horus.R subset created) information Horus catalogue can loaded using data reports earthquake time string (time_string), longitude (lon) latitude (lat) epicentre, depth kilometres (depth), moment magnitude (M).","code":"# load HORUS catalogue data(horus, package = \"ETAS.inlabru\")  # transform time string in Date object horus$time_date <- as.POSIXct(   horus$time_string,   format = \"%Y-%m-%dT%H:%M:%OS\" )  head(horus) #>           time_string     lon     lat depth    M           time_date #> 1 1960-01-03T20:19:34 15.3000 39.3000   290 6.34 1960-01-03 20:19:34 #> 2 1960-01-04T09:20:00 13.1667 43.1333     0 3.94 1960-01-04 09:20:00 #> 3 1960-01-06T15:17:34 12.7000 46.4833     4 4.69 1960-01-06 15:17:34 #> 4 1960-01-06T15:20:53 12.7000 46.4667     0 4.14 1960-01-06 15:20:53 #> 5 1960-01-06T15:31:00 12.7500 46.4333     0 3.00 1960-01-06 15:31:00 #> 6 1960-01-06T15:45:00 12.7500 46.4333     0 3.00 1960-01-06 15:45:00  # Set df_cat to be the catalogue we want to analyse and then use this below df_cat <- horus  # Add an integer id to each event df_cat$event_num <- seq.int(nrow(df_cat))  # Generate an sf version of the catalogue where the longitude and latitude are converted to a point object df_cat.sf<- st_as_sf(df_cat,                      coords = c(\"lon\", \"lat\"),                      crs = crs_wgs84)  head(df_cat.sf) #> Simple feature collection with 6 features and 5 fields #> Geometry type: POINT #> Dimension:     XY #> Bounding box:  xmin: 12.7 ymin: 39.3 xmax: 15.3 ymax: 46.4833 #> Geodetic CRS:  WGS 84 #>           time_string depth    M           time_date event_num #> 1 1960-01-03T20:19:34   290 6.34 1960-01-03 20:19:34         1 #> 2 1960-01-04T09:20:00     0 3.94 1960-01-04 09:20:00         2 #> 3 1960-01-06T15:17:34     4 4.69 1960-01-06 15:17:34         3 #> 4 1960-01-06T15:20:53     0 4.14 1960-01-06 15:20:53         4 #> 5 1960-01-06T15:31:00     0 3.00 1960-01-06 15:31:00         5 #> 6 1960-01-06T15:45:00     0 3.00 1960-01-06 15:45:00         6 #>                  geometry #> 1       POINT (15.3 39.3) #> 2 POINT (13.1667 43.1333) #> 3    POINT (12.7 46.4833) #> 4    POINT (12.7 46.4667) #> 5   POINT (12.75 46.4333) #> 6   POINT (12.75 46.4333)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"get-map-and-extract-crs-for-the-map","dir":"Articles","previous_headings":"Load an earthquake catalogue","what":"Get map and extract crs for the map","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"download polygon file national boundary Italy use later notebook.","code":"italy.map <- ne_countries(country = 'Italy', returnclass = \"sf\", scale = 'medium') italy.crs <- crs(italy.map) print(italy.crs) #> [1] \"BOUNDCRS[\\n    SOURCECRS[\\n        GEOGCRS[\\\"unknown\\\",\\n            DATUM[\\\"World Geodetic System 1984\\\",\\n                ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                    LENGTHUNIT[\\\"metre\\\",1]],\\n                ID[\\\"EPSG\\\",6326]],\\n            PRIMEM[\\\"Greenwich\\\",0,\\n                ANGLEUNIT[\\\"degree\\\",0.0174532925199433],\\n                ID[\\\"EPSG\\\",8901]],\\n            CS[ellipsoidal,2],\\n                AXIS[\\\"longitude\\\",east,\\n                    ORDER[1],\\n                    ANGLEUNIT[\\\"degree\\\",0.0174532925199433,\\n                        ID[\\\"EPSG\\\",9122]]],\\n                AXIS[\\\"latitude\\\",north,\\n                    ORDER[2],\\n                    ANGLEUNIT[\\\"degree\\\",0.0174532925199433,\\n                        ID[\\\"EPSG\\\",9122]]]]],\\n    TARGETCRS[\\n        GEOGCRS[\\\"WGS 84\\\",\\n            DATUM[\\\"World Geodetic System 1984\\\",\\n                ELLIPSOID[\\\"WGS 84\\\",6378137,298.257223563,\\n                    LENGTHUNIT[\\\"metre\\\",1]]],\\n            PRIMEM[\\\"Greenwich\\\",0,\\n                ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n            CS[ellipsoidal,2],\\n                AXIS[\\\"geodetic latitude (Lat)\\\",north,\\n                    ORDER[1],\\n                    ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n                AXIS[\\\"geodetic longitude (Lon)\\\",east,\\n                    ORDER[2],\\n                    ANGLEUNIT[\\\"degree\\\",0.0174532925199433]],\\n            ID[\\\"EPSG\\\",4326]]],\\n    ABRIDGEDTRANSFORMATION[\\\"Transformation from unknown to WGS84\\\",\\n        METHOD[\\\"Geocentric translations (geog2D domain)\\\",\\n            ID[\\\"EPSG\\\",9603]],\\n        PARAMETER[\\\"X-axis translation\\\",0,\\n            ID[\\\"EPSG\\\",8605]],\\n        PARAMETER[\\\"Y-axis translation\\\",0,\\n            ID[\\\"EPSG\\\",8606]],\\n        PARAMETER[\\\"Z-axis translation\\\",0,\\n            ID[\\\"EPSG\\\",8607]]]]\"  ggplot() +    geom_sf(data = italy.map) +    theme_bw() +   ggtitle(\"Map of the Italian territorial boundary and coastline\")"},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"histogram-of-event-depths","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Histogram of event depths","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"histogram depth data 1km bins initially looks reasonable except artefact cluster events zero depth.  However, reduce bin width 100m see artefacts data. spikes 0, 5, 10 11km artefacts depth estimation, one cause algorithms may got stuck starting values. magnitude time series shows completeness intermediate deep events improved time.","code":"hist(df_cat$depth, breaks=seq(650,-5,-1), xlim=c(-5,40), main=\"Histogram of depths, 1km bins\", xlab=\"Depth [km]\") hist(df_cat$depth, breaks=seq(650,-5,-0.1), xlim=c(-5,40), main=\"Histogram of depths (100m bins)\", xlab=\"Depth [km]\") ggplot(df_cat, aes(x=time_date, y=depth))  +    geom_point(size = 0.1) +   ylim(620,0) +   ggtitle('Depth timeseries using natural time') #> Warning: Removed 3 rows containing missing values (`geom_point()`)."},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"plot-of-event-magnitudes-using-natural-time","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Plot of event magnitudes using natural time","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"Natural time refers plot event evenly spaced along x-axis. advantage data occurs periods high activity spread , means can see structure data rates high. plot magnitude events y-axis natural time horizontal. observations : 40,000 events magnitude data cluster events \\(M=0\\) likely artefact catalogue generated period time data rounded 1 decimal place producing horizontal banding times, data rounded sensitivity lowest magnitudes varies time can seen changes lowest magnitudes","code":"ggplot(df_cat, aes(x=event_num, y=M))  +    geom_point(size = 0.1) +   ggtitle('Magnitude timeseries using natural time')"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"plot-of-event-magnitudes-using-date-time","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Plot of event magnitudes using date-time","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"present data previous plot, plotted data-time. Clustered events now sit top . get better representaion data density increases towards modern day magnitude incompleteness varyies time.  number events occuring year difficult assess plot, group data year count number events occuring year. plot shows number events recorded year gradually increasing. artefact due gradual increase sensitivity network, seismicity systematically increasing.","code":"ggplot(df_cat, aes(x=time_date, y=M)) +    geom_point(size = 0.1) +   ggtitle(\"Horus catalogue magnitude time series\") #> Warning: Removed 1 rows containing missing values (`geom_point()`). df_cat$Time <- as.Date(df_cat$time_date)   print(\"Extract year\") #> [1] \"Extract year\" # extract the year and convert to numeric format df_cat$Year <- as.numeric(format(df_cat$Time, \"%Y\"))  countEventsInYear <- df_cat %>%   group_by(Year) %>%   summarize(counts = n())  plot(countEventsInYear, type=\"l\", main=\"Annual number of events for whole catalogue\") # Filtered for M>4 ggplot(df_cat[df_cat$M>4,], aes(x=time_date, y=M)) +    geom_point(size = 0.1) +   ggtitle(\"Whole catalogue magnitude timeseries for M>4\") #> Warning: Removed 1 rows containing missing values (`geom_point()`). countEventsInYear <- df_cat[df_cat$M>=4,] %>%   group_by(Year) %>%   summarize(counts = n())  plot(countEventsInYear, type=\"l\", main=\"Annual number of events with M>=4\") abline(h=mean(countEventsInYear), col=2) #> Warning in mean.default(countEventsInYear): argument is not numeric or logical: #> returning NA"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"frequency-magnitude-analysis-for-horus-catalogue","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Frequency-magnitude analysis for Horus catalogue","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"traditional GR plot shows cumulative data (red) also show incremental data (black). personally prefer looking incremental data correlated therefore easier understand Poisson counting errors account uncertainty data. three domains standard GR plot. - low magnitudes always incompleteness due limitations monitoring network - requirement GR good model log-linear portion data slope stable, slope refered b-value - high magnitudes always fluctuations magnitudes due effect counting errors bins low rates","code":"minMag <- 1.5 maxMag <- max(df_cat$M)  mags <- df_cat[df_cat$M>minMag,]$M  tmp <- hist(mags, breaks=seq(minMag-0.05,maxMag+0.1,0.1), plot=FALSE)  N.counts <- length( tmp$counts) tmp$cumulativeCounts <- cumsum(tmp$counts[N.counts:1])[N.counts:1]  m.min <- 4 bin_m.min <- which(tmp$mids==m.min) freq_m.min <- tmp$counts[bin_m.min] b <- 1 x <- tmp$mids y <- freq_m.min * 10^(-b*(x-m.min)) y.cum <- tmp$cumulativeCounts[bin_m.min] * 10^(-b*(x-m.min))  ggplot() +   geom_point( aes(x=tmp$mids, y=tmp$counts) ) +   geom_point( aes(x=tmp$mids, y=tmp$cumulativeCounts) , color='red', pch=\"+\", size=2) +   scale_y_log10() +   ggtitle(paste(\"Frequency-magnitude plot with arbitary GR dist: b =\", b)) +   xlab(\"Magnitude\") +   ylab(\"log10(Frequency)\") +   geom_line(aes(x=x, y=y)) +   geom_line(aes(x=x, y=y.cum), color='red') +   geom_vline( xintercept=m.min, lty=2 ) #> Warning: Transformation introduced infinite values in continuous y-axis"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"b-value-stability-plot-for-the-events-in-the-horus-catalogue","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"b-value stability plot for the events in the Horus catalogue","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"","code":"minMag <- 2 maxMag <- max(df_cat$M, na.rm=TRUE) mags <- df_cat[df_cat$M>=minMag,]$M  x <- seq(minMag,maxMag,0.1)  b.stability.list <- c() b.error.list <- c() m.mean <- c()  b_utsu <- c() b_guttorp <- c() b_elst <- c() delta_b_utsu <- c() b_elst_lower <- c() b_elst_upper <- c()  max.index.x <- length(x)-5  for( i in 1:max.index.x ){   mag.threshold <- x[i]   mags.subset <- mags[mags > mag.threshold]      N <- length(mags.subset)   b_utsu[i] <- 1/( log(10)*(mean(mags.subset)-mag.threshold+0.05))   delta_b_utsu[i] <- log(10)*b_utsu[i]**2 * sqrt( sum((mags.subset - mean(mags.subset))**2)/(N*(N-1)))        b_guttorp[i] = 1/( 2*0.05*log(10))*log((mean(mags.subset)-mag.threshold+2*0.05)/(mean(mags.subset)-mag.threshold))        deltaMags <- diff(mags.subset)   deltaMags_p <- deltaMags[deltaMags>0.1]   N <- length(deltaMags_p)   b_elst[i] <- 1/(2*0.05* log(10)) * log((mean(deltaMags_p))/(mean(deltaMags_p)-0.1))   c = 10**(0.1*b_elst[i])   b_elst_lower[i] <- 1/(0.1 * log(10)) * log((c+sqrt(c/N))/(1+sqrt(c/N)))   b_elst_upper[i] <- 1/(0.1 * log(10)) * log((c-sqrt(c/N))/(1-sqrt(c/N))) }  ggplot() +   geom_line( aes(x=x[1:max.index.x], y=b_utsu) ) +   geom_line( aes(x=x[1:max.index.x], y=b_utsu+delta_b_utsu), color=2, lty=2 ) +   geom_line( aes(x=x[1:max.index.x], y=b_utsu-delta_b_utsu), color=2, lty=2 ) +   geom_line( aes(x=x[1:max.index.x], y=b_guttorp), color=3, lty=1 ) +   xlab(\"Magnitude threshold\") +   ylab(\"b-value estimate\") +   geom_hline(yintercept = 1, lty=3) +   geom_hline(yintercept = 0.85, lty=3) +   ggtitle(\"b-value stability plot for Horus catalogue\")"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"heatmap-of-the-events-in-the-horus-catalogue","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Heatmap of the events in the Horus catalogue","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"","code":"ggplot() +   geom_hex(data = df_cat[df_cat$M>3,], aes(x = lon, y = lat), bins = 50) +   scale_fill_continuous(type = \"viridis\") +   geom_sf(data = italy.map, fill=alpha(\"lightgrey\", 0), color = 'orange', size=0.2) +    ggtitle(\"Density plot for M>3 events\") +   theme_bw()"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"map-of-the-events-in-the-italian-horus-catalogue","dir":"Articles","previous_headings":"Exploratory Data Analysis on the whole of Italy using the Horus catalogue","what":"Map of the events in the Italian Horus catalogue","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"plot location seismicity map. outline Italy territory shown green.","code":"ggplot() +   geom_sf(data = df_cat.sf[df_cat$M>3,], size = 0.05) +   geom_sf(data = italy.map, fill=alpha(\"lightgrey\", 0), color = 'green', linewidth=0.7) +   geom_sf(data = df_cat.sf[df_cat$M>5,], size = 0.5, color='orange') +   geom_sf(data = df_cat.sf[df_cat$M>6,], size = 0.5, color='red') +   ggtitle(\"Map of event locations\") eventDate <- ymd_hms( '2009-04-06 00:00:00' ) endDate <- eventDate + days(400) startDate <- eventDate - days(50) deltaLat <- 2.4 latLims <- c( 42.2,42.5) longLims <- c( 13, 13.75)  ggplot() +    geom_point(data=df_cat[df_cat$M>3,], aes(time_date, lat), size=0.1) +   geom_point(data=df_cat[df_cat$M>5,], aes(time_date, lat), size=1.2, color='orange') +   geom_point(data=df_cat[df_cat$M>6,], aes(time_date, lat), size=1.5, color='red') +   ggtitle(\"Italian latitude-time plot\")  +   geom_rect(aes(xmin = as.POSIXct(startDate), xmax = as.POSIXct(endDate), ymin = latLims[1], ymax = latLims[2]), alpha = 0.4, fill='blue', color='blue') #> Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"analysis-if-the-laquila-sequence","dir":"Articles","previous_headings":"","what":"Analysis if the L’Aquila Sequence","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"focus L Aquila seismic sequence sufficient retain observations specific space-time-magnitude region include sequence interest. L’Aquila sequence, retain events magnitude greater equal \\(2.5\\) happened 2009 longitude \\((10.5, 16)\\) latitude \\((40.5, 45)\\). L’Aquila sequence selected way composed 1024 events. seismic sequence can selected similarly. selection convenient transform time string Date object select rows Horus catalogue verifying conditions. start.date = “2009-04-06 00:00:00 BST” end.date = “2010-01-01 00:00:00 BST” magnitude.completeness = 2.49 min.longitude = 13.00 max.longitude = 13.75 min.latitude = 42.2 max.latitude = 42.5","code":"eventDate <- ymd_hms( '2009-04-06 00:00:00' ) endDate <- eventDate + days(400) startDate <- eventDate - days(50) deltaLat <- 2.4 latLims <- c( 42.2,42.5) longLims <- c( 13, 13.75)  minMAG <- 0  # Subset the main catalogue df_cat.subset <- df_cat[df_cat$M >= minMAG, ] df_cat.subset <- df_cat.subset[ (df_cat.subset$lat>latLims[1]), ] df_cat.subset <- df_cat.subset[ (df_cat.subset$lat<latLims[2]), ] df_cat.subset <- df_cat.subset[ (df_cat.subset$lon>longLims[1]), ] df_cat.subset <- df_cat.subset[ (df_cat.subset$lon<longLims[2]), ]  head(df_cat.subset) #>             time_string     lon     lat depth    M           time_date #> 243 1961-03-25T10:40:00 13.3167 42.4333     0 3.64 1961-03-25 10:40:00 #> 295 1961-10-05T19:59:35 13.0167 42.3500     3 0.00 1961-10-05 19:59:35 #> 302 1961-10-31T00:00:00 13.0167 42.3500    10 3.94 1961-10-31 00:00:00 #> 303 1961-10-31T00:00:00 13.0167 42.3500    10 3.94 1961-10-31 00:00:00 #> 304 1961-10-31T13:37:18 13.0833 42.4167     4 4.64 1961-10-31 13:37:18 #> 305 1961-10-31T13:41:59 13.0833 42.4167     0 4.14 1961-10-31 13:41:59 #>     event_num       Time Year #> 243       243 1961-03-25 1961 #> 295       295 1961-10-05 1961 #> 302       302 1961-10-31 1961 #> 303       303 1961-10-31 1961 #> 304       304 1961-10-31 1961 #> 305       305 1961-10-31 1961"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"plot-of-the-event-magnitude-time-series-laquila","dir":"Articles","previous_headings":"Analysis if the L’Aquila Sequence","what":"Plot of the event magnitude time series: l’Aquila","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"","code":"ggplot() +    geom_point(data=df_cat.subset[df_cat.subset$M>3,], aes(time_date, lat), size=0.1) +   geom_point(data=df_cat.subset[df_cat.subset$M>5,], aes(time_date, lat), size=1.2, color='orange') +   geom_point(data=df_cat.subset[df_cat.subset$M>6,], aes(time_date, lat), size=1.5, color='red') +   ggtitle(\"L'Aquila latitude-time plot\") +   geom_rect(aes(xmin = as.POSIXct(startDate), xmax = as.POSIXct(endDate), ymin = latLims[1], ymax = latLims[2]), alpha = 0.4, fill='blue', color='blue') minMag <- 0 maxMag <- max(df_cat.subset$M, na.rm=TRUE)  mags <- df_cat.subset[df_cat.subset$M>=minMag,]$M  tmp <- hist(mags, breaks=seq(minMag-0.05,maxMag+0.4,0.1), plot=FALSE)  N.counts <- length( tmp$counts) tmp$cumulativeCounts <- cumsum(tmp$counts[N.counts:1])[N.counts:1]  m.min <- 4 bin_m.min <- which(tmp$mids==m.min) freq_m.min <- tmp$counts[bin_m.min] b <- 1. x <- tmp$mids y <- freq_m.min * 10^(-b*(x-m.min)) y.cum <- tmp$cumulativeCounts[bin_m.min] * 10^(-b*(x-m.min))  ggplot() +   geom_point( aes(x=tmp$mids, y=tmp$counts) ) +   geom_point( aes(x=tmp$mids, y=tmp$cumulativeCounts) , color='red', pch=\"+\") +   scale_y_log10() +   ggtitle(paste(\"Frequency-magnitude plot with arbitary GR dist: b =\", b)) +   xlab(\"Magnitude\") +   ylab(\"log10(Frequency)\") +   geom_line(aes(x=x, y=y)) +   geom_line(aes(x=x, y=y.cum), color='red') +   geom_vline( xintercept=m.min, lty=2 ) #> Warning: Transformation introduced infinite values in continuous y-axis #> Transformation introduced infinite values in continuous y-axis"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/EDA_Italy_Horus.html","id":"b-value-stability-plot-laquila","dir":"Articles","previous_headings":"Analysis if the L’Aquila Sequence","what":"b-value stability plot: l’Aquila","title":"1. Exploratory Data Analysis: Italian Earthquake Catalogue - Horus","text":"","code":"minMag <- 0 maxMag <- max(df_cat.subset$M, na.rm=TRUE) mags <- df_cat.subset[df_cat.subset$M>=minMag,]$M  x <- seq(minMag,maxMag,0.1)  b.stability.list <- c() b.error.list <- c() m.mean <- c()  b_utsu <- c() b_guttorp <- c() b_elst <- c() delta_b_utsu <- c() b_elst_lower <- c() b_elst_upper <- c()  max.index.x <- length(x)-5  for( i in 1:max.index.x ){   mag.threshold <- x[i]   mags.subset <- mags[mags > mag.threshold]      N <- length(mags.subset)   b_utsu[i] <- 1/( log(10)*(mean(mags.subset)-mag.threshold+0.05))   delta_b_utsu[i] <- log(10)*b_utsu[i]**2 * sqrt( sum((mags.subset - mean(mags.subset))**2)/(N*(N-1)))        b_guttorp[i] = 1/( 2*0.05*log(10))*log((mean(mags.subset)-mag.threshold+2*0.05)/(mean(mags.subset)-mag.threshold))        deltaMags <- diff(mags.subset)   deltaMags_p <- deltaMags[deltaMags>0.1]   N <- length(deltaMags_p)   b_elst[i] <- 1/(2*0.05* log(10)) * log((mean(deltaMags_p))/(mean(deltaMags_p)-0.1))   c = 10**(0.1*b_elst[i])   b_elst_lower[i] <- 1/(0.1 * log(10)) * log((c+sqrt(c/N))/(1+sqrt(c/N)))   b_elst_upper[i] <- 1/(0.1 * log(10)) * log((c-sqrt(c/N))/(1-sqrt(c/N))) }  ggplot() +   geom_line( aes(x=x[1:max.index.x], y=b_utsu) ) +   geom_line( aes(x=x[1:max.index.x], y=b_utsu+delta_b_utsu), color=2, lty=2 ) +   geom_line( aes(x=x[1:max.index.x], y=b_utsu-delta_b_utsu), color=2, lty=2 ) +   geom_line( aes(x=x[1:max.index.x], y=b_guttorp), color=3, lty=1 ) +   xlab(\"Magnitude threshold\") +   ylab(\"b-value estimate\") +   geom_hline(yintercept = 1, lty=3) +   geom_hline(yintercept = 0.85, lty=3) +   ggtitle(\"b-value stability plot for the l'Aquila catalogue\") #> Warning: Removed 2 rows containing missing values (`geom_line()`). #> Removed 2 rows containing missing values (`geom_line()`)."},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/generateSyntheticCatalogues.html","id":"create-catalogue","dir":"Articles","previous_headings":"","what":"Create catalogue","title":"2a Temporal Model: Generating synthetic temporal ETAS catalogues","text":"define ETAS parameters define model domain specify history generate ETAS sample plot results","code":"mu <- 1070. / 365 K <- 0.089 alpha <- 2.29 c <- 0.011 p <- 1.08  modelledDuration <- 10 # [days]  M0 <- 2  theta_etas <- data.frame(mu = mu, K = K, alpha = alpha, c = c, p = p)  Ht <- data.frame(ts = c(0., 1.5), magnitudes = c(6.7, 7.))  combined.M7.ETAS.cat <-   generate_temporal_ETAS_synthetic(     theta = theta_etas,     beta.p = log(10),     M0 = M0,     T1 = 0,     T2 = modelledDuration,     Ht = Ht,     format = \"df\"   ) combined.M7.ETAS.cat$ID <- seq_len(nrow(combined.M7.ETAS.cat))  ggplot(combined.M7.ETAS.cat) +   geom_point(aes(x = ts, y = magnitudes, color = factor(gen))) +   xlim(0, modelledDuration) +   ggtitle(\"M7 plus background and ETAS\") ggplot(combined.M7.ETAS.cat %>%          mutate(generation = if_else(gen == -1, \"Initial\", \"Child\"))) +   geom_point(aes(x = ts, y = magnitudes, color = generation)) +   xlim(0, modelledDuration) +   ggtitle(\"M7 plus background and ETAS\") ggplot() +   geom_point(data = combined.M7.ETAS.cat, aes(x = ID, y = magnitudes), color = \"red\") #+ #  geom_ma(data = combined.M7.ETAS.cat, aes(x=ID, y=magnitudes), ma_fun = SMA, n = 10)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sampleFromETASpriors.html","id":"sampling-etas-priors","dir":"Articles","previous_headings":"","what":"Sampling ETAS Priors","title":"2b Temporal Model: Presenting samples drawn from the ETAS priors","text":"important check priors broad enough expect model parameterisation lie within . notebook shows draw samples priors present resulting triggering functions.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"multiple-analyses-of-two-catalogues-using-different-initial-values","dir":"Articles","previous_headings":"","what":"Multiple analyses of two catalogues using different initial values","title":"Sensitivity to starting point","text":"inlabru algorithm takes initial guess mode parameters inverting iteratively updates initial guess. potential may bad initial conditions find different solutions runtime differ depending upon solution converges. notebook, explore robustness posteriors two synthetic catalogues true parameters known. catalogues contain 2000 days data. One catalogue contain large event second contains M6.7 event day 1000.","code":"library(ETAS.inlabru)  library(tidyquant) library(gridExtra) library(grid) library(lemon) library(ggplot2) library(ggpubr) library(GGally)  library(inlabru) library(INLA) library(ETAS.inlabru)  # inla.setOption(pardiso.license=\"~/sys/licences/pardiso.lic\")  library(dplyr)  # Increase num.threads if you have more cores on your computer INLA::inla.setOption(num.threads = 2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"define-the-parameters-for-the-synthetic-catalogues-and-starting-values-for-inversion","dir":"Articles","previous_headings":"Multiple analyses of two catalogues using different initial values","what":"Define the parameters for the synthetic catalogues and starting values for inversion","title":"Sensitivity to starting point","text":"","code":"# Parameters we use to generate synthetics, which we will refer to as the 'true' parameters mu <- 0.1 K <- 0.089 alpha <- 2.29 c <- 0.11 p <- 1.08  # Format the true ETAS parameters for code to generate the synthetics theta_etas <- data.frame(mu = mu, K = K, alpha = alpha, c = c, p = p)  # A dataframe containing different starting values for the algorithm startingValues <- data.frame(   mu = c(5., mu),   K = c(1., K),   alpha = c(5., alpha),   c = c(0.3, c),   p = c(1.5, p) ) nRealisations <- length(startingValues$mu)   # Temporal duration of the synthetic catalogue in days modelledDuration <- 1000 # [days]  # The minimum magnitude that will be modelled M0 <- 2.5"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"generate-new-catalogues-and-save-them","dir":"Articles","previous_headings":"Multiple analyses of two catalogues using different initial values","what":"Generate new catalogues and save them","title":"Sensitivity to starting point","text":"vignette use Rmd caching, can save catalogues files explicitly:","code":"############ #### Generate the first catalogue with no large events  samp.etas.list <- generate_temporal_ETAS_synthetic(   theta = theta_etas,   beta.p = log(10), M0 = M0, T1 = 0, T2 = modelledDuration, Ht = NULL )  quiet.ETAS.cat <- bind_rows(samp.etas.list) quiet.ETAS.cat <- quiet.ETAS.cat[order(quiet.ETAS.cat$ts), ] # quiet.ETAS.cat <- na.omit(quiet.ETAS.cat) ############ #### Generate the second catalogue with a M6.7 event on day 1000  Ht <- data.frame(ts = c(500), magnitudes = c(6.7)) # Impose a M6.7 event on day 1000  samp.etas.list <- generate_temporal_ETAS_synthetic(theta = theta_etas, beta.p = log(10), M0 = M0, T1 = 0, T2 = modelledDuration, Ht = Ht)  M6p7.ETAS.cat <- bind_rows(samp.etas.list) M6p7.ETAS.cat <- M6p7.ETAS.cat[order(M6p7.ETAS.cat$ts), ] # save(M6p7.ETAS.cat,file=\"M6p7_ETAS_cat.Rda\") # save(quiet.ETAS.cat,file=\"quiet.ETAS.cat.Rda\")"},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"load-the-catalogues","dir":"Articles","previous_headings":"Present the catalogues","what":"Load the catalogues","title":"Sensitivity to starting point","text":"read saved object files:","code":"# load(\"M6p7_ETAS_cat.Rda\") # load(\"quiet.ETAS.cat.Rda\")"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"plot-properties-of-the-catalogues","dir":"Articles","previous_headings":"Present the catalogues","what":"Plot properties of the catalogues","title":"Sensitivity to starting point","text":"","code":"plots <- list()  plots[[1]] <- ggplot() +   geom_point(data = quiet.ETAS.cat, aes(x = ts, y = magnitudes), size = 0.1, alpha = 0.5) +   xlim(0, modelledDuration) +   ggtitle(paste(\"A.  Unseeded catalog, nEvents =\", length(quiet.ETAS.cat$ts))) +   ylim(2, 7) +   xlab(\"Time [days]\") +   ylab(\"Magnitude\") +   theme_bw()  plots[[2]] <- ggplot() +   geom_point(data = M6p7.ETAS.cat, aes(x = ts, y = magnitudes), size = 0.1, alpha = 0.5) +   xlim(0, modelledDuration) +   ggtitle(paste(\"B.  Catalog seeded with M6.7 event on day 500, nEvents =\", length(M6p7.ETAS.cat$ts))) +   ylim(2, 7) +   xlab(\"Time [days]\") +   ylab(\"Magnitude\") +   theme_bw()   plt <- grid.arrange(plots[[1]], plots[[2]], ncol = 1, nrow = 2) # ggsave(\"initialConditionCats.png\", plt) # ggsave(\"initialConditionCats.pdf\", plt)"},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"analysis-of-quiet-catalogue","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions","what":"Analysis of quiet catalogue","title":"Sensitivity to starting point","text":"","code":"list.output.quietScenario <- list()  for (i in seq_len(nRealisations)) {   if (exists(\"list.input\")) remove(\"list.input\")    # Load a set of parameters that we will need to tweak for this application   fpath <- system.file(\"extdata\", \"user_input_synthetic_noCatalogue.txt\", package = \"ETAS.inlabru\")   list.input <- create_input_list_temporal_noCatalogue(fpath)    ####################   # Tweak the variables loaded from the input file   list.input$M0 <- M0   list.input$time.int <- c(0, modelledDuration)   list.input$T12 <- c(0, modelledDuration)    # Change the starting location, measured on the ETAS scale   list.input$mu.init <- startingValues$mu[i]   list.input$alpha.init <- startingValues$alpha[i]   list.input$K.init <- startingValues$K[i]   list.input$c.init <- startingValues$c[i]   list.input$p.init <- startingValues$p[i]    link.f <- list(     mu = \\(x) gamma_t(x, a_mu, b_mu),     K = \\(x) loggaus_t(x, a_K, b_K),     alpha = \\(x) unif_t(x, a_alpha, b_alpha),     c_ = \\(x) unif_t(x, a_c, b_c),     p = \\(x) unif_t(x, a_p, b_p)   )    # initial value - convert from ETAS scale to internal scale   list.input$th.init <- list(     th.mu = inv_gamma_t(list.input$mu.init, list.input$a_mu, list.input$b_mu),     th.K = inv_loggaus_t(list.input$K.init, list.input$a_K, list.input$b_K),     th.alpha = inv_unif_t(list.input$alpha.init, list.input$a_alpha, list.input$b_alpha),     th.c = inv_unif_t(list.input$c.init, list.input$a_c, list.input$b_c),     th.p = inv_unif_t(list.input$p.init, list.input$a_p, list.input$b_p)   )    # Define options for inlabru   if (is.null(list.input$max_step)) {     list.input$bru.opt.list <- list(       bru_verbose = 0, # type of visual output       bru_max_iter = list.input$max_iter, # maximum number of iterations       # bru_method = list(max_step = 0.5),       bru_initial = list.input$th.init     ) # parameters initial values   } else {     list.input$bru.opt.list <- list(       bru_verbose = 0, # type of visual output       bru_max_iter = list.input$max_iter, # maximum number of iterations       bru_method = list(max_step = list.input$max_step),       bru_initial = list.input$th.init     ) # parameters initial values   }    ## Add out catalogue to the input list   list.input$catalog <- data.frame(     time_diff = quiet.ETAS.cat$ts,     magnitudes = quiet.ETAS.cat$magnitudes   )    ## Add the catalogue formatted for bru   list.input$catalog.bru <- data.frame(     ts = quiet.ETAS.cat$ts,     magnitudes = quiet.ETAS.cat$magnitudes,     idx.p = seq_len(nrow(quiet.ETAS.cat))   )    ## Input list is now formatted   ####################    ## Run the model according to the input list   ETAS.model.fit <- Temporal.ETAS.fit(list.input)    ## Small bit of post processing   list.output.quietScenario[[i]] <- append(list.input, list(model.fit = ETAS.model.fit))   list.output.quietScenario[[i]]$runtime <- sum(list.output.quietScenario[[i]]$model.fit$bru_timings$Time)   list.output.quietScenario[[i]]$nEvents <- length(list.output.quietScenario[[i]]$catalog[, 1]) } #> Start model fitting  #> Start creating grid...  #> Finished creating grid, time  1.19201  #> Finish model fitting  #> Start model fitting  #> Start creating grid...  #> Finished creating grid, time  1.139593  #> Finish model fitting"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"analysis-of-m6-7-catalogue","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions","what":"Analysis of M6.7 catalogue","title":"Sensitivity to starting point","text":"","code":"list.output.M6p7Scenario <- list()  for (i in seq_len(nRealisations)) {   if (exists(\"list.input\")) {     remove(list.input)   }    # Load a set of parameters that we will need to tweak for this application   fpath <- system.file(\"extdata\", \"user_input_synthetic_noCatalogue.txt\", package = \"ETAS.inlabru\")   list.input <- create_input_list_temporal_noCatalogue(fpath)    ####################   # Tweak the variables laoded from the input file   list.input$M0 <- M0   list.input$time.int <- c(0, modelledDuration)   list.input$T12 <- c(0, modelledDuration)    # Change the starting location, measured on the ETAS scale   list.input$mu.init <- startingValues$mu[i]   list.input$alpha.init <- startingValues$alpha[i]   list.input$K.init <- startingValues$K[i]   list.input$c.init <- startingValues$c[i]   list.input$p.init <- startingValues$p[i]    link.f <- list(     mu = \\(x) gamma_t(x, a_mu, b_mu),     K = \\(x) loggaus_t(x, a_K, b_K),     alpha = \\(x) unif_t(x, a_alpha, b_alpha),     c_ = \\(x) unif_t(x, a_c, b_c),     p = \\(x) unif_t(x, a_p, b_p)   )    # initial value - convert from ETAS scale to internal scale   list.input$th.init <- list(     th.mu = inv_gamma_t(list.input$mu.init, list.input$a_mu, list.input$b_mu),     th.K = inv_loggaus_t(list.input$K.init, list.input$a_K, list.input$b_K),     th.alpha = inv_unif_t(list.input$alpha.init, list.input$a_alpha, list.input$b_alpha),     th.c = inv_unif_t(list.input$c.init, list.input$a_c, list.input$b_c),     th.p = inv_unif_t(list.input$p.init, list.input$a_p, list.input$b_p)   )    # Define options for inlabru   if (is.null(list.input$max_step)) {     list.input$bru.opt.list <- list(       bru_verbose = 3, # type of visual output       bru_max_iter = list.input$max_iter, # maximum number of iterations       # bru_method = list(max_step = 0.5),       bru_initial = list.input$th.init     ) # parameters initial values   } else {     list.input$bru.opt.list <- list(       bru_verbose = 3, # type of visual output       bru_max_iter = list.input$max_iter, # maximum number of iterations       bru_method = list(max_step = list.input$max_step),       bru_initial = list.input$th.init     ) # parameters initial values   }    ## Add out catalogue to the input list   list.input$catalog <- data.frame(     time_diff = M6p7.ETAS.cat$ts,     magnitudes = M6p7.ETAS.cat$magnitudes   )    ## Add the catalogue formatted for bru   list.input$catalog.bru <- data.frame(     ts = M6p7.ETAS.cat$ts,     magnitudes = M6p7.ETAS.cat$magnitudes,     idx.p = seq_len(nrow(M6p7.ETAS.cat))   )    ## Input list is now formatted   ####################    ## Run the model according to the input list   ETAS.model.fit <- Temporal.ETAS.fit(list.input)    ## Small bit of post processing   list.output.M6p7Scenario[[i]] <- append(list.input, list(model.fit = ETAS.model.fit))   list.output.M6p7Scenario[[i]]$runtime <- sum(list.output.M6p7Scenario[[i]]$model.fit$bru_timings$Time)   list.output.M6p7Scenario[[i]]$nEvents <- length(list.output.M6p7Scenario[[i]]$catalog[, 1]) } #> Start model fitting  #> Start creating grid...  #> Finished creating grid, time  12.42259 #> iinla: Evaluate component inputs #> iinla: Evaluate component linearisations #> iinla: Evaluate component simplifications #> iinla: Evaluate predictor linearisation #> iinla: Construct inla stack #> iinla: Model initialisation completed #> iinla: Iteration 1 [max:100] #> iinla: Step rescaling: 92.75%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Iteration 2 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 130.6%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 2180% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 3 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 53.76%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 2300% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 4 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 125.5%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 1750% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 5 [max:100] #> iinla: Step rescaling: 61.8%, Contract #> iinla: Step rescaling: 43.89%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 753% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 6 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 127.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 1130% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 7 [max:100] #> iinla: Step rescaling: 61.8%, Contract #> iinla: Step rescaling: 23.61%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 497% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 8 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.9%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 384% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 9 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 113%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 263% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 10 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 109.4%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 293% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 11 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 105%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 230% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 12 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 204% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 13 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 101.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 169% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 14 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.5%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 161% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 15 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.7%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 147% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 16 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.6%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 138% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 17 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.6%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 129% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 18 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.6%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 122% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 19 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.5%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 114% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 20 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.5%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 108% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 21 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.5%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 102% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 22 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.4%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 96.2% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 23 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.4%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 91% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 24 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.4%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 86.2% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 25 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 81.7% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 26 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 77.4% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 27 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 73.5% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 28 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 69.8% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 29 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 66.3% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 30 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.3%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 63% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 31 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 59.9% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 32 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 57% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 33 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 54.2% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 34 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 51.6% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 35 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 49.1% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 36 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 46.8% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 37 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 44.6% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 38 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 42.5% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 39 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 40.5% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 40 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 38.6% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 41 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 36.8% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 42 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 35.1% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 43 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 33.4% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 44 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 31.9% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 45 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 30.4% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 46 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 29% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 47 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 27.7% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 48 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 26.4% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 49 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 25.2% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 50 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 24.1% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 51 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 23% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 52 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 21.9% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 53 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 20.9% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 54 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 20% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 55 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 19.1% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 56 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 18.2% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 57 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 17.4% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 58 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 16.6% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 59 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 15.8% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 60 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.1%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 15.1% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 61 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 14.5% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 62 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 13.8% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 63 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 13.2% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 64 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 12.6% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 65 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 12% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 66 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 11.5% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 67 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 11% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 68 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 10.5% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 69 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 10% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 70 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 9.56% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Convergence criterion met, running final INLA integration with known theta mode. #> iinla: Iteration 71 [max:100] #> Finish model fitting  #> Start model fitting  #> Start creating grid...  #> Finished creating grid, time  12.2833 #> iinla: Evaluate component inputs #> iinla: Evaluate component linearisations #> iinla: Evaluate component simplifications #> iinla: Evaluate predictor linearisation #> iinla: Construct inla stack #> iinla: Model initialisation completed #> iinla: Iteration 1 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 105.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Iteration 2 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 101.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 28.7% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 3 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100.2%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 20.2% of SD, and line search is active [stop if: <10% and line search inactive] #> iinla: Iteration 4 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 17.6% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 5 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 16.2% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 6 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 15.3% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 7 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 14.5% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 8 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 13.7% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 9 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 13% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 10 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 12.4% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 11 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 11.8% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 12 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 11.3% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 13 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 10.8% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 14 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 10.3% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Iteration 15 [max:100] #> iinla: Step rescaling: 162%, Expand #> iinla: Step rescaling: 100%, Overstep #> iinla: Step rescaling: 100%, Optimisation #> iinla: Evaluate component linearisations #> iinla: Evaluate predictor linearisation #> iinla: Max deviation from previous: 9.8% of SD, and line search is inactive [stop if: <10% and line search inactive] #> iinla: Convergence criterion met, running final INLA integration with known theta mode. #> iinla: Iteration 16 [max:100] #> Finish model fitting"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"plot-posteriors-with-corresponding-starting-values","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions > Analysis of M6.7 catalogue","what":"Plot posteriors with corresponding starting values","title":"Sensitivity to starting point","text":"","code":"plots <- list()  trueParas <- data.frame(value = c(mu, K, alpha, c, p), param = c(\"mu\", \"K\", \"alpha\", \"c\", \"p\"))  post.list <- get_posterior_param(input.list = list.output.quietScenario[[1]]) post.df <- post.list[[1]] post.df$id <- 1  for (i in 2:nRealisations) {   post.list <- get_posterior_param(input.list = list.output.quietScenario[[i]])   post.df.tmp <- post.list[[1]]   post.df.tmp$id <- i    post.df <- rbind(post.df, post.df.tmp) }  plots[[1]] <- ggplot(post.df, aes(x = x, y = y, group = id, color = factor(id), lty = factor(id))) +   geom_line() +   # scale_x_discrete(guide = guide_axis(check.overlap = TRUE)) +   facet_wrap(facets = vars(param), scales = \"free\", labeller = label_parsed, nrow = 1) +   geom_vline(aes(xintercept = value),     data = trueParas, color = \"black\", linetype = 2,     label = \"True value\"   ) +   labs(color = \"Initial ETAS Para. Set\", linetype = \"Initial ETAS Para. Set\") +   ggtitle(paste(\"A.  Inversion of a 1000 day catalogue with no large events, nEvents =\", length(quiet.ETAS.cat$ts))) +   xlab(\"ETAS Posteriors\") +   theme_bw() +   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +   theme(legend.position = \"hidden\") +   theme(plot.title = element_text(size = 12)) #> Warning in geom_vline(aes(xintercept = value), data = trueParas, color = #> \"black\", : Ignoring unknown parameters: `label` trueParas <- data.frame(value = c(mu, K, alpha, c, p), param = c(\"mu\", \"K\", \"alpha\", \"c\", \"p\"))  post.list <- get_posterior_param(input.list = list.output.M6p7Scenario[[1]]) post.df <- post.list[[1]] post.df$id <- 2  for (i in 2:nRealisations) {   post.list <- get_posterior_param(input.list = list.output.M6p7Scenario[[i]])   post.df.tmp <- post.list[[1]]   post.df.tmp$id <- i    post.df <- rbind(post.df, post.df.tmp) }  plots[[2]] <- ggplot(post.df, aes(x = x, y = y, group = id, color = factor(id), lty = factor(id))) +   geom_line() +   # scale_x_discrete(guide = guide_axis(check.overlap = TRUE)) +   facet_wrap(facets = vars(param), scales = \"free\", labeller = label_parsed, nrow = 1) +   geom_vline(aes(xintercept = value),     data = trueParas, color = \"black\", linetype = 2,     label = \"True value\"   ) +   labs(color = \"Initial ETAS Para. Set\", linetype = \"Initial ETAS Para. Set\") +   ggtitle(paste(\"B. Inversion of a 1000 day catalogue with a M6.7 on day 500, nEvents =\", length(M6p7.ETAS.cat$ts))) +   xlab(\"ETAS Posteriors\") +   theme_bw() +   theme(axis.text.x = element_text(angle = 45, hjust = 1)) +   theme(legend.position = \"hidden\") +   theme(plot.title = element_text(size = 12)) #> Warning in geom_vline(aes(xintercept = value), data = trueParas, color = #> \"black\", : Ignoring unknown parameters: `label` plt <- grid_arrange_shared_legend(plots[[1]], plots[[2]], ncol = 1, nrow = 2, position = \"bottom\") plt #> TableGrob (2 x 1) \"arrange\": 2 grobs #>   z     cells    name              grob #> 1 1 (1-1,1-1) arrange   gtable[arrange] #> 2 2 (2-2,1-1) arrange gtable[guide-box] # ggsave(\"initialCondition_posteriors.png\", plt) # ggsave(\"initialCondition_posteriors.pdf\", plt)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"explore-etas-triggering-function-using-posterior-samples","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions","what":"Explore ETAS triggering function using posterior samples","title":"Sensitivity to starting point","text":"","code":"plot_triggering <- list() plot_triggering[[1]] <- triggering_fun_plot(list.output.quietScenario[[1]], magnitude = 4, n.samp = 100) +   ggtitle(\"C. M4 triggering function\") +   theme_bw() +   ylim(0, 5.5) +   theme(plot.title = element_text(size = 8))  plot_triggering[[2]] <- triggering_fun_plot(list.output.M6p7Scenario[[1]], magnitude = 4, n.samp = 100) +   ggtitle(\"D. M4 triggering function\") +   theme_bw() +   ylim(0, 5.5) +   theme(plot.title = element_text(size = 8))  plot_triggering[[3]] <- triggering_fun_plot(list.output.quietScenario[[1]], magnitude = 6.7, n.samp = 100) +   ggtitle(\"E. M6.7 triggering function\") +   theme_bw() +   ylim(0, 1700) +   theme(plot.title = element_text(size = 8))   plot_triggering[[4]] <- triggering_fun_plot(list.output.M6p7Scenario[[1]], magnitude = 6.7, n.samp = 100) +   ggtitle(\"F. M6.7 triggering function\") +   theme_bw() +   ylim(0, 1700) +   theme(plot.title = element_text(size = 8))   plt <- grid.arrange(plot_triggering[[1]], plot_triggering[[3]], plot_triggering[[2]], plot_triggering[[4]], ncol = 2, nrow = 2, top = \"Triggering function variability\") +   theme(plot.title = element_text(size = 8)) #> Warning: Removed 8 rows containing missing values (`geom_line()`). #> Warning: Removed 1 row containing missing values (`geom_line()`). plt #> NULL  # ggsave(\"trigFuncVariability_runin.png\", plt) # ggsave(\"trigFuncVariability_runin.pdf\", plt) plot_omori <- list() plot_omori[[1]] <- omori_plot_posterior(list.output.quietScenario[[1]], n.samp = 100) +   ggtitle(\"A. Omori decay\") +   theme_bw() +   ylim(0, 1) +   theme(plot.title = element_text(size = 8))   plot_omori[[2]] <- omori_plot_posterior(list.output.M6p7Scenario[[1]], n.samp = 100) +   ggtitle(\"B. Omori decay\") +   theme_bw() +   ylim(0, 1) +   theme(plot.title = element_text(size = 8)) plt <- grid.arrange(plot_omori[[1]], plot_triggering[[1]], plot_triggering[[3]], plot_omori[[2]], plot_triggering[[2]], plot_triggering[[4]], ncol = 3, nrow = 2, top = \"Triggering  function variability\", left = \"M6.7 baseline            Unseeded baseline\") #> Warning: Removed 8 rows containing missing values (`geom_line()`). #> Warning: Removed 1 row containing missing values (`geom_line()`). plt #> TableGrob (3 x 4) \"arrange\": 8 grobs #>   z     cells    name                 grob #> 1 1 (2-2,2-2) arrange       gtable[layout] #> 2 2 (2-2,3-3) arrange       gtable[layout] #> 3 3 (2-2,4-4) arrange       gtable[layout] #> 4 4 (3-3,2-2) arrange       gtable[layout] #> 5 5 (3-3,3-3) arrange       gtable[layout] #> 6 6 (3-3,4-4) arrange       gtable[layout] #> 7 7 (1-1,2-4) arrange text[GRID.text.1299] #> 8 8 (1-3,1-1) arrange text[GRID.text.1300]  # ggsave(\"trigFuncVariability_runin.png\", plt) # ggsave(\"trigFuncVariability_runin.pdf\", plt)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"plot-the-samples-from-the-joint-posteriors-as-pairs-plots","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions","what":"Plot the samples from the joint posteriors as pairs plots","title":"Sensitivity to starting point","text":"","code":"post_pairs_plot(list.output.quietScenario[[1]], n.samp = 1000)$pair.plot post_pairs_plot(list.output.M6p7Scenario[[1]], n.samp = 1000)$pair_plot #> NULL"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/sensitivityToStartingPoint.html","id":"inlabru-convergence-diagnostics","dir":"Articles","previous_headings":"Analyse the sensitivity to starting conditions","what":"inlabru convergence diagnostics","title":"Sensitivity to starting point","text":"can also assess convergence inlabru method , using bru_convergence_plot() function. can reveal starting values inlabru estimation unreasonable, better starting values nonlinear iterations might speed computations.","code":"bru_convergence_plot(list.output.quietScenario[[1]]$model.fit) bru_convergence_plot(list.output.quietScenario[[2]]$model.fit) bru_convergence_plot(list.output.M6p7Scenario[[1]]$model.fit) bru_convergence_plot(list.output.M6p7Scenario[[2]]$model.fit)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"introduction-to-etas-model","dir":"Articles","previous_headings":"","what":"Introduction to ETAS model","title":"2d Temporal Model: Tutorial on real data","text":"tutorial, show use ETAS.inlabru R-package fit temporal ETAS model real earthquakes data. tutorial shows prepare data, fit model, retrieve posterior distribution parameters posterior distribution quantities interest, generate synthetic catalogues fitted model, produce forecasts seismicity. Epidemic-Type Aftershock Sequence (ETAS) model belongs family Hawkes () point processes. temporal Hawkes process point process model conditional intensity given \\[ \\lambda(t | \\mathcal H_t) = \\mu + \\sum_{t_h \\\\mathcal H_t} g(t- t_h) \\] \\(\\mathcal H_t\\) history process time \\(t\\). Generally speaking \\(\\mathcal H_t\\) contains events occurred \\(t\\). quantity \\(\\mu > 0\\) usually called , interpreted rate events occur spontaneously. function \\(g(t-t_h)\\) called function (excitation function, simply kernel) measures influence event \\(t_h\\) time \\(t\\). look \\(g(t-t_h)\\) function \\(t\\) intensity point process representing offspring event \\(t_h\\). seismology offspring event called , two terms used synonyms. essence, Hawkes process model can seen superposition background process intensity \\(\\mu\\) aftershock processes generated observations \\(\\mathcal H_t\\) one intensity \\(g(t-t_h)\\). makes Hawkes process model particularly suitable describe phenomena event ability trigger additional events, phenomena characterized cascades events earthquakes, infectious diseases, wildfires, financial crisis, similar. ETAS model particular instance Hawkes process model proven particularly suitable model earthquake occurrence. Earthquakes usually described modelled marked time points marking variable magnitude event. history process composed time-magnitude pairs, namely \\(\\mathcal H_t = \\{(t_h,m_h), h = 1,...,N_h\\}\\). Various slightly different ETAS formulations exist, usually characterized slightly different triggering functions, one implemented ETAS.inlabru R-package conditional intensity given \\[ \\lambda(t | \\mathcal H_t) = \\mu + \\sum_{t_h \\\\mathcal H_t} K \\exp\\{\\alpha(m_h - M_0)\\}\\left(\\frac{t - t_h}{c} + 1\\right)^{-p} \\] \\(M_0\\) cutoff magnitude \\(m_h \\geq M_0\\) \\(h\\). value decided priori based quality catalogue used. parameters model : \\(\\mu \\geq 0\\), background rate \\(K \\geq 0\\) general productivity parameter, plays role determining average number aftershocks induced event catalogue. \\(\\alpha \\geq 0\\) magnitude scaling parameter, determines number aftershocks changes based magnitude event generating aftershocks. non-negative reflect fact stronger earthquakes generate aftershocks. \\(c > 0\\) time offset parameter, smaller values associated catalogues fewer missing events. \\(p > 1\\) aftershock decay parameter, determines rate aftershock activity decreases time. greater 1 otherwise event may generate infinite number aftershocks infinite interval time thought unphysical.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"priors","dir":"Articles","previous_headings":"","what":"Priors","title":"2d Temporal Model: Tutorial on real data","text":"Bayesian analysis need decide priors parameters. approximation method use considers parameters two different scales: original ETAS scale, internal scale. internal scale used package perform calculations. internal scale parameters constraint standard normal distribution prior. need set priors parameters ETAS scale. done considering copula transformation \\(\\eta(X)\\) \\(X \\sim N(0,1)\\) , \\(\\eta(X)\\) desired distribution. ETAS.inlabru R-package provides four different functions corresponding three different distributions: gamma_t(X, , b) Gamma distribution shape parameter \\(\\) rate \\(b\\). distribution mean \\(/b\\) variance \\(/b^2\\). unit_t(X, , b) Uniform distribution \\(\\) \\(b\\). exp_t(X, r) Exponential distribution rate \\(r\\). loggaus_t(X, m ,s) Log-Gaussian distribution mean logarithm \\(m\\) standard deviation logarithm \\(s\\). code generate 1000 observations normal distribution, transform using functions provided package, shows empirical density estimated sample.  package also provide inverse functions retrieve value parameter internal scale value ETAS scale provided. example decided priors going use analysis, need store corresponding copula transformations list. list one element parameter model (\\(5\\)), element list must name corresponding parameter. names fixed mu, K, alpha, c_, p. parameter \\(c\\) referred c_ avoid clashing names R function c(). useful inverse functions also, list used set initial value parameters later. code assumes parameter \\(\\mu\\) Gamma distribution prior parameters \\(0.3\\) \\(0.6\\), parameters \\(K, \\alpha,\\) \\(c\\) Uniform prior \\((0,10)\\), parameter \\(p\\) Uniform prior \\((1,10)\\).","code":"# obtain sample from standard normal distribution X <- rnorm(1000) # apply copula transformations gamma.X <- gamma_t(X, 1, 2) unif.X <- unif_t(X, 0, 1) exp.X <- exp_t(X, 1) loggaus.X <- loggaus_t(X, 0.5, 0.5)  # build data.frame for plotting df.to.plot <- rbind(   data.frame(     value = X,     distribution = \"Std Normal\"   ),   data.frame(     value = gamma.X,     distribution = \"Gamma\"   ),   data.frame(     value = unif.X,     distribution = \"Uniform\"   ),   data.frame(     value = exp.X,     distribution = \"Exponential\"   ),   data.frame(     value = loggaus.X,     distribution = \"Log-Gaussian\"   ) ) # plot them ggplot(df.to.plot, aes(value)) +   geom_histogram() +   theme_bw() +   facet_wrap(facets = ~distribution, scales = \"free\") #> `stat_bin()` using `bins = 30`. Pick better value with `binwidth`. inv_gamma_t(gamma_t(1.2, 1, 2), 1, 2) #> [1] 1.2 inv_unif_t(unif_t(1.2, 1, 2), 1, 2) #> [1] 1.2 inv_exp_t(exp_t(1.2, 1), 1) #> [1] 1.2 inv_loggaus_t(loggaus_t(1.2, 1, 2), 1, 2) #> [1] 1.2 # set copula transformations list link.f <- list(   mu = \\(x) gamma_t(x, 0.3, 0.6),   K = \\(x) unif_t(x, 0, 10),   alpha = \\(x) unif_t(x, 0, 10),   c_ = \\(x) unif_t(x, 0, 10),   p = \\(x) unif_t(x, 1, 10) )  # set inverse copula transformations list inv.link.f <- list(   mu = \\(x) inv_gamma_t(x, 0.3, 0.6),   K = \\(x) inv_unif_t(x, 0, 10),   alpha = \\(x) inv_unif_t(x, 0, 10),   c_ = \\(x) inv_unif_t(x, 0, 10),   p = \\(x) inv_unif_t(x, 1, 10) )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"laquila-seismic-sequence","dir":"Articles","previous_headings":"","what":"L’Aquila seismic sequence","title":"2d Temporal Model: Tutorial on real data","text":"Earthquake data stored -called earthquake catalogues. Many different catalogues exists region easy way decide one better. , provide subset HOmogenized instRUmental Seismic (HORUS) catalogue 1960 2020. can downloaded http://horus.bo.ingv./. See data-raw/horus.R details subset created original data set. HORUS catalogue subset can accessed directly using horus ETAS.inlabru::horus: documentation data set available via ?horus. data reports earthquake time string (time_string), longitude (lon) latitude (lat) epicentre, depth kilometres (depth), moment magnitude (M). focus L’Aquila seismic sequence sufficient retain observations specific space-time-magnitude region include sequence interest. L’Aquila sequence, retain events magnitude greater equal \\(2.5\\) happened 2009 longitude \\((10.5, 16)\\) latitude \\((40.5, 45)\\). L’Aquila sequence selected way composed 1024 events. seismic sequence can selected similarly. selection convenient transform time string Date object select rows Horus catalogue verifying conditions. data can visually represented plotting time event magnitude. shows clustering observations correspondance high magnitude events. L’Aquila seismic sequence, times versus magnitudes","code":"# load HORUS catalogue head(horus) #>           time_string     lon     lat depth    M #> 1 1960-01-03T20:19:34 15.3000 39.3000   290 6.34 #> 2 1960-01-04T09:20:00 13.1667 43.1333     0 3.94 #> 3 1960-01-06T15:17:34 12.7000 46.4833     4 4.69 #> 4 1960-01-06T15:20:53 12.7000 46.4667     0 4.14 #> 5 1960-01-06T15:31:00 12.7500 46.4333     0 3.00 #> 6 1960-01-06T15:45:00 12.7500 46.4333     0 3.00 # transform time string in Date object horus$time_date <- as.POSIXct(   horus$time_string,   format = \"%Y-%m-%dT%H:%M:%OS\" ) # There may be some incorrectly registered data-times in the original data set, # that as.POSIXct() can't convert, depending on the system. # These should ideally be corrected, but for now, we just remove the rows that # couldn't be converted. horus <- na.omit(horus)  # set up parameters for selection start.date <- as.POSIXct(\"2009-01-01T00:00:00\", format = \"%Y-%m-%dT%H:%M:%OS\") end.date <- as.POSIXct(\"2010-01-01T00:00:00\", format = \"%Y-%m-%dT%H:%M:%OS\") min.longitude <- 10.5 max.longitude <- 16 min.latitude <- 40.5 max.latitude <- 45 M0 <- 2.5  # set up conditions for selection aquila.sel <- (horus$time_date >= start.date) &   (horus$time_date < end.date) &   (horus$lon >= min.longitude) &   (horus$lon <= max.longitude) &   (horus$lat >= min.latitude) &   (horus$lat <= max.latitude) &   (horus$M >= M0)  # select aquila <- horus[aquila.sel, ] ggplot(aquila, aes(time_date, M)) +   geom_point() +   theme_bw()"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"data-preparation-to-model-fitting","dir":"Articles","previous_headings":"","what":"Data preparation to model fitting","title":"2d Temporal Model: Tutorial on real data","text":"need prepare data.frame used input data fit ETAS model. data.frame must three columns: ts time difference starting date occurrence time events (measured days example), magnitudes magnitude events, idx.p index column different value event. names fixed changed , need set initial values parameters list containing inlabru options used. initial values stored list elements th.mu, th.K, th.alpha, th.c, th.p corresponds ETAS parameters. initial values must provided internal scale therefore useful retrieve using inverse copula transformations set . way, can find values parameters internal scale given value parameters ETAS scale. example uses \\(\\mu = 0.5, K = 0.1, \\alpha = 1, c = 0.1,\\) \\(p = 1.1\\) initial values. crucial set initial values cause numerical problems, general achieved setting initial values zero. values provided worked well various examples. Lastly, need set list inlabru options. main elements list : bru_verbose: number indicating type diagnostic output. Set 0 output. bru_max_iter: maximum number iterations. set max_step inlabru algorithm stops stopping criterion met. However, setting max_step values smaller 1 forces algorithm run exactly bru_max_iter iterations. bru_method: relevant , thing may need set max_step argument. algorithm converge without fixing max_step suggest try fix value 1, experience \\(0.5\\) \\(0.2\\) works well. example line setting bru_method commented. bru_initial: list initial values created . Note: option list, one can also set number threads allowed INLA , e.g. num.threads = 8. override global option set beginning tutorial. code likely run many different systems, using global setting easier manage.","code":"# set up data.frame for model fitting aquila.bru <- data.frame(   ts = as.numeric(     difftime(aquila$time_date, start.date, units = \"days\")   ),   magnitudes = aquila$M,   idx.p = 1:nrow(aquila) ) # set up list of initial values th.init <- list(   th.mu = inv.link.f$mu(0.5),   th.K = inv.link.f$K(0.1),   th.alpha = inv.link.f$alpha(1),   th.c = inv.link.f$c_(0.1),   th.p = inv.link.f$p(1.1) ) # set up list of bru options bru.opt.list <- list(   bru_verbose = 3, # type of visual output   bru_max_iter = 70, # maximum number of iterations   # bru_method = list(max_step = 0.5),   bru_initial = th.init # parameters' initial values )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model fitting","title":"2d Temporal Model: Tutorial on real data","text":"function Temporal.ETAS fit ETAS model returns bru object output. required inputs : total.data: data.frame containing observed events. format described previous Section. M0: cutoff magnitude. events total.data must magnitude greater equal number. T1: starting time time interval want fit model. T2: end time time interval want fit model. link.functions: list copula transformation functions format described previous sections. coef.t., delta.t., N.max.: parameters temporal binning. binning strategy described Appendix B paper Approximation Bayesian Hawkes process inlabru. parameters corresponds coef.t.\\(=\\delta\\), delta.t.\\(=\\Delta\\), N.max.\\(=n_{\\max}\\). bru.opt: list inlabru options described previous Section.","code":"# set starting and time of the time interval used for model fitting. In this case, we use the interval covered by the data. T1 <- 0 T2 <- max(aquila.bru$ts) + 0.2 # Use max(..., na.rm = TRUE) if there may still be NAs here # fit the model aquila.fit <- Temporal.ETAS(   total.data = aquila.bru,   M0 = M0,   T1 = T1,   T2 = T2,   link.functions = link.f,   coef.t. = 1,   delta.t. = 0.1,   N.max. = 5,   bru.opt = bru.opt.list ) #> Start creating grid...  #> Finished creating grid, time  2.116181"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"create-input-list","dir":"Articles","previous_headings":"","what":"Create input list","title":"2d Temporal Model: Tutorial on real data","text":"model fitted package ETAS.inlabru offers various functions visually explore output. require input list. list must different elements depending function going use. retrieve posterior parameters sample posterior parameters need two elements: model.fit: output Temporal.ETAS link.functions: list copula transformations","code":"# create input list to explore model output input_list <- list(   model.fit = aquila.fit,   link.functions = link.f )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"check-marginal-posterior-distributions","dir":"Articles","previous_headings":"","what":"Check marginal posterior distributions","title":"2d Temporal Model: Tutorial on real data","text":"function get_posterior_param can use retrieve marginal posteriors parameters ETAS scale. function returns list elements: post.df: data.frame containing posterior parameters. data.frame three columns, x value parameter, y corresponding value posterior, param indicates ETAS parameter x y referring . post.plot: ggplot object containing plot marginal posteriors parameters","code":"# get marginal posterior information post.list <- get_posterior_param(input.list = input_list)  # plot marginal posteriors post.list$post.plot"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"sample-the-joint-posterior-and-make-pair-plot","dir":"Articles","previous_headings":"","what":"Sample the joint posterior and make pair plot","title":"2d Temporal Model: Tutorial on real data","text":"function post_sampling generate samples joint posterior ETAS parameters. function takes input: input.list: list model.fit element link.functions elements described . n.samp: number posterior samples. max.batch: number posterior samples generated simultaneously. n.samp\\(>\\)max.batch, , samples generated parallel batches maximum size equal max.batch. Default \\(1000\\). ncore: number cores used parallel n.samp\\(>\\)max.batch. function returns data.frame columns corresponding ETAS parameters posterior samples can used analyse correlation parameters. function post_pairs_plot generate pair plot posterior samples taken input. function 4 arguments need specified. input : post.samp: data.frame samples joint posterior distribution parameters. NULL samples generated function . input.list: input list arguments model.fit link.functions used generate posterior samples. used post.samp = NULL. Default NULL. n.samp: number posterior samples. NULL, samples post.samp used. post.samp NULL, n.samp samples generated joint posterior. post.samp n.samp NULL n.samp samples randomly (uniformly replacement) selected post.samp. Default NULL max.batch number posterior samples generated simultaneously. used post.samp NULL. Default NULL function returns list two elements: post.samp posterior samples, pair.plot ggplot object containing pair plot.","code":"post.samp <- post_sampling(   input.list = input_list,   n.samp = 1000,   max.batch = 1000,   ncore = num.cores )  head(post.samp) #>          mu         K    alpha          c        p #> 1 0.3470104 0.1260210 2.497211 0.05949712 1.157757 #> 2 0.2958848 0.1316819 2.450078 0.06304385 1.166512 #> 3 0.3216552 0.1332976 2.470935 0.06368277 1.157579 #> 4 0.2499366 0.1371255 2.449576 0.06398508 1.149188 #> 5 0.2957505 0.1372523 2.438459 0.06870959 1.169935 #> 6 0.3010415 0.1462465 2.424095 0.05610195 1.140713 pair.plot <- post_pairs_plot(   post.samp = post.samp,   input.list = NULL,   n.samp = NULL,   max.batch = 1000 ) #> Registered S3 method overwritten by 'GGally': #>   method from    #>   +.gg   ggplot2 pair.plot$pair.plot"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"check-posterior-number-of-events","dir":"Articles","previous_headings":"","what":"Check posterior number of events","title":"2d Temporal Model: Tutorial on real data","text":"quantity interest posterior distribution number events. can accessed using function get_posterior_N requires input list. However, list needs additional elements respect one used now. Specifically, need add T12 extremes time interval want calculate number events, M0 cutoff magnitude, catalog.bru data.frame containing observed events. latter format total.data used Temporal.ETAS function. function returns list three elements: post.plot plot distribution, post.plot.shaded plot distribution shaded regions representing \\(95\\%\\) interval distribution, post.df data.frame used generate plots. vertical line plots represent number events catalog.bru element input list.","code":"# set additional elements of the list input_list$T12 <- c(T1, T2) input_list$M0 <- M0 input_list$catalog.bru <- aquila.bru N.post <- get_posterior_N(input.list = input_list) N.post$post.plot"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"posterior-of-the-triggering-function-and-omori-law","dir":"Articles","previous_headings":"","what":"Posterior of the triggering function and Omori law","title":"2d Temporal Model: Tutorial on real data","text":"functions triggering_fun_plot triggering_fun_plot_prior plot, respectively, quantiles posterior prior distribution triggering function \\(g(t-t_h, mh)\\), namely, \\[ g(t - t_h, m_h) = K\\exp\\{\\alpha(m_h - M_0)\\}\\left(\\frac{t - t_h}{c} + 1\\right)^{-p} \\] function takes input input.list: input list defined functions used previously. post.samp: data.frame samples posterior distribution parameters. NULL, n.samp samples generated posterior. n.samp: number posterior samples parameters used generated. magnitude: magnitude event (\\(m_h\\)). t.end: maximum value \\(t\\) plot. n.breaks: number breaks interval \\((0, \\texttt{t.end})\\) divided. function returns ggplot object. sample parameters triggering function \\(0\\) t.end calculated. black solid lines represents \\(95\\%\\) posterior interval function, grey lines represent triggering function calculated posterior samples, horizontal red lines represent \\(95\\%\\) posterior interval background rate \\(\\mu\\). function triggering_fun_plot_prior value parameters sampled according prior distribution rather posterior, therefore, need specify posterior samples data.frame.   functions omori_plot_posterior omori_plot_prior functions triggering_fun_plot triggering_fun_plot_prior considering \\[ \\left(\\frac{t- t_h}{c} + 1\\right)^{-p} \\] instead whole triggering function without background rate.","code":"triggering_fun_plot(   input.list = input_list,   post.samp = post.samp,   n.samp = NULL, magnitude = 4,   t.end = 5, n.breaks = 100 ) triggering_fun_plot_prior(input.list = input_list, magnitude = 4, n.samp = 1000, t.end = 10) omori_plot_posterior(input.list = input_list, post.samp = post.samp, n.samp = NULL, t.end = 5) omori_plot_prior(input.list = input_list, n.samp = 1000, t.end = 5)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"generate-synthetic-catalogues-from-model","dir":"Articles","previous_headings":"","what":"Generate synthetic catalogues from model","title":"2d Temporal Model: Tutorial on real data","text":"earthquake forecast usually composed collection synthetic catalogues model. package ETAS.inlabru provides function generate synthetic catalogues given set parameters. can used produce forecasts simply produce synthetic catalogues. function generate synthetic catalogues called generate_temporal_ETAS_synthetic takes input theta: list ETAS parameters names mu, K, alpha, c, p, corresponding ETAS parameters. beta.p: parameter magnitude distribution M0: cutoff magnitude, generated event magnitude greater M0. T1: starting time catalogue (unit measure depends unit used fit model). T2: end time catalogue (unit measure depends unit used fit model). Ht: set known events. can also T1 T2, useful want generate catalogues imposed events. Regarding magnitude distribution, exponential, specificically assume \\[ m - M_0 \\sim \\text{Exp}(\\beta) \\] parameter \\(\\beta\\) usually estimated independently ETAS parameters. use maximum likelihood estimator \\(\\beta\\) given \\[ \\hat\\beta = \\frac{1}{\\bar{m} - M_0} \\] \\(\\bar m\\) mean observed magnitudes values. function returns list data.frame, element output list corresponds different generation. data.frame three columns: occurence time (ts), magnitude (magnitudes), generation identifier (gen). generation identifier uses following convention, \\(-1\\) indicates events Ht time T1 T2, \\(0\\) indicates first generation offspring events gen equal \\(-1\\), \\(1\\) indicates background events, \\(2\\) offspring events gen equal \\(0\\) \\(1\\), \\(3\\) indicates offspring events gen equal \\(2\\), \\(4\\) indicates offspring events gen equal \\(3\\), . obtain unique data.frame containing simulated events sufficient bind rows generations. example generate 1 synthetic catalogue using parameters one posterior samples generated . catalogue covers time span L’Aquila catalogue impose greatest event sequence.  can easily generate multiple catalogues. code generates 8 catalogues using different samples posterior distribution parameters. red point indicates event imposed last panel represents observed L’Aquila sequence.","code":"# maximum likelihood estimator for beta beta.p <- 1 / (mean(aquila.bru$magnitudes) - M0) synth.cat.list <- generate_temporal_ETAS_synthetic(   theta = post.samp[1, ], # ETAS parameters   beta.p = beta.p, # magnitude distribution parameter   M0 = M0, # cutoff magnitude   T1 = T1, # starting time   T2 = T2, # end time   Ht = aquila.bru[which.max(aquila.bru$magnitudes), ] # known events ) # merge into unique data.frame synth.cat.df <- do.call(rbind, synth.cat.list) # order events by time synth.cat.df <- synth.cat.df[order(synth.cat.df$ts), ]  ggplot(synth.cat.df, aes(ts, magnitudes, color = as.factor(gen))) +   geom_point(size = 0.5) set.seed(2) n.cat <- 8 # generate catalogues as list of lists multi.synth.cat.list <- lapply(seq_len(n.cat), \\(x) generate_temporal_ETAS_synthetic(   theta = post.samp[x, ],   beta.p = beta.p,   M0 = M0,   T1 = T1,   T2 = T2,   Ht = aquila.bru[which.max(aquila.bru$magnitudes), ] ))  # store catalogues as list of data.frames multi.synth.cat.list.df <- lapply(multi.synth.cat.list, \\(x) do.call(rbind, x)) # set catalogue identifier multi.synth.cat.list.df <- lapply(seq_len(n.cat), \\(x) cbind(multi.synth.cat.list.df[[x]],   cat.idx = x )) # merge catalogues in unique data.frame multi.synth.cat.df <- do.call(rbind, multi.synth.cat.list.df)  # we need to bing the synthetics with the observed catalogue for plotting cat.df.for.plotting <- rbind(   multi.synth.cat.df,   cbind(aquila.bru[, c(\"ts\", \"magnitudes\")],     gen = NA,     cat.idx = \"observed\"   ) )  # plot them ggplot(cat.df.for.plotting, aes(ts, magnitudes)) +   geom_point(size = 0.5) +   geom_point(     data = aquila.bru[which.max(aquila.bru$magnitudes), ],     mapping = aes(ts, magnitudes),     color = \"red\"   ) +   facet_wrap(facets = ~cat.idx)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_real.html","id":"forecasting","dir":"Articles","previous_headings":"","what":"Forecasting","title":"2d Temporal Model: Tutorial on real data","text":"earthquake forecast usually collection synthetic catalogues generated model. bayesian models can reflect uncertainty parameters values generating synthetic catalogue composing forecast using different set parameters sampled join posterior distribution. can generate forecasts using function Temporal.ETAS.forecast. function takes input post.samp: data.frame samples posterior distribution parameters format described previous sections. n.cat: number synthetic catalogues composing forecast. n.cat greater nrow(post.samp), rows post.samp sampled uniformly replacement n.cat times. n.cat smaller nrow(post.samp), , rows post.samp sampled uniformly without replacement n.cat times. n.cat NULL equal nrow(post.samp), , post.samp used . ncore: number cores used generate synthetic catalogues parallel. remaining inputs (beta.p, M0, T1, T2, Ht) ones used generate_temporal_ETAS_synthetic. output function list two elements: fore.df n.cat. element fore.df data.frame synthetic catalogues binded together row, multi.synth.cat.df created . element n.cat just number catalogues generated. need n.cat zero-events catalogues appear fore.df, corresponding cat.idx value missing. Therefore need n.cat recover total number catalogues. code creates daily forecast 24 hours starting 1 minute event greatest magnitude sequence. starting date end date forecast expressed unit used catalogue fit model (days case). Day zero correspond start.date stated beginning document example \\(2009-01-01 00:00:00\\). forecast generated assuming known events catalogue occurred forecasting period. can easily retrieve predictive distribution number events forecasting period looking frequencies catalogue identifiers appears fore.df element. Indeed, number rows fore.df cat.idx value represents number events synthetic catalogue. , frequency catalogue identifier appears fore.df$cat.idx correspond number events catalogue. allows easily retrieve predictive distribution number events using code . remark case can use function table find frequencies elements fore.df$cat.idx. catalogue identifier zero-events catalogues present fore.df$cat.idx. using table lead zero probability zero events day, quantity crucial intersted probability earthquake activity (probability least one event).","code":"# express 1 minute in days min.in.days <- 1 / (24 * 60) # find time of the event with the greatest magnitude t.max.mag <- aquila.bru$ts[which.max(aquila.bru$magnitudes)] # set starting time of the forecasting period T1.fore <- t.max.mag + min.in.days # set forecast length fore.length <- 1 # set end time of the forecasting period T2.fore <- T1.fore + fore.length # set known data Ht.fore <- aquila.bru[aquila.bru$ts < T1.fore, ]  # produce forecast daily.fore <- Temporal.ETAS.forecast(   post.samp = post.samp, # ETAS parameters posterior samples   n.cat = nrow(post.samp), # number of synthetic catalogues   beta.p = beta.p, # magnitude distribution parameter   M0 = M0, # cutoff magnitude   T1 = T1.fore, # forecast starting time   T2 = T2.fore, # forecast end time   Ht = Ht.fore, # known events   ncore = num.cores ) # number of cores # find number of events per catalogue N.fore <- vapply(   seq_len(daily.fore$n.cat),   \\(x) sum(daily.fore$fore.df$cat.idx == x), 0 ) # find number of observed events in the forecasting period N.obs <- sum(aquila.bru$ts >= T1.fore & aquila.bru$ts <= T2.fore) # plot the distribution ggplot() +   geom_histogram(aes(x = N.fore, y = after_stat(density)), binwidth = 1) +   geom_vline(xintercept = N.obs) +   xlim(100, 500) #> Warning: Removed 39 rows containing non-finite values (`stat_bin()`). #> Warning: Removed 2 rows containing missing values (`geom_bar()`)."},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"2c Temporal Model: Tutorial on synthetic data","text":"tutorial shows use ETAS.inlabru package generate synthetic catalogue temporal ETAS model fit ETAS model data. also show retrieve posterior distribution parameters quantity interest. brief introduction ETAS model refer tutorial real earthquake data.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"generate-a-synthetic-catalogue","dir":"Articles","previous_headings":"","what":"Generate a synthetic catalogue","title":"2c Temporal Model: Tutorial on synthetic data","text":"function generate_temporal_ETAS_synthetic() can used generate synthetic catalogues temporal ETAS model fixed parameters spanning given interval time. generate_temporal_ETAS_synthetic() takes input theta: list ETAS parameters names mu, K, alpha, c, p, corresponding ETAS parameters. beta.p: parameter magnitude distribution M0: cutoff magnitude, generated event magnitude greater M0. T1: starting time catalogue (unit measure depends unit used fit model). T2: end time catalogue (unit measure depends unit used fit model). Ht: set known events. can also T1 T2, useful want generate catalogues imposed events. NULL events imposed. function returns list data.frame, element output list corresponds different generation. data.frame three columns: occurence time (ts), magnitude (magnitudes), generation identifier (gen). generation identifier uses following convention, \\(-1\\) indicates events Ht time T1 T2, \\(0\\) indicates first generation offspring events gen equal \\(-1\\), \\(1\\) indicates background events, \\(2\\) offspring events gen equal \\(0\\) \\(1\\), \\(3\\) indicates offspring events gen equal \\(2\\), \\(4\\) indicates offspring events gen equal \\(3\\), . obtain unique data.frame containing simulated events sufficient bind rows generations. code generates synthetic catalogue events magnitude greater \\(2.5\\) according temporal ETAS model parameters equal vector true.param. value parameters equal posterior mean parameters obtained fitting model L’Aquila seismic sequence done tutorial real data. Also parameter \\(\\beta\\) magnitude distribution comes example. output function list data.frames convenient transform single data.frame binding rows data.frames list. synthetic catalogue composed total \\(288\\) events \\(112\\) background events \\(176\\) aftershocks. can easily retrieve numbers looking gen column data. code plot occurrence time events magnitude color indicating generation event time evolution cumulative number events. multiplot function provided inlabru R-package can used combine plots.","code":"set.seed(111) # set true ETAS parameters true.param <- list(mu = 0.30106014, K = 0.13611399, alpha = 2.43945301, c = 0.07098607, p = 1.17838741) # set magnitude distribution parameter beta.p <- 2.353157 # set cutoff magnitude M0 <- 2.5 # set starting time of the synthetic catalogue T1 <- 0 # set end time of the synthetic catalogue T2 <- 365 # generate the catalogue - it returns a list of data.frames synth.cat.list <- generate_temporal_ETAS_synthetic(   theta = true.param,   beta.p = beta.p,   M0 = M0,   T1 = T1,   T2 = T2,   Ht = NULL,   ncore = 1 ) synth.cat.df <- do.call(rbind, synth.cat.list) head(synth.cat.df) #>           ts magnitudes gen #> 1 135.204031   2.661688   1 #> 2 187.947198   2.632073   1 #> 3 137.847074   3.073890   1 #> 4 152.693124   2.653628   1 #> 5   3.890113   2.686633   1 #> 6 194.287763   3.035756   1 c(N = nrow(synth.cat.df), N.bkg = sum(synth.cat.df$gen == 1), N.after = sum(synth.cat.df$gen > 1)) #>       N   N.bkg N.after  #>     288     112     176 pl1 <- ggplot(synth.cat.df, aes(ts, magnitudes, color = as.factor(gen))) +   geom_point() +   labs(color = \"gen\")  t.breaks <- T1:T2 N.cumsum <- vapply(t.breaks, \\(x) sum(synth.cat.df$ts < x), 0) df.to.cumsum.plot <- data.frame(ts = t.breaks, N.cum = N.cumsum) pl2 <- ggplot(df.to.cumsum.plot, aes(ts, N.cum)) +   geom_line() +   ylab(\"cumulative number of events\")  inlabru::multiplot(pl1, pl2, cols = 2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"prepare-data-for-model-fitting","dir":"Articles","previous_headings":"","what":"Prepare data for model fitting","title":"2c Temporal Model: Tutorial on synthetic data","text":"order fit model synthetic catalogue need set parameters priors set initial value parameters set inlabru options prepare data model fitting set priors need create list copula transformation (simply link) functions. method works internal representation parameters parameter Gaussian distribution. need function transform parameters original ETAS scale set prior . ETAS.inlabru package offers four different functions corresponding four different prior distributions. functions gamma_t, unif_t, exp_t, loggaus_t corresponds Gamma distribution, Uniform distribution, Exponential distribution Log-Gaussian distribution. also provide inverse functions retrieve value parameters internal scale given value ETAS scale. inv_gamma_t, inv_unif_t, exp_t, inv_loggaus_t. example going consider following priors parameters \\[\\begin{align*} \\mu & \\sim \\Gamma(0.3, 0.6) \\\\ K & \\sim \\text{Unif}(0,10) \\\\ \\alpha & \\sim \\text{Unif}(0,10) \\\\ c & \\sim \\text{Unif}(0,10) \\\\ p & \\sim \\text{Unif}(1,10) \\end{align*}\\] list link functions corresponding priors initial value parameters inlabru algorithm must specified internal scale parameters. reason, useful create list inverse link functions can specify initial value parameters ETAS scale easily retrieve corresponding value parameters internal scale. can done shown initial value parameters specified list names th.mu, th.K, th.alpha, th.c, th.p, , example, th.mu corresponds initial value parameter \\(\\mu\\) internal scale. initial value parameters important ensure algorithm able converge. Indeed, start algorithm values parameters causing numerical problems, may prevent algorithm converge. experience, setting initial values parameter (e.g. \\(< 10^{-5}\\)) (e.g. \\(> 10^2\\)) safe choice. code uses following initial values parameters \\(\\mu_{\\text{init}} = 0.5, K_{\\text{init}} = 0.1, \\alpha_{\\text{init}} = 1, c_{\\text{init}} = 0.1, p_{\\text{init}} = 1.1\\) Also inlabru options provided list, main elements list : bru_verbose: number indicating type visual output. Set 0 output. bru_max_iter: maximum number iterations. set max_step inlabru algorithm stops stopping criterion met. However, setting max_step values smaller 1 forces algorithm run exactly bru_max_iter iterations. bru_method: relevant , thing may need set max_step argument. algorithm converge without fixing max_step suggest try fix value 1, experience \\(0.5\\) \\(0.2\\) works well. example line setting bru_method commented. bru_initial: list initial values created . Lastly, need prepare data model fitting. data must provided data.frame least 3 columns names ts corresponding occurrence time events, magnitudes corresponding magnitude, idx.p event identifier. events data.frame must sorted respect occurrence time. synthetic catalogue generated beginning already columns ts magnitudes, sorted generation time. code sort rows data.frame adds event identifier","code":"# set copula transformations list link.f <- list(   mu = \\(x) gamma_t(x, 0.3, 0.6),   K = \\(x) unif_t(x, 0, 10),   alpha = \\(x) unif_t(x, 0, 10),   c_ = \\(x) unif_t(x, 0, 10),   p = \\(x) unif_t(x, 1, 10) ) # set inverse copula transformations list inv.link.f <- list(   mu = \\(x) inv_gamma_t(x, 0.3, 0.6),   K = \\(x) inv_unif_t(x, 0, 10),   alpha = \\(x) inv_unif_t(x, 0, 10),   c_ = \\(x) inv_unif_t(x, 0, 10),   p = \\(x) inv_unif_t(x, 1, 10) ) # set up list of initial values th.init <- list(   th.mu = inv.link.f$mu(0.5),   th.K = inv.link.f$K(0.1),   th.alpha = inv.link.f$alpha(1),   th.c = inv.link.f$c_(0.1),   th.p = inv.link.f$p(1.1) ) # set up list of bru options bru.opt.list <- list(   bru_verbose = 3, # type of visual output   bru_max_iter = 70, # maximum number of iterations   # bru_method = list(max_step = 0.5),   bru_initial = th.init ) # parameters initial values # sort catalogue by occurrence time synth.cat.df <- synth.cat.df[order(synth.cat.df$ts), ] # add event identifier synth.cat.df$idx.p <- seq_len(nrow(synth.cat.df))"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"model-fitting","dir":"Articles","previous_headings":"","what":"Model Fitting","title":"2c Temporal Model: Tutorial on synthetic data","text":"function Temporal.ETAS fit ETAS model returns bru object output. required inputs : total.data: data.frame containing observed events. format described previous Section. M0: cutoff magnitude. events total.data must magnitude greater equal number. T1: starting time time interval want fit model. T2: end time time interval want fit model. link.functions: list copula transformation functions format described previous sections. coef.t., delta.t., N.max.: parameters temporal binning. binning strategy described Appendix B paper Approximation Bayesian Hawkes process inlabru. parameters corresponds coef.t.\\(=\\delta\\), delta.t.\\(=\\Delta\\), N.max.\\(=n_{\\max}\\). bru.opt: list inlabru options described previous Section.","code":"synth.fit <- Temporal.ETAS(   total.data = synth.cat.df,   M0 = M0,   T1 = T1,   T2 = T2,   link.functions = link.f,   coef.t. = 1,   delta.t. = 0.1,   N.max. = 5,   bru.opt = bru.opt.list ) #> Start creating grid...  #> Finished creating grid, time  0.5662448"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"check-marginal-posterior-distributions","dir":"Articles","previous_headings":"","what":"Check marginal posterior distributions","title":"2c Temporal Model: Tutorial on synthetic data","text":"order retrieve marginal posterior distributions parameter need provide list containing two elements: model.fit bru object containing fitted model, link.functions list link functions created . list created, function get_posterior_param returns marginal posterior distribution parameters ETAS scale. function returns list two elements: post.df data.frame three columns, x indicating value parameter, y indicating corresponding value marginal posterior distribution, param parameter identifier. output list also contains post.plot ggplot object containing plot marginal posterior distributions parameter. code retrieve marginal posterior distribution parameters plot along true value parameters represented vertical dashed lines.","code":"# create input list to explore model output input_list <- list(   model.fit = synth.fit,   link.functions = link.f ) # retrieve marginal posterior distributions post.list <- get_posterior_param(input.list = input_list)  # create data.frame of true value of parameters df.true.param <- data.frame(   x = unlist(true.param),   param = names(true.param) ) # add to the marginal posterior distribution of the parameters the true value of the parameters. post.list$post.plot +   geom_vline(     data = df.true.param,     mapping = aes(xintercept = x), linetype = 2   )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"sampling-the-joint-posterior-distribution","dir":"Articles","previous_headings":"","what":"Sampling the joint posterior distribution","title":"2c Temporal Model: Tutorial on synthetic data","text":"function post_sampling generate samples joint posterior ETAS parameters. function takes input: input.list: list model.fit element link.functions elements described . n.samp: number posterior samples. max.batch: number posterior samples generated simultaneously. n.samp\\(>\\)max.batch, , samples generated parallel batches maximum size equal max.batch. Default \\(1000\\). ncore: number cores used parallel n.samp\\(>\\)max.batch. function returns data.frame columns corresponding ETAS parameters posterior samples can used estimate posterior distribution functions parameters.","code":"post.samp <- post_sampling(   input.list = input_list,   n.samp = 1000,   max.batch = 1000,   ncore = 1 ) head(post.samp) #>          mu          K    alpha         c        p #> 1 0.3486628 0.04560290 2.587489 0.2359790 1.352721 #> 2 0.3256986 0.02997082 2.558787 0.3960673 1.446702 #> 3 0.3212016 0.03376037 2.680164 0.4344579 1.657118 #> 4 0.2705829 0.04753127 2.499950 0.2526586 1.343067 #> 5 0.3098899 0.04627551 2.483610 0.3416950 1.406082 #> 6 0.3025027 0.02243282 2.635444 0.4811390 1.531598"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"triggering-function-and-omori-law","dir":"Articles","previous_headings":"","what":"Triggering function and Omori law","title":"2c Temporal Model: Tutorial on synthetic data","text":"Interesting functions parameters triggering function Omori law. can estimate posterior distribution functions using samples joint posterior distribution parameters obtained previous section. functions triggering_fun_plot provides plot quantiles posterior distribution triggering function \\(g(t-t_h, mh)\\), namely, \\[ g(t - t_h, m_h) = K\\exp\\{\\alpha(m_h - M_0)\\}\\left(\\frac{t - t_h}{c} + 1\\right)^{-p} \\] function takes input input.list: input list defined functions used previously. post.samp: data.frame samples posterior distribution parameters. NULL, n.samp samples generated posterior. n.samp: number posterior samples parameters used generated. magnitude: magnitude event (\\(m_h\\)). t.end: maximum value \\(t\\) plot. n.breaks: number breaks interval \\((0, \\texttt{t.end})\\) divided. function returns ggplot object. sample parameters triggering function \\(0\\) t.end calculated. black solid lines represents \\(95\\%\\) posterior interval function, grey lines represent triggering function calculated posterior samples, horizontal red lines represent \\(95\\%\\) posterior interval background rate \\(\\mu\\). function triggering_plot_prior using parameters sampled priors parameters. code creates plot posterior triggering function adds triggering function calculated true parameter values blue. need add argument M0 input_list use function triggering_fun_plot.  functions omori_plot_posterior function triggering_fun_plot considering \\[ \\left(\\frac{t- t_h}{c} + 1\\right)^{-p} \\] instead whole triggering function without background rate.","code":"# add cutoff magnitude to input_list input_list$M0 <- M0  # generate triggering function plot trig.plot <- triggering_fun_plot(   input.list = input_list,   post.samp = post.samp,   n.samp = NULL, magnitude = 4,   t.end = 5, n.breaks = 100 )  # set times at which calculate the true triggering function t.breaks <- seq(1e-6, 5, length.out = 100) # calculate the function true.trig <- gt(unlist(true.param), t = t.breaks, th = 0, mh = 4, M0 = M0) # store in data.frame for plotting true.trig.df <- data.frame(ts = t.breaks, trig.fun = true.trig)  # add the true triggering function to the plot trig.plot +   geom_line(     data = true.trig.df,     mapping = aes(x = ts, y = trig.fun), color = \"blue\"   ) omori.plot <- omori_plot_posterior(input.list = input_list, post.samp = post.samp, n.samp = NULL, t.end = 5)  true.omori <- omori(theta = unlist(true.param), t = t.breaks, ti = 0) true.omori.df <- data.frame(ts = t.breaks, omori.fun = true.omori)  omori.plot +   geom_line(     data = true.omori.df,     mapping = aes(x = ts, y = omori.fun), color = \"blue\"   )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/articles/tutorial_synth.html","id":"comparison-between-different-fitted-models","dir":"Articles","previous_headings":"","what":"Comparison between different fitted models","title":"2c Temporal Model: Tutorial on synthetic data","text":"interesting fit model multiple synthetic catalogues compare parameters posterior distributions obtained different catalogues. section, going generate second synthetic catalogue, fit model, compare posterior distributions ones obtained . second catalogue impose large event magnitude \\(6\\) happening midpoint time interval. first step set data.frame known events generate second synthetic catalogue Counting number background events aftershocks case slightly different . fact, count imposed event background event, aftershocks need include also event gen = 0 ones induced imposed event case 192. comparison number events two catalogues. Notice background events roughly expected given time interval . , just need set data.frame model fitting. inputs can use ones created first model fit. Now, extract marginal posterior distributions, need create input_list second model fit. Now, can retrieve marginal posterior distributions provided model fitted second catalogue compare ones obtained .  process shown can extended multiple (\\(>2\\)) input catalogues order study parameters identifiable. Also, using characteristics input catalogue catalogue identifier can study change posterior distribution characteristic input catalogue changes. interesting example number events catalogue, studying marginal posterior distributions change increase decrease number events.","code":"# set up data.frame of imposed events Ht.imposed <- data.frame(   ts = mean(c(T1, T2)),   magnitudes = 6 ) # generate second catalogue set.seed(1) synth.cat.list.2 <- generate_temporal_ETAS_synthetic(   theta = true.param,   beta.p = beta.p,   M0 = M0,   T1 = T1,   T2 = T2,   Ht = Ht.imposed,   ncore = 1 ) # transform it in a data.frame synth.cat.df.2 <- do.call(rbind, synth.cat.list.2) sum(synth.cat.df.2$gen == 0) #> [1] 192 rbind(   first = c(     N = nrow(synth.cat.df),     N.bkg = sum(synth.cat.df$gen == 1),     N.after = sum(synth.cat.df$gen > 1)   ),   second = c(     N = nrow(synth.cat.df.2),     N.bkg = sum(synth.cat.df.2$gen == 1 | synth.cat.df.2$gen == -1),     N.after = sum(synth.cat.df.2$gen > 1 | synth.cat.df.2$gen == 0)   ) ) #>          N N.bkg N.after #> first  288   112     176 #> second 408   104     304 synth.cat.df.2 <- synth.cat.df.2[order(synth.cat.df.2$ts), ] synth.cat.df.2$idx.p <- seq_len(nrow(synth.cat.df.2))  synth.fit.2 <- Temporal.ETAS(   total.data = synth.cat.df.2,   M0 = M0,   T1 = T1,   T2 = T2,   link.functions = link.f,   coef.t. = 1,   delta.t. = 0.1,   N.max. = 5,   bru.opt = bru.opt.list ) #> Start creating grid...  #> Finished creating grid, time  0.784637 input_list.2 <- list(   model.fit = synth.fit.2,   link.functions = link.f ) # retrieve marginal posterior distributions post.list.2 <- get_posterior_param(input.list = input_list.2)  # set model identifier post.list$post.df$cat.used <- \"first catalogue\" post.list.2$post.df$cat.used <- \"second catalogue\"  # bind marginal posterior data.frames bind.post.df <- rbind(post.list$post.df, post.list.2$post.df)  # plot them ggplot(bind.post.df, aes(x = x, y = y, color = cat.used)) +   geom_line() +   facet_wrap(facets = ~param, scales = \"free\") +   xlab(\"param\") +   ylab(\"pdf\") +   geom_vline(     data = df.true.param,     mapping = aes(xintercept = x), linetype = 2   )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Francesco Serafini. Author, maintainer. Mark Naylor. Author, thesis advisor. Finn Lindgren. Author, thesis advisor.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Mark Naylor, & Francesco Serafini (2023). edinburgh-seismicity-hub/ETAS.inlabru: Temporal Hawkes (v1.0.1).  Zenodo. https://doi.org/10.5281/zenodo.7515785 Mark Naylor, Francesco Serafini, Finn Lindgren (2023). doi:10.3389/fams.2023.1126759, https://www.frontiersin.org/articles/10.3389/fams.2023.1126759 Francesco Serafini, Finn Lindgren, Mark Naylor (2023). doi:10.1002/env.2798, https://onlinelibrary.wiley.com/doi/abs/10.1002/env.2798","code":"@Misc{,   title = {edinburgh-seismicity-hub/ETAS.inlabru: Temporal Hawkes},   author = {Mark Naylor and Francesco Serafini},   publisher = {Zenodo},   year = {2023},   number = {v1.0.1},   url = {https://doi.org/10.5281/zenodo.7515785},   doi = {10.5281/zenodo.7515785}, } @Article{,   title = {Bayesian modelling of the temporal evolution of seismicity using the ETAS.inlabru R-package},   author = {Mark Naylor and Francesco Serafini and Finn Lindgren},   journal = {Frontiers in Applied Mathematics and Statistics},   year = {2023},   doi = {10.3389/fams.2023.1126759},   url = {https://www.frontiersin.org/articles/10.3389/fams.2023.1126759}, } @Article{,   title = {Approximation of Bayesian Hawkes process with inlabru},   author = {{Serafini} and {Francesco} and {Lindgren} and {Finn} and {Naylor} and {Mark}},   journal = {Environmetrics},   year = {2023},   doi = {10.1002/env.2798},   url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/env.2798}, }"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"etasinlabru","dir":"","previous_headings":"","what":"Bayesian ETAS model for modelling seismic sequences with inlabru","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"R package implements ETAS Hawkes process modelling seismicity Online documentation: https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"authors","dir":"","previous_headings":"","what":"Authors","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"Dr Francesco Serafini Dr Mark Naylor , School GeoSciences, University Edinburgh Prof Finn Lindgren , School Mathematics, University Edinburgh Dr Kirsty Bayliss , Global Earthquake Model (GEM)","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"funding","dir":"","previous_headings":"","what":"Funding","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"study funded yhe Real-Time Earthquake Risk Reduction Resilient Europe RISE project , received funding European Union’s Horizon 2020 Research Innovation Program grant Agreement 821115. Naylor additionally funded NSFGEO-NERC grant NE/R000794/1. Bayliss funded EPSRC Studentship.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"ETAS.inlabru work, need install R-INLA inlabru: inlabru (see https://inlabru-org.github.io/inlabru/): CRAN release, development version, R-INLA (see https://www.r-inla.org/download-install): can install development version ETAS.inlabru GitHub ","code":"install.packages(\"inlabru\") # install.packages(\"remotes\") remotes::install_github(\"inlabru-org/inlabru\") install.packages(   \"INLA\",   repos = c(getOption(\"repos\"), INLA=\"https://inla.r-inla-download.org/R/testing\"),   dep = TRUE ) # install.packages(\"remotes\") remotes::install_github(\"edinburgh-seismicity-hub/ETAS.inlabru\")"},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"file-structure-in-package","dir":"","previous_headings":"Terminology and planning suggestions","what":"File structure in package","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"ETAS.triggering.function.R : Contains ETAS specific model functions HawkesProcess.R : Generic Hawkes code intended integration back inlabru generateSyntheticCatalogues.R : Contains iterative Hawkes functions generating triggered events actual triggering functions reside ETAS file introduce models temporalBinning.R : Code generate time bins make integration scheme efficient plottingFunctions.R : lets put standard plotting functions setupInlabruInputs.R : Put functions generating input.list ","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"terminology","dir":"","previous_headings":"","what":"Terminology","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"Let’s specific just temporal clear function names spatial spatial-temporal later Might anything bad? tried modify just theta","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"implemented","dir":"","previous_headings":"","what":"Implemented","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"Generation synthetic ETAS catalogues ETAS.inlabru demonstration notebook","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"in-development","dir":"","previous_headings":"","what":"In development","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"Add inversion modelling based original code Modify implementation generic Hawkes code can go inlabru ETAS triggering function code stay package Implement time varying incompleteness model Farnaz Kamranzad","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/index.html","id":"roadmap","dir":"","previous_headings":"","what":"Roadmap","title":"Bayesian ETAS model for modelling seismic sequences with inlabru","text":"Implement incompleteness fix Integrate spatial modelling","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/ETAS.inlabru-package.html","id":null,"dir":"Reference","previous_headings":"","what":"ETAS.inlabru: Bayesian ETAS model for modelling seismic sequences with inlabru — ETAS.inlabru-package","title":"ETAS.inlabru: Bayesian ETAS model for modelling seismic sequences with inlabru — ETAS.inlabru-package","text":"Modelling inversion ETAS model seismicity using inlabru Epidemic Type Aftershock Sequence (ETAS) model designed model earthquakes triggered previous events. statistics, referred Hawkes process. code can used generate synthetic ETAS catalogues can also include seeded events model specific sequences. also implement Bayesian inversion scheme using Integrated Nested Laplace Approximation (INLA) using inlabru. temporal model, given training catalogue times magnitudes, code returns joint posteriors ETAS parameters. future roadmap, include tools model spatial distribution spatio-temporal evolution seismic sequences.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/ETAS.inlabru-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"ETAS.inlabru: Bayesian ETAS model for modelling seismic sequences with inlabru — ETAS.inlabru-package","text":"Maintainer: Francesco Serafini francesco.serafini@newcastle.ac.uk (ORCID) Authors: Mark Naylor mark.naylor@ed.ac.uk (ORCID) [thesis advisor] Finn Lindgren Finn.Lindgren@ed.ac.uk (ORCID) [thesis advisor]","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/IntInjectionIntensity.html","id":null,"dir":"Reference","previous_headings":"","what":"Injection Rate function calculations — IntInjectionIntensity","title":"Injection Rate function calculations — IntInjectionIntensity","text":"Forward time integrated function exponential rate decay, inverse","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/IntInjectionIntensity.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Injection Rate function calculations — IntInjectionIntensity","text":"","code":"IntInjectionIntensity(a = 50, V.i = 1, tau = 10, T.i, T2)  Inv_IntInjectionIntensity(   a = 50,   V.i = 1,   tau = 10,   T.i,   number.injected.events )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/IntInjectionIntensity.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Injection Rate function calculations — IntInjectionIntensity","text":"Event rate per unit volume injected V.Injected volume tau Decay rate [days] T.Time injection event T2 End temporal model domain number.injected.events number expected injected events, used inverse.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/IntInjectionIntensity.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Injection Rate function calculations — IntInjectionIntensity","text":"IntInjectionIntensity returns forward time integrated function exponential rate decay. Inv_IntInjectionIntensity returns end time corresponding given expected number injected events.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Int_ETAS_time_trig_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Integrated Omori's law — Int_ETAS_time_trig_function","title":"Integrated Omori's law — Int_ETAS_time_trig_function","text":"Integrated Omori's law","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Int_ETAS_time_trig_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Integrated Omori's law — Int_ETAS_time_trig_function","text":"","code":"Int_ETAS_time_trig_function(theta, th, T2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Int_ETAS_time_trig_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Integrated Omori's law — Int_ETAS_time_trig_function","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p) th Time past event [days] start temporal domain, vector. T2 End temporal domain, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Int_ETAS_time_trig_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Integrated Omori's law — Int_ETAS_time_trig_function","text":"Value integral Omori's law","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Int_ETAS_time_trig_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Integrated Omori's law — Int_ETAS_time_trig_function","text":"function returns integral Omori's law, namely $$\\int_{t_h}^{T_2} \\left(\\frac{t - t_h}{c} + 1\\right)^{-p} dt$$","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Inv_Int_ETAS_time_trig_function.html","id":null,"dir":"Reference","previous_headings":"","what":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","title":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","text":"Inverse integrated Omori's law","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Inv_Int_ETAS_time_trig_function.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","text":"","code":"Inv_Int_ETAS_time_trig_function(theta, omega, th)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Inv_Int_ETAS_time_trig_function.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p) omega Value integral inverted, vector th Time integral calculated scalar","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Inv_Int_ETAS_time_trig_function.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","text":"Value start temporal domain used calculate integral","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Inv_Int_ETAS_time_trig_function.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Inverse of integrated Omori's law — Inv_Int_ETAS_time_trig_function","text":"Considering integral Omori's law $$\\omega = \\int_{t_h}^{T_2}\\left(\\frac{t - t_h}{c} + 1\\right)^{-p} dt$$ function applied value \\(\\omega\\) returns value \\(t_h\\).","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/It_df.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate the integral of Omori's law — It_df","title":"Function to calculate the integral of Omori's law — It_df","text":"Function calculate integral Omori's law","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/It_df.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate the integral of Omori's law — It_df","text":"","code":"It_df(param_, time.df)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/It_df.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate the integral of Omori's law — It_df","text":"param_ ETAS parameters vector (\\(\\mu, K, \\alpha, c, p\\)), \\(c, p\\) used. time.df output function time_grid()","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/It_df.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to calculate the integral of Omori's law — It_df","text":"vector integral values bin provided time.df","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.fit.html","id":null,"dir":"Reference","previous_headings":"","what":"Fits the remporal ETAS model and returns the results. This function decomposes the input.list for the `Hawkes.bru2`` function. — Temporal.ETAS.fit","title":"Fits the remporal ETAS model and returns the results. This function decomposes the input.list for the `Hawkes.bru2`` function. — Temporal.ETAS.fit","text":"Fits remporal ETAS model returns results. function decomposes input.list `Hawkes.bru2`` function.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.fit.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fits the remporal ETAS model and returns the results. This function decomposes the input.list for the `Hawkes.bru2`` function. — Temporal.ETAS.fit","text":"","code":"Temporal.ETAS.fit(input.list)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.fit.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fits the remporal ETAS model and returns the results. This function decomposes the input.list for the `Hawkes.bru2`` function. — Temporal.ETAS.fit","text":"input.list input data parameters passed inlabru via structured list. output function create_input_list_temporal_withCatalogue create_input_list_temporal_noCatalogue","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.fit.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fits the remporal ETAS model and returns the results. This function decomposes the input.list for the `Hawkes.bru2`` function. — Temporal.ETAS.fit","text":"fitted model bru object, list","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.forecast.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — Temporal.ETAS.forecast","title":"Title — Temporal.ETAS.forecast","text":"Title","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.forecast.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — Temporal.ETAS.forecast","text":"","code":"Temporal.ETAS.forecast(post.samp, n.cat, beta.p, M0, T1, T2, Ht, ncore = 1)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.forecast.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — Temporal.ETAS.forecast","text":"post.samp data.frame containing samples posterior distribution ETAS parameters. row data.frame corresponds different sample parameters order \\(\\mu\\), \\(K\\), \\(\\alpha\\), \\(c\\), \\(p\\). n.cat number synthetic catalogues composing forecast. n.cat greater nrow(post.samp), , n.cat rows sampled uniformly replacement post.samp. n.cat smaller nrow(post.samp), , n.cat rows sampled uniformly without replacement post.samp. n.cat NULL equal nrow(post.samp), post.samp used nrow(post.samp) catalogues generated. beta.p parameter magnitude distribution M0 cutoff magnitude, synthetic events magnitude greater value. T1 starting time forecast T2 end time forecast Ht set known events ncore number cores used generate synthetic catalogues parallel.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.forecast.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — Temporal.ETAS.forecast","text":"list two elements: fore.df data.frame containing synthetic catalogues composing forecast. data.frame four columns, ts occurrence time, magnitudes magnitude, gen generation event, cat.idx catalogue identifier second element output list n.cat number synthetic catalogues generated.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to fit Hawkes process model — Temporal.ETAS","title":"Function to fit Hawkes process model — Temporal.ETAS","text":"function fit temporal ETAS model using inlabru.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to fit Hawkes process model — Temporal.ETAS","text":"","code":"Temporal.ETAS(   total.data,   M0,   T1,   T2,   link.functions = NULL,   coef.t.,   delta.t.,   N.max.,   bru.opt )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to fit Hawkes process model — Temporal.ETAS","text":"total.data Observed events: data.frame columns time (ts), magnitude (magnitudes), event identifier (idx.p). Column names must changed. M0 Minimum magnitude threshold, scalar T1 Start temporal model domain, scalar [measure unit sample.s$ts]. T2 End temporal model domain, scalar [measure unit sample.s$ts]. link.functions Functions transform parameters internal INLA scale ETAS scale. must list functions names (mu, K, alpha, c_, p) coef.t. TimeBinning parameter: parameter regulating relative length successive bins, scalar. delta.t. TimeBinning parameter: parameter regulating bins' width, scalar. N.max. TimeBinning parameter: parameter regulating Number bins (= N.max + 2), scalar. bru.opt Runtime options inlabru: See https://inlabru-org.github.io/inlabru/reference/bru_call_options.html, list","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/Temporal.ETAS.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to fit Hawkes process model — Temporal.ETAS","text":"fitted model 'bru' object, list","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":null,"dir":"Reference","previous_headings":"","what":"Find breaks point for 1D grid — breaks_exp","title":"Find breaks point for 1D grid — breaks_exp","text":"breaks_exp return breaks points one dimensional grid depending three parameters, see details","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Find breaks point for 1D grid — breaks_exp","text":"","code":"breaks_exp(start.grid, end.grid, coef.t = 2, delta.t, N.exp. = 10)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Find breaks point for 1D grid — breaks_exp","text":"start.grid Starting point grid, scalar. end.grid End point grid, scalar. coef.t TimeBinning parameter: \\(\\delta > 0\\) determines relative length subsequent intervals, scalar. delta.t TimeBinning parameter: \\(\\Delta > 0\\) determines length intervals, scalar. N.exp. TimeBinning parameter: \\(n_{max} >0\\) determines maximum number intervals, scalar","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Find breaks point for 1D grid — breaks_exp","text":"vector containing grid points","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Find breaks point for 1D grid — breaks_exp","text":"grid calculated follows $$t, t + \\Delta, t + \\Delta(1 + \\delta), t + \\Delta(1 + \\delta)^2,...., T$$ \\(t\\) start.grid argument, \\(T\\) end.grid argument, \\(n_{max}\\) maximum value exponent","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/breaks_exp.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Find breaks point for 1D grid — breaks_exp","text":"","code":"breaks_exp(start.grid = 1, end.grid = 100, coef.t = 1, delta.t = 1, N.exp. = 3) #> [1]   1   2   3   5   9 100 breaks_exp(start.grid = 1, end.grid = 100, coef.t = 1, delta.t = 1, N.exp. = 10) #> [1]   1   2   3   5   9  17  33  65 100"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/compute_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to compute the integral of Omori's law efficiently — compute_grid","title":"Function to compute the integral of Omori's law efficiently — compute_grid","text":"Function compute integral Omori's law efficiently","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/compute_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to compute the integral of Omori's law efficiently — compute_grid","text":"","code":"compute_grid(param., list.input_)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/compute_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to compute the integral of Omori's law efficiently — compute_grid","text":"param. ETAS parameters vector (\\(\\mu, K, \\alpha, c, p\\)), \\(c, p\\) used. list.input_ list containing information calculate integrals efficiently. list created inside Temporal.ETAS function Two elements used time.sel selection rows output time_grid unique t.ref_layer value, data.frame. Imapping mapper unique names provided time.sel original rows output time_grid(), vector.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/compute_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to compute the integral of Omori's law efficiently — compute_grid","text":"vector length list.input_$Imapping integral Omori's law bin.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/cond_lambda.html","id":null,"dir":"Reference","previous_headings":"","what":"ETAS conditional intensity - used by inlabru — cond_lambda","title":"ETAS conditional intensity - used by inlabru — cond_lambda","text":"Function calculate value ETAS model conditional intensity specified time given history process.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/cond_lambda.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ETAS conditional intensity - used by inlabru — cond_lambda","text":"","code":"cond_lambda(theta, t, th, mh, M0)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/cond_lambda.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ETAS conditional intensity - used by inlabru — cond_lambda","text":"theta ETAS parameters list names mu, K, alpha, c, p t Time conditional intensity evaluated, scalar th Time events history process, vector mh Magnitudes events history process, vector M0 Minimum magnitude threshold","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/cond_lambda.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ETAS conditional intensity - used by inlabru — cond_lambda","text":"Value ETAS conditional intensity calculated t history th, mh, scalar","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/cond_lambda.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ETAS conditional intensity - used by inlabru — cond_lambda","text":"function takes single value t returns ETAS conditional intensity calculated t history th, mh. ETAS conditional intensity given $$\\lambda(t | \\mathcal H_t) = \\mu + \\sum_{h: (t_h,m_h) \\\\mathcal H_t} K e^{\\alpha(m_h - M_0)} \\left( \\frac{t - t_h}{c} + 1\\right)^{-p}$$ use t vector.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_noCatalogue.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","title":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","text":"Function create default input list ETAS Hawkes temporal model catalogue specified input file","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_noCatalogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","text":"","code":"create_input_list_temporal_noCatalogue(input_path, num.threads = NULL)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_noCatalogue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","text":"input_path Input file path string num.threads Optional argument number threads used parallel processing","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_noCatalogue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","text":"formatted input.list elements required temporal Hawkes model","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_noCatalogue.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Function to create a default input list for the ETAS Hawkes temporal model where no catalogue is specified in the input file — create_input_list_temporal_noCatalogue","text":"","code":"create_input_list_temporal_noCatalogue(   system.file(\"extdata\", \"user_input_synthetic_noCatalogue.txt\", package = \"ETAS.inlabru\") ) #> $catalog #> NULL #>  #> $catalog.bru #> NULL #>  #> $time.int #> NULL #>  #> $T12 #> [1] \"T1\"  \" T2\" #>  #> $lat.int #> [1] -90  90 #>  #> $lon.int #> [1] -180  180 #>  #> $M0 #> NULL #>  #> $mu.init #> [1] 0.25 #>  #> $K.init #> [1] 0.3 #>  #> $alpha.init #> [1] 1.6 #>  #> $c.init #> [1] 0.2 #>  #> $p.init #> [1] 1.1 #>  #> $a_mu #> [1] 0.5 #>  #> $b_mu #> [1] 0.5 #>  #> $a_K #> [1] -1 #>  #> $b_K #> [1] 0.5 #>  #> $a_alpha #> [1] 0 #>  #> $b_alpha #> [1] 10 #>  #> $a_c #> [1] 0 #>  #> $b_c #> [1] 1 #>  #> $a_p #> [1] 1 #>  #> $b_p #> [1] 2 #>  #> $max_iter #> [1] 100 #>  #> $max_step #> NULL #>  #> $link.functions #> $link.functions$mu #> function (x)  #> gamma_t(x, a_mu, b_mu) #> <bytecode: 0x55847900beb0> #> <environment: 0x55847900e700> #>  #> $link.functions$K #> function (x)  #> loggaus_t(x, a_K, b_K) #> <bytecode: 0x55847900bbd8> #> <environment: 0x55847900e700> #>  #> $link.functions$alpha #> function (x)  #> unif_t(x, a_alpha, b_alpha) #> <bytecode: 0x55847900b900> #> <environment: 0x55847900e700> #>  #> $link.functions$c_ #> function (x)  #> unif_t(x, a_c, b_c) #> <bytecode: 0x55847900b628> #> <environment: 0x55847900e700> #>  #> $link.functions$p #> function (x)  #> unif_t(x, a_p, b_p) #> <bytecode: 0x55847900b350> #> <environment: 0x55847900e700> #>  #>  #> $bru.opt.list #> $bru.opt.list$bru_verbose #> [1] 3 #>  #> $bru.opt.list$bru_max_iter #> [1] 100 #>  #> $bru.opt.list$num.threads #> NULL #>  #> $bru.opt.list$bru_initial #> $bru.opt.list$bru_initial$th.mu #> [1] -0.2978078 #>  #> $bru.opt.list$bru_initial$th.K #> [1] -0.4079456 #>  #> $bru.opt.list$bru_initial$th.alpha #> [1] -0.9944579 #>  #> $bru.opt.list$bru_initial$th.c #> [1] -0.8416212 #>  #> $bru.opt.list$bru_initial$th.p #> [1] -1.281552 #>  #>  #>  #> $coef.t #> [1] 1 #>  #> $delta.t #> [1] 0.1 #>  #> $Nmax #> [1] 8 #>  #> $n.periods #> [1] 120 #>  #> $period.length #> [1] 1 #>  #> $start.date.fore #> NULL #>  #> $magnitude.update #> [1] 5.5 #>  #> $output.name #> [1] \"report_ETAS\" #>"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_withCatalogue.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to create a default input file for the ETAS Hawkes temporal model where a catalogue is specified in the input file. — create_input_list_temporal_withCatalogue","title":"Function to create a default input file for the ETAS Hawkes temporal model where a catalogue is specified in the input file. — create_input_list_temporal_withCatalogue","text":"Function create default input file ETAS Hawkes temporal model catalogue specified input file.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_withCatalogue.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to create a default input file for the ETAS Hawkes temporal model where a catalogue is specified in the input file. — create_input_list_temporal_withCatalogue","text":"","code":"create_input_list_temporal_withCatalogue(input_path, num.threads = NULL)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_withCatalogue.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to create a default input file for the ETAS Hawkes temporal model where a catalogue is specified in the input file. — create_input_list_temporal_withCatalogue","text":"input_path path txt file containing experiment's information num.threads Optional argument number threads used parallel processing","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/create_input_list_temporal_withCatalogue.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to create a default input file for the ETAS Hawkes temporal model where a catalogue is specified in the input file. — create_input_list_temporal_withCatalogue","text":"formatted input.list elements required temporal Hawkes model","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/exp_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from a standard Normal distribution to an Exponential distribution — exp_t","title":"Copula transformation from a standard Normal distribution to an Exponential distribution — exp_t","text":"Copula transformation standard Normal distribution Exponential distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/exp_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from a standard Normal distribution to an Exponential distribution — exp_t","text":"","code":"exp_t(x, r)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/exp_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from a standard Normal distribution to an Exponential distribution — exp_t","text":"x values standard Normal distribution, vector. r rate exponential distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/exp_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from a standard Normal distribution to an Exponential distribution — exp_t","text":"values Exponential distribution rate r, vector length x.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gamma_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from a standard Normal distribution to a Gamma distribution — gamma_t","title":"Copula transformation from a standard Normal distribution to a Gamma distribution — gamma_t","text":"Copula transformation standard Normal distribution Gamma distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gamma_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from a standard Normal distribution to a Gamma distribution — gamma_t","text":"","code":"gamma_t(x, a, b)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gamma_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from a standard Normal distribution to a Gamma distribution — gamma_t","text":"x values standard Normal distribution, vector. shape parameter gamma distribution scalar. b rate parameter gamma distribution scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gamma_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from a standard Normal distribution to a Gamma distribution — gamma_t","text":"values Gamma distribution shape rate b, vector length x.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/generate_temporal_ETAS_synthetic.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","title":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","text":"Generates synthetic catalogue using ETAS model","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/generate_temporal_ETAS_synthetic.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","text":"","code":"generate_temporal_ETAS_synthetic(   theta,   beta.p,   M0,   T1,   T2,   Ht = NULL,   ncore = 1,   format = \"list\" )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/generate_temporal_ETAS_synthetic.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p). beta.p Slope GR relation: beta = b ln(10). M0 minimum magnitude synthetic catalogue. T1 start time synthetic catalogue [days]. T2 end time synthetic catalogue [days]. Ht catalogue history impose synthetic sequence. ncore Integer number compute cores use. format \"list\", return list data.frame objects, one generation. \"df\", return data.frame list element joined single data.frame, ordered ts","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/generate_temporal_ETAS_synthetic.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","text":"list data.frame objects temporal catalogue columns [ts, magnitudes, gen] , ts times t_i, magnitudes magnitudes M_i, gen includes information generation number, gen_i. join time-ordered data.frame,   ","code":"cata <- generate_temporal_ETAS_synthetic(...) cata <- dplyr::bind_rows(cata) cata <- dplyr::arrange(cata, ts) cata <- generate_temporal_ETAS_synthetic(..., format = \"df\")"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/generate_temporal_ETAS_synthetic.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates a synthetic catalogue using the ETAS model — generate_temporal_ETAS_synthetic","text":"","code":"## EXAMPLE 1: Generate a 1000 day synthetic ETAS catalogue  generate_temporal_ETAS_synthetic(   theta = list(mu = 0.1, K = 0.089, alpha = 2.29, c = 0.11, p = 1.08),   beta.p = log(10),   M0 = 2.5,   T1 = 0, T2 = 1000 ) #> [[1]] #>           ts magnitudes gen #> 1  768.94288   2.914907   1 #> 2  343.24267   2.867387   1 #> 3  738.66547   3.194602   1 #> 4  108.26704   2.518561   1 #> 5  867.82367   3.625826   1 #> 6  414.88712   3.008329   1 #> 7  812.87292   2.547728   1 #> 8   40.48613   2.701251   1 #> 9  302.47906   3.375942   1 #> 10 106.38470   2.753569   1 #> 11 408.06406   3.428480   1 #> 12 494.06665   2.817480   1 #> 13 966.52894   3.002823   1 #> 14  60.95371   2.650849   1 #> 15 475.72108   3.144826   1 #> 16 908.43401   2.658247   1 #> 17 499.19728   2.955842   1 #> 18 213.75351   2.516805   1 #> 19 949.68692   2.950718   1 #> 20  45.57655   2.920412   1 #> 21 194.50902   2.538381   1 #> 22  59.64472   3.090420   1 #> 23 844.23265   2.953326   1 #> 24 999.90696   2.565290   1 #> 25 166.89891   2.584367   1 #> 26 864.24059   2.970848   1 #> 27 252.80563   2.660037   1 #> 28 365.85365   2.512064   1 #> 29 664.47738   2.707932   1 #> 30 396.26655   2.807730   1 #> 31 456.09287   2.992743   1 #> 32 477.28202   3.782399   1 #> 33 982.13470   3.035147   1 #> 34 278.19211   3.840254   1 #> 35 254.60423   3.115541   1 #> 36 469.56218   3.592450   1 #> 37 486.34192   2.700479   1 #> 38 195.05290   3.142409   1 #> 39 226.74433   2.614344   1 #> 40 152.32931   2.724616   1 #> 41 137.86613   2.987232   1 #> 42 518.59169   2.527105   1 #> 43 829.25144   2.826389   1 #> 44 637.01892   2.837931   1 #> 45 586.63989   3.378862   1 #> 46 307.91627   2.554206   1 #> 47 199.69977   2.795357   1 #> 48 344.60511   2.825597   1 #> 49 496.74651   2.725747   1 #> 50 866.51108   2.821058   1 #> 51 685.54766   3.084814   1 #> 52  50.94860   2.777734   1 #> 53 310.63062   2.556011   1 #> 54  88.60022   2.897186   1 #> 55 377.06210   2.911928   1 #> 56 982.37554   2.895771   1 #> 57 773.73164   3.472748   1 #> 58  84.28980   2.646058   1 #> 59  57.70424   2.686735   1 #> 60 804.55752   2.504752   1 #> 61 852.42084   3.111845   1 #> 62 201.14365   2.637924   1 #> 63 548.55729   2.603352   1 #> 64 129.78938   2.913046   1 #> 65  25.02077   2.701317   1 #> 66 718.98609   2.989109   1 #> 67 181.79995   2.647752   1 #> 68 888.75215   3.007088   1 #> 69  56.07339   3.627920   1 #> 70 387.00343   2.667610   1 #> 71 326.87180   2.693218   1 #> 72 332.72041   3.805017   1 #> 73 644.09652   2.691397   1 #> 74 320.01841   2.574990   1 #> 75 769.57481   2.708469   1 #> 76 853.46595   2.598815   1 #> 77 419.65011   3.313624   1 #> 78 722.72942   2.921434   1 #> 79 276.84660   2.778897   1 #> 80 227.60863   2.812437   1 #> 81 560.07609   2.946377   1 #> 82 857.70515   2.637104   1 #> 83 735.04175   2.513344   1 #> 84 997.86756   2.544444   1 #> 85 380.57601   2.697106   1 #> 86 746.25492   3.069314   1 #> 87 689.74477   2.608214   1 #> 88 454.36657   2.852483   1 #> 89  65.07985   3.360735   1 #> 90 626.69282   2.813992   1 #> 91 795.39773   2.824555   1 #> 92 508.24424   3.225807   1 #> 93 382.24734   2.790374   1 #> 94 830.78594   2.931449   1 #> 95  57.82214   2.601453   1 #> 96 977.87349   2.503373   1 #> 97  43.43726   3.093694   1 #> 98 655.60984   2.602934   1 #>  #> [[2]] #>           ts magnitudes gen #> 1  740.81987   3.225781   2 #> 2  902.57022   2.625820   2 #> 3  546.07828   2.516313   2 #> 4  233.96877   3.309097   2 #> 5  844.27115   3.671799   2 #> 6  951.20665   3.983780   2 #> 7  864.55918   2.653189   2 #> 8  293.91186   2.916203   2 #> 9  463.12213   2.538033   2 #> 10 278.20977   2.970762   2 #> 11 282.65627   2.908542   2 #> 12 215.70722   2.585807   2 #> 13  56.35975   2.934514   2 #> 14 333.95691   3.783545   2 #> 15 851.89747   3.609388   2 #> 16  44.50742   3.137553   2 #>  #> [[3]] #>           ts magnitudes gen #> 1  781.28771   3.261869   3 #> 2  241.79718   2.559793   3 #> 3  845.62057   2.531844   3 #> 4  926.33790   2.653817   3 #> 5  953.70500   2.977551   3 #> 6  865.75028   2.562467   3 #> 7   56.37735   2.629755   3 #> 8  461.05530   2.879793   3 #> 9  572.19931   3.502518   3 #> 10 334.01469   2.653366   3 #> 11 864.21496   2.542116   3 #>  #> [[4]] #>         ts magnitudes gen #> 1 781.4972   3.810396   4 #> 2 592.7480   2.647813   4 #> 3 868.5187   3.441938   4 #>    ## EXAMPLE 2: To generate a 1000 day catalogue including a M6.7 event on day 500  Ht <- data.frame(ts = c(500), magnitudes = c(6.7)) generate_temporal_ETAS_synthetic(   theta = list(mu = 0.1, K = 0.089, alpha = 2.29, c = 0.11, p = 1.08),   beta.p = log(10),   M0 = 2.5,   T1 = 0, T2 = 1000,   Ht = Ht ) #> [[1]] #>    ts magnitudes gen #> 1 500        6.7  -1 #>  #> [[2]] #>             ts magnitudes gen #> 1    500.54260   2.942775   0 #> 2    505.51297   2.542256   0 #> 3    500.09074   2.618118   0 #> 4    500.47080   2.776967   0 #> 5    500.03679   2.740408   0 #> 6    610.86048   2.770760   0 #> 7    504.74364   2.661295   0 #> 8    643.48785   2.784972   0 #> 9    500.32261   2.587885   0 #> 10   501.97714   2.771367   0 #> 11   501.49379   2.556601   0 #> 12   500.37933   3.175341   0 #> 13   730.17345   2.843446   0 #> 14   505.46370   2.505925   0 #> 15   500.34557   3.311499   0 #> 16   613.83767   2.614019   0 #> 17   500.03867   2.920726   0 #> 18   885.21250   2.554355   0 #> 19   502.11688   2.941102   0 #> 20   510.52842   2.632370   0 #> 21   500.18770   2.807659   0 #> 22   500.07612   2.725658   0 #> 23   550.68947   2.698872   0 #> 24   500.28485   2.523414   0 #> 25   500.38891   2.630402   0 #> 26   502.30722   3.468451   0 #> 27   500.25938   3.011877   0 #> 28   657.31990   4.256645   0 #> 29   535.93750   3.482552   0 #> 30   522.62509   2.815692   0 #> 31   506.66405   3.376475   0 #> 32   653.26271   2.890448   0 #> 33   502.32436   2.906998   0 #> 34   520.81893   2.682203   0 #> 35   727.11321   3.221627   0 #> 36   641.87605   2.555661   0 #> 37   513.75689   2.614706   0 #> 38   500.11537   3.618697   0 #> 39   500.03090   2.838405   0 #> 40   501.08868   2.933842   0 #> 41   500.21043   4.014930   0 #> 42   654.17292   3.005930   0 #> 43   500.09144   2.515241   0 #> 44   500.07335   3.553283   0 #> 45   500.19921   2.655839   0 #> 46   500.20030   3.874199   0 #> 47   502.33541   2.889587   0 #> 48   500.03992   3.239439   0 #> 49   500.45695   2.884322   0 #> 50   500.14603   3.246529   0 #> 51   500.14518   2.611367   0 #> 52   503.92845   3.877494   0 #> 53   727.59270   2.573042   0 #> 54   671.35201   2.608660   0 #> 55   504.66133   2.591619   0 #> 56   523.69142   2.535427   0 #> 57   548.78499   2.890774   0 #> 58   506.71208   2.818438   0 #> 59   501.31321   2.722857   0 #> 60   500.05448   2.945881   0 #> 61   500.49643   2.705082   0 #> 62   500.35226   2.621771   0 #> 63   551.81016   2.840560   0 #> 64   503.90200   2.620392   0 #> 65   500.48988   3.165379   0 #> 66   502.17534   2.561140   0 #> 67   506.17509   2.662693   0 #> 68   518.88567   3.001548   0 #> 69   506.22579   2.606813   0 #> 70   501.44457   2.808409   0 #> 71   503.53479   2.715349   0 #> 72   505.66563   3.047450   0 #> 73   571.99564   3.151850   0 #> 74   504.20911   2.614318   0 #> 75   620.23865   2.611629   0 #> 76   500.59304   2.537302   0 #> 77   527.51507   2.767663   0 #> 78   558.79059   2.753650   0 #> 79   500.01082   2.541595   0 #> 80   501.06962   2.572060   0 #> 81   500.09937   2.501024   0 #> 82   503.22788   2.581983   0 #> 83   758.87831   2.542271   0 #> 84   571.60876   2.605955   0 #> 85   500.26872   3.633054   0 #> 86   502.83002   2.647009   0 #> 87   512.59068   2.622685   0 #> 88   500.08580   2.996034   0 #> 89   500.79926   3.534751   0 #> 90   517.47285   2.569394   0 #> 91   506.83141   3.113642   0 #> 92   509.48082   4.320441   0 #> 93   508.47556   3.202597   0 #> 94   523.79909   2.540712   0 #> 95   503.05109   2.785447   0 #> 96   500.58578   2.655431   0 #> 97   501.80205   2.820269   0 #> 98   500.14628   3.457911   0 #> 99   638.72550   2.798294   0 #> 100  672.81880   2.718635   0 #> 101  927.09874   2.565721   0 #> 102  507.94520   3.007938   0 #> 103  505.14336   2.625373   0 #> 104  510.35283   3.031201   0 #> 105  503.96797   3.343291   0 #> 106  500.21729   2.691090   0 #> 107  500.52301   2.737381   0 #> 108  501.06111   2.639046   0 #> 109  501.73665   2.920921   0 #> 110  505.84254   2.543038   0 #> 111  598.35243   3.246399   0 #> 112  819.69745   2.607739   0 #> 113  501.68957   3.466243   0 #> 114  500.02320   3.031629   0 #> 115  820.51040   2.630268   0 #> 116  532.05469   2.937009   0 #> 117  551.10569   3.406733   0 #> 118  500.09737   2.587183   0 #> 119  500.26821   2.646868   0 #> 120  501.02594   2.667567   0 #> 121  513.84368   2.836719   0 #> 122  502.10688   2.979212   0 #> 123  621.62402   2.622160   0 #> 124  500.11290   2.956086   0 #> 125  500.42295   2.772599   0 #> 126  505.88789   3.695033   0 #> 127  500.30706   2.865176   0 #> 128  502.17510   2.910468   0 #> 129  510.57091   2.738583   0 #> 130  501.48436   2.504822   0 #> 131  510.72275   3.362336   0 #> 132  502.77917   2.827273   0 #> 133  531.22487   3.311722   0 #> 134  500.05891   2.618295   0 #> 135  500.13216   2.797170   0 #> 136  512.37312   2.871878   0 #> 137  537.67413   3.070765   0 #> 138  500.25606   2.694620   0 #> 139  682.83339   2.606688   0 #> 140  500.04649   3.548090   0 #> 141  500.02035   2.691999   0 #> 142  505.02877   2.881111   0 #> 143  500.71161   4.012626   0 #> 144  615.90325   2.939741   0 #> 145  502.94530   2.649365   0 #> 146  515.41752   2.530902   0 #> 147  555.30266   2.588837   0 #> 148  640.03514   3.161373   0 #> 149  500.53509   2.967064   0 #> 150  504.05415   3.143554   0 #> 151  545.92308   3.951833   0 #> 152  502.10863   3.086401   0 #> 153  500.21318   3.317656   0 #> 154  500.75109   2.533272   0 #> 155  544.41842   2.905383   0 #> 156  501.79161   3.230135   0 #> 157  534.35199   3.249783   0 #> 158  505.29325   3.051782   0 #> 159  592.60866   2.570305   0 #> 160  520.17145   2.704631   0 #> 161  560.38837   2.636834   0 #> 162  500.34704   2.506928   0 #> 163  500.09168   3.238401   0 #> 164  500.22778   2.839834   0 #> 165  926.40742   2.768823   0 #> 166  502.49841   3.112095   0 #> 167  500.04358   3.347808   0 #> 168  500.39088   2.654770   0 #> 169  500.17073   2.962895   0 #> 170  500.47506   2.651062   0 #> 171  500.09265   3.211218   0 #> 172  500.27037   4.313982   0 #> 173  504.05450   3.187026   0 #> 174  501.45138   2.996519   0 #> 175  501.99214   3.402264   0 #> 176  517.72089   3.521530   0 #> 177  623.22923   3.209919   0 #> 178  524.72916   2.731417   0 #> 179  500.23360   2.581761   0 #> 180  506.92917   3.705137   0 #> 181  521.96195   4.792936   0 #> 182  506.78511   2.670712   0 #> 183  509.85097   2.628114   0 #> 184  501.98974   3.669920   0 #> 185  502.38056   2.571487   0 #> 186  545.38530   2.657266   0 #> 187  671.26919   2.812585   0 #> 188  502.09739   2.766179   0 #> 189  501.93616   3.278880   0 #> 190  694.83720   2.782585   0 #> 191  522.10165   3.728666   0 #> 192  501.47312   2.526795   0 #> 193  500.58804   2.967469   0 #> 194  689.82324   2.717300   0 #> 195  513.64022   3.112048   0 #> 196  501.49871   3.189331   0 #> 197  539.65149   2.884544   0 #> 198  500.91814   3.612143   0 #> 199  500.26506   2.557045   0 #> 200  509.56424   2.947982   0 #> 201  501.81440   2.693748   0 #> 202  640.88709   3.006931   0 #> 203  500.34311   2.570605   0 #> 204  529.55178   3.170802   0 #> 205  500.56931   2.633040   0 #> 206  625.50187   2.569569   0 #> 207  501.23490   2.739256   0 #> 208  659.16122   4.259124   0 #> 209  500.37978   2.556576   0 #> 210  504.45043   2.706034   0 #> 211  500.66888   2.646205   0 #> 212  500.01590   2.579388   0 #> 213  916.87268   2.891623   0 #> 214  504.56086   2.817034   0 #> 215  502.55345   2.657426   0 #> 216  584.32536   3.277384   0 #> 217  506.52400   2.692381   0 #> 218  504.96337   3.828399   0 #> 219  563.90580   2.539180   0 #> 220  519.95849   4.097566   0 #> 221  505.85117   3.770670   0 #> 222  500.53256   3.596162   0 #> 223  500.27029   3.546990   0 #> 224  513.43332   2.780595   0 #> 225  500.31638   3.224990   0 #> 226  500.53197   2.583819   0 #> 227  631.21676   3.348478   0 #> 228  922.22251   3.150075   0 #> 229  501.41653   3.064381   0 #> 230  500.03215   2.880421   0 #> 231  579.51259   2.722048   0 #> 232  500.28060   4.183387   0 #> 233  504.44231   2.508388   0 #> 234  500.56399   2.521829   0 #> 235  502.36943   3.236951   0 #> 236  521.73063   2.957332   0 #> 237  525.73826   2.576243   0 #> 238  689.24017   3.468915   0 #> 239  541.00665   2.717838   0 #> 240  500.05813   2.868379   0 #> 241  502.91014   3.124991   0 #> 242  696.56646   2.577152   0 #> 243  500.86799   2.848954   0 #> 244  500.78864   2.882123   0 #> 245  500.19114   2.524860   0 #> 246  501.77962   2.656101   0 #> 247  502.71028   2.855711   0 #> 248  505.08180   2.713785   0 #> 249  500.13546   2.923261   0 #> 250  500.11023   2.539110   0 #> 251  501.16959   2.707134   0 #> 252  610.02945   3.669640   0 #> 253  500.84799   2.623676   0 #> 254  500.54194   2.590502   0 #> 255  536.87790   2.878449   0 #> 256  503.10966   2.816548   0 #> 257  526.09902   2.586481   0 #> 258  500.16993   3.224518   0 #> 259  501.78548   2.564511   0 #> 260  501.83184   2.591919   0 #> 261  508.07491   3.028098   0 #> 262  501.17433   2.542862   0 #> 263  500.00021   2.556895   0 #> 264  507.54903   2.884974   0 #> 265  500.69998   2.574860   0 #> 266  500.20628   2.748637   0 #> 267  500.09726   3.148206   0 #> 268  500.95030   3.540811   0 #> 269  502.31487   2.867404   0 #> 270  540.54351   2.509278   0 #> 271  507.98297   2.766949   0 #> 272  568.51885   2.532388   0 #> 273  501.18728   2.692794   0 #> 274  509.68257   3.048457   0 #> 275  687.50994   3.005293   0 #> 276  500.29890   3.019189   0 #> 277  500.16596   2.663360   0 #> 278  515.84608   2.506067   0 #> 279  500.73952   2.560834   0 #> 280  500.47433   3.259643   0 #> 281  592.79845   2.520666   0 #> 282  501.93664   2.851825   0 #> 283  583.52918   2.510720   0 #> 284  780.45554   3.266540   0 #> 285  500.22687   2.718146   0 #> 286  503.10762   2.601174   0 #> 287  500.43394   2.549555   0 #> 288  534.25381   2.603609   0 #> 289  501.43141   2.511531   0 #> 290  500.03750   2.861123   0 #> 291  505.62856   3.672358   0 #> 292  500.07707   3.775932   0 #> 293  501.66866   2.792400   0 #> 294  505.80267   2.909001   0 #> 295  500.02116   3.546383   0 #> 296  506.11794   2.653167   0 #> 297  564.72995   3.064946   0 #> 298  842.46503   3.205734   0 #> 299  723.58252   2.582803   0 #> 300  500.05621   2.907482   0 #> 301  500.20158   3.292885   0 #> 302  500.74038   2.731278   0 #> 303  822.24614   2.531950   0 #> 304  643.70700   2.500232   0 #> 305  500.19909   2.662157   0 #> 306  601.96126   2.504556   0 #> 307  702.17890   2.646437   0 #> 308  544.21265   3.001196   0 #> 309  506.31553   2.679985   0 #> 310  801.97719   2.624786   0 #> 311  503.38898   3.386488   0 #> 312  500.07265   2.592820   0 #> 313  501.92781   2.547867   0 #> 314  502.89737   2.877870   0 #> 315  501.17143   2.627933   0 #> 316  505.11358   2.500445   0 #> 317  847.09367   2.690423   0 #> 318  507.26752   2.951163   0 #> 319  537.23913   2.918889   0 #> 320  512.24374   3.827511   0 #> 321  522.85912   3.965486   0 #> 322  500.50802   2.632552   0 #> 323  500.32239   2.709486   0 #> 324  507.88535   2.621086   0 #> 325  500.34630   4.670800   0 #> 326  722.64626   2.603553   0 #> 327  500.14407   3.266143   0 #> 328  750.13454   2.564250   0 #> 329  513.77031   2.708045   0 #> 330  514.14444   2.928676   0 #> 331  506.60218   2.923468   0 #> 332  523.61860   2.559553   0 #> 333  639.48080   3.092892   0 #> 334  779.73573   2.639322   0 #> 335  502.18354   3.149776   0 #> 336  503.59866   2.732521   0 #> 337  726.88770   3.518992   0 #> 338  532.82092   2.734536   0 #> 339  500.41784   2.610729   0 #> 340  506.53990   3.817959   0 #> 341  500.31722   2.805173   0 #> 342  500.14420   2.538187   0 #> 343  523.91009   2.650629   0 #> 344  504.94535   3.142734   0 #> 345  501.46382   3.303959   0 #> 346  677.91974   2.514581   0 #> 347  500.04353   2.780084   0 #> 348  512.30085   3.098807   0 #> 349  500.47980   2.810220   0 #> 350  502.56512   2.570308   0 #> 351  500.31909   2.674679   0 #> 352  504.11811   2.952474   0 #> 353  608.42761   3.213513   0 #> 354  591.26829   2.544172   0 #> 355  524.23529   2.725596   0 #> 356  500.24717   3.308297   0 #> 357  608.41755   2.554335   0 #> 358  500.98585   2.761633   0 #> 359  524.21387   3.143261   0 #> 360  945.92310   2.627966   0 #> 361  529.88297   2.656419   0 #> 362  511.77849   2.663711   0 #> 363  504.93502   2.575520   0 #> 364  530.09510   2.878214   0 #> 365  511.58511   3.348693   0 #> 366  720.25129   2.589422   0 #> 367  503.32086   2.830373   0 #> 368  500.04452   4.150405   0 #> 369  790.81394   2.790628   0 #> 370  500.84681   2.714527   0 #> 371  784.85808   2.865208   0 #> 372  501.14533   2.527782   0 #> 373  502.41760   2.968257   0 #> 374  510.81044   3.288933   0 #> 375  500.06417   2.809945   0 #> 376  587.28581   2.549711   0 #> 377  500.63765   3.223833   0 #> 378  500.26982   2.737603   0 #> 379  500.02910   2.536644   0 #> 380  658.62204   2.528636   0 #> 381  500.01868   2.691384   0 #> 382  500.70158   2.789378   0 #> 383  518.11354   2.711952   0 #> 384  765.29931   2.809103   0 #> 385  500.52492   2.626309   0 #> 386  501.91645   3.534843   0 #> 387  501.62137   2.532339   0 #> 388  503.41270   2.712930   0 #> 389  664.43501   3.055813   0 #> 390  507.61051   2.732627   0 #> 391  503.46505   3.143762   0 #> 392  510.87688   2.670156   0 #> 393  556.19969   2.571228   0 #> 394  500.03824   2.805959   0 #> 395  503.81440   2.914243   0 #> 396  500.01033   2.575910   0 #> 397  500.11516   2.817559   0 #> 398  500.12832   2.609793   0 #> 399  721.28947   3.024511   0 #> 400  524.44082   3.392023   0 #> 401  506.06246   2.721337   0 #> 402  744.09397   2.686641   0 #> 403  779.43305   2.617368   0 #> 404  500.16192   2.621224   0 #> 405  500.44019   2.817553   0 #> 406  500.08676   2.839042   0 #> 407  522.04814   2.579086   0 #> 408  827.49969   4.142922   0 #> 409  501.51667   3.223547   0 #> 410  558.72419   2.761477   0 #> 411  500.49495   2.624780   0 #> 412  500.05545   2.897836   0 #> 413  636.66566   2.983969   0 #> 414  500.03791   2.695200   0 #> 415  520.50484   2.701125   0 #> 416  565.08351   2.649174   0 #> 417  586.62395   2.742309   0 #> 418  503.22462   2.579624   0 #> 419  506.31221   2.811099   0 #> 420  501.75693   3.192523   0 #> 421  540.67785   4.358567   0 #> 422  731.68398   4.454930   0 #> 423  500.33517   2.542596   0 #> 424  500.09280   2.584717   0 #> 425  512.25638   2.671580   0 #> 426  528.85455   2.643463   0 #> 427  500.24940   2.508098   0 #> 428  500.12787   2.696949   0 #> 429  507.47639   3.195667   0 #> 430  500.04108   2.698812   0 #> 431  508.27250   3.806291   0 #> 432  500.46626   2.507603   0 #> 433  524.83575   2.733773   0 #> 434  500.00470   4.312831   0 #> 435  502.69689   2.918812   0 #> 436  503.49882   3.171199   0 #> 437  500.05820   2.818950   0 #> 438  811.68192   3.009875   0 #> 439  500.50792   3.138176   0 #> 440  506.80692   3.366526   0 #> 441  500.15740   2.527527   0 #> 442  500.17526   2.788523   0 #> 443  702.58205   3.327294   0 #> 444  500.10460   2.847122   0 #> 445  500.02560   2.628030   0 #> 446  500.16157   2.557473   0 #> 447  500.31132   2.514448   0 #> 448  501.01691   2.521432   0 #> 449  562.68585   2.958858   0 #> 450  524.04585   2.611364   0 #> 451  957.24371   3.036529   0 #> 452  693.14607   2.809287   0 #> 453  582.34244   2.820942   0 #> 454  583.16033   4.277467   0 #> 455  655.80046   2.625227   0 #> 456  500.74841   2.580956   0 #> 457  547.84088   3.480513   0 #> 458  503.30440   2.593362   0 #> 459  512.83650   3.171606   0 #> 460  500.32155   3.260873   0 #> 461  502.20999   2.795632   0 #> 462  507.14051   3.101714   0 #> 463  518.06187   3.244041   0 #> 464  938.30695   2.723811   0 #> 465  539.15879   3.875263   0 #> 466  508.23386   2.811421   0 #> 467  811.17322   3.679038   0 #> 468  500.43801   2.511444   0 #> 469  502.62295   2.866298   0 #> 470  501.23753   2.503660   0 #> 471  551.65054   3.351680   0 #> 472  500.22362   2.908773   0 #> 473  500.95205   2.574619   0 #> 474  502.59276   2.613066   0 #> 475  812.95311   2.765807   0 #> 476  522.64946   2.660255   0 #> 477  500.24283   2.560722   0 #> 478  824.45556   2.924970   0 #> 479  759.73033   3.169900   0 #> 480  622.45869   2.767023   0 #> 481  514.00706   2.546769   0 #> 482  504.83737   2.564503   0 #> 483  522.67876   2.607673   0 #> 484  650.01702   2.694865   0 #> 485  512.99538   3.580674   0 #> 486  500.01053   4.382511   0 #> 487  501.43761   4.017016   0 #> 488  501.53945   2.576790   0 #> 489  509.43059   2.798350   0 #> 490  501.66217   2.877282   0 #> 491  519.05862   3.963275   0 #> 492  501.25327   2.974117   0 #> 493  506.47901   2.635596   0 #> 494  512.38630   3.266064   0 #> 495  500.02824   3.868476   0 #> 496  500.16809   2.571375   0 #> 497  500.74785   2.770579   0 #> 498  500.18941   2.519021   0 #> 499  500.30568   3.129993   0 #> 500  500.19073   2.538677   0 #> 501  500.18776   2.916423   0 #> 502  563.52970   2.630585   0 #> 503  500.48455   2.645273   0 #> 504  507.06828   2.988290   0 #> 505  663.54886   2.958043   0 #> 506  500.16309   2.521514   0 #> 507  500.01104   3.071066   0 #> 508  673.93325   3.112480   0 #> 509  593.99489   2.511860   0 #> 510  829.87370   2.758950   0 #> 511  519.91249   2.536523   0 #> 512  615.34011   2.564428   0 #> 513  500.96815   2.589241   0 #> 514  792.91022   3.516457   0 #> 515  710.42602   2.868740   0 #> 516  500.05131   2.743139   0 #> 517  950.44309   2.774686   0 #> 518  501.32449   2.927015   0 #> 519  501.30520   2.722266   0 #> 520  771.79142   2.632069   0 #> 521  501.36663   3.284233   0 #> 522  553.52670   3.828677   0 #> 523  697.70159   2.528299   0 #> 524  500.41904   2.583091   0 #> 525  554.90110   3.069921   0 #> 526  504.43568   3.130123   0 #> 527  510.89862   3.097649   0 #> 528  500.25827   2.561931   0 #> 529  500.11276   2.788960   0 #> 530  593.81459   3.145754   0 #> 531  612.35770   2.709324   0 #> 532  523.29356   2.704873   0 #> 533  511.89416   2.808501   0 #> 534  502.66980   3.514634   0 #> 535  988.72307   3.105932   0 #> 536  500.05606   3.039688   0 #> 537  501.35188   3.148116   0 #> 538  548.39884   2.819333   0 #> 539  504.70405   2.511974   0 #> 540  505.09183   2.675473   0 #> 541  500.18076   2.647337   0 #> 542  685.95512   2.661208   0 #> 543  500.09477   3.901557   0 #> 544  541.65768   2.648382   0 #> 545  508.34915   2.770423   0 #> 546  509.09069   2.956288   0 #> 547  500.04555   3.384401   0 #> 548  673.63189   2.594907   0 #> 549  560.25327   2.714695   0 #> 550  584.63683   4.052505   0 #> 551  526.61437   2.552854   0 #> 552  591.39374   2.518151   0 #> 553  503.82072   3.451093   0 #> 554  500.92500   2.799639   0 #> 555  515.54136   2.564309   0 #> 556  503.52141   2.591704   0 #> 557  501.65799   2.506398   0 #> 558  500.34942   2.596194   0 #> 559  538.17375   2.518971   0 #> 560  500.21639   2.939903   0 #> 561  683.70593   2.578642   0 #> 562  544.45044   2.514403   0 #> 563  500.43184   2.638144   0 #> 564  500.15422   2.563794   0 #> 565  519.99769   2.953652   0 #> 566  812.67100   2.999613   0 #> 567  503.89197   2.895772   0 #> 568  500.09224   2.677901   0 #> 569  505.96512   2.894984   0 #> 570  606.80040   2.630835   0 #> 571  502.60975   3.283060   0 #> 572  502.44566   2.598911   0 #> 573  509.58215   2.997658   0 #> 574  612.41483   2.770894   0 #> 575  500.45243   3.152650   0 #> 576  503.45475   2.538089   0 #> 577  500.01829   3.246775   0 #> 578  502.72739   2.632341   0 #> 579  500.28617   2.889614   0 #> 580  527.94510   3.083567   0 #> 581  502.98156   2.548190   0 #> 582  500.24550   2.782606   0 #> 583  500.22339   3.071415   0 #> 584  500.11583   2.558165   0 #> 585  850.09292   2.842892   0 #> 586  527.38964   2.550571   0 #> 587  500.22549   2.520294   0 #> 588  500.24329   3.503365   0 #> 589  500.83298   3.333614   0 #> 590  504.22120   3.878450   0 #> 591  500.83435   2.588625   0 #> 592  500.29953   2.946889   0 #> 593  746.78892   3.725477   0 #> 594  511.87751   3.398506   0 #> 595  500.00874   2.710266   0 #> 596  768.27135   3.898694   0 #> 597  520.48021   2.794879   0 #> 598  502.26130   2.645721   0 #> 599  512.54340   2.603335   0 #> 600  561.73601   2.833427   0 #> 601  500.17543   2.915235   0 #> 602  500.15123   2.513324   0 #> 603  500.51210   3.066653   0 #> 604  500.14466   2.518273   0 #> 605  546.50257   4.455900   0 #> 606  500.08537   2.672383   0 #> 607  742.59029   2.953146   0 #> 608  500.19661   4.641221   0 #> 609  500.93354   3.138121   0 #> 610  519.75058   2.717989   0 #> 611  500.02459   3.662949   0 #> 612  515.25042   2.983865   0 #> 613  505.90055   3.384747   0 #> 614  527.05699   3.899792   0 #> 615  502.32342   2.504599   0 #> 616  506.08820   2.594304   0 #> 617  500.53961   2.693111   0 #> 618  500.00862   2.903445   0 #> 619  519.57394   2.929994   0 #> 620  503.25167   3.029329   0 #> 621  810.74100   3.689071   0 #> 622  500.95593   2.815629   0 #> 623  857.00009   3.051993   0 #> 624  615.69916   2.813927   0 #> 625  500.54794   2.786629   0 #> 626  500.20288   2.721264   0 #> 627  502.26735   3.292707   0 #> 628  500.04105   2.871778   0 #> 629  703.88261   3.120838   0 #> 630  504.96693   2.914909   0 #> 631  940.16605   2.774536   0 #> 632  853.37384   2.703207   0 #> 633  522.42312   2.938637   0 #> 634  501.68556   3.157482   0 #> 635  601.49890   2.749183   0 #> 636  544.12546   2.857149   0 #> 637  512.99991   2.565172   0 #> 638  752.84535   2.670782   0 #> 639  595.15192   2.590965   0 #> 640  529.39503   2.769541   0 #> 641  502.31805   2.887895   0 #> 642  500.70188   2.832731   0 #> 643  500.17364   3.812779   0 #> 644  500.31135   2.951696   0 #> 645  643.94191   2.822481   0 #> 646  509.24160   2.531927   0 #> 647  500.09069   4.068216   0 #> 648  500.09079   2.515036   0 #> 649  500.00814   2.927230   0 #> 650  500.09540   2.663877   0 #> 651  502.59920   3.075166   0 #> 652  500.42852   2.600835   0 #> 653  620.78597   2.514426   0 #> 654  500.46129   2.770708   0 #> 655  500.83932   4.324474   0 #> 656  504.56915   2.793049   0 #> 657  500.66618   3.333935   0 #> 658  515.72712   2.542928   0 #> 659  501.98673   2.930825   0 #> 660  502.82285   2.704666   0 #> 661  503.51160   2.649678   0 #> 662  514.70492   2.812472   0 #> 663  505.57721   2.506062   0 #> 664  594.15190   3.229839   0 #> 665  704.76877   2.669331   0 #> 666  573.46447   2.960825   0 #> 667  536.87818   2.570494   0 #> 668  546.90388   2.871535   0 #> 669  500.20949   3.410633   0 #> 670  500.02839   3.521587   0 #> 671  648.76540   2.635905   0 #> 672  515.26700   2.583121   0 #> 673  500.66031   2.572449   0 #> 674  500.58711   2.611467   0 #> 675  500.36348   3.100440   0 #> 676  617.88574   3.892131   0 #> 677  506.41394   3.067813   0 #> 678  500.28849   2.905041   0 #> 679  503.65061   2.607218   0 #> 680  507.45857   2.832177   0 #> 681  664.49859   2.791424   0 #> 682  501.40136   2.561488   0 #> 683  506.56416   3.077401   0 #> 684  500.39393   2.860290   0 #> 685  717.37444   2.576464   0 #> 686  659.00909   2.683218   0 #> 687  991.29328   2.996747   0 #> 688  502.77848   2.850142   0 #> 689  500.21146   3.241770   0 #> 690  694.06970   2.510054   0 #> 691  643.11796   3.171351   0 #> 692  500.83198   2.858701   0 #> 693  530.77643   2.707091   0 #> 694  885.44194   2.812781   0 #> 695  500.15110   2.626119   0 #> 696  500.18349   2.607794   0 #> 697  500.21796   2.805193   0 #> 698  501.34307   3.043731   0 #> 699  500.03614   3.054515   0 #> 700  570.63680   2.959050   0 #> 701  535.52649   2.895539   0 #> 702  501.13354   2.862149   0 #> 703  500.06846   2.500503   0 #> 704  501.09899   2.668164   0 #> 705  518.66025   2.843796   0 #> 706  500.04378   2.816902   0 #> 707  505.21746   2.754011   0 #> 708  500.01248   2.986263   0 #> 709  500.98716   2.547062   0 #> 710  500.03577   2.839539   0 #> 711  513.05334   2.750949   0 #> 712  568.42989   2.524776   0 #> 713  629.18464   2.573214   0 #> 714  517.65904   2.977963   0 #> 715  691.21620   3.243263   0 #> 716  714.75747   2.576582   0 #> 717  596.74368   2.605443   0 #> 718  509.44941   2.834949   0 #> 719  573.44351   2.672306   0 #> 720  500.24801   2.671916   0 #> 721  626.28812   3.142081   0 #> 722  502.65887   2.510514   0 #> 723  500.64425   2.569522   0 #> 724  501.13518   2.584547   0 #> 725  501.46124   2.974293   0 #> 726  995.15379   2.632420   0 #> 727  503.61451   3.345932   0 #> 728  500.02076   3.183195   0 #> 729  501.51641   2.704462   0 #> 730  500.73095   3.176148   0 #> 731  500.52178   3.475429   0 #> 732  506.80859   2.551446   0 #> 733  788.90660   2.892985   0 #> 734  500.41546   2.907491   0 #> 735  501.14137   2.740578   0 #> 736  500.26475   2.937412   0 #> 737  502.48900   3.310183   0 #> 738  520.37723   3.315674   0 #> 739  502.25902   3.126257   0 #> 740  671.73539   2.522412   0 #> 741  502.81245   2.512725   0 #> 742  500.01763   2.808340   0 #> 743  993.54443   2.727842   0 #> 744  538.18167   2.977097   0 #> 745  500.59640   2.849882   0 #> 746  506.50104   2.808214   0 #> 747  500.02581   2.747849   0 #> 748  514.13833   3.049989   0 #> 749  502.45959   2.947808   0 #> 750  500.55753   2.559340   0 #> 751  500.15767   2.840206   0 #> 752  553.14887   3.106555   0 #> 753  776.15293   3.116370   0 #> 754  501.38707   2.604440   0 #> 755  500.03352   3.572421   0 #> 756  500.06396   2.571720   0 #> 757  502.25761   2.624015   0 #> 758  503.70912   2.591967   0 #> 759  901.79368   2.846207   0 #> 760  503.37208   2.933713   0 #> 761  501.48972   2.796011   0 #> 762  500.02424   2.560777   0 #> 763  502.46894   3.958509   0 #> 764  500.01521   2.983965   0 #> 765  813.24146   2.847059   0 #> 766  500.51883   2.732259   0 #> 767  500.46671   3.748103   0 #> 768  514.38618   2.928223   0 #> 769  501.48622   3.058477   0 #> 770  500.68896   2.655577   0 #> 771  500.26920   3.029974   0 #> 772  500.43741   3.457235   0 #> 773  500.35295   2.570753   0 #> 774  501.05907   3.400629   0 #> 775  500.24084   5.052545   0 #> 776  500.09719   2.975727   0 #> 777  764.44554   2.954067   0 #> 778  645.45026   4.006835   0 #> 779  501.61040   2.837830   0 #> 780  519.34083   2.667113   0 #> 781  500.04996   2.750920   0 #> 782  503.18090   3.540326   0 #> 783  500.01399   2.633355   0 #> 784  503.25592   2.914317   0 #> 785  500.07517   2.538570   0 #> 786  500.67601   3.319401   0 #> 787  500.34074   4.207301   0 #> 788  500.05448   2.632253   0 #> 789  511.53890   2.846158   0 #> 790  500.01498   2.901462   0 #> 791  502.94163   2.594830   0 #> 792  685.20817   2.856389   0 #> 793  509.09115   4.023630   0 #> 794  516.91751   2.943305   0 #> 795  500.08608   2.572741   0 #> 796  500.24251   2.704845   0 #> 797  500.37746   3.327114   0 #> 798  505.96954   2.839247   0 #> 799  500.20334   2.989731   0 #> 800  500.01581   3.149506   0 #> 801  500.87238   2.524805   0 #> 802  560.38105   2.634306   0 #> 803  538.80511   2.661380   0 #> 804  501.04002   3.321491   0 #> 805  502.12841   3.381609   0 #> 806  515.71614   2.746426   0 #> 807  500.42404   2.542536   0 #> 808  500.27348   3.262189   0 #> 809  500.68427   3.225484   0 #> 810  522.33865   2.537304   0 #> 811  522.06222   2.554289   0 #> 812  500.09762   3.188477   0 #> 813  505.96744   2.690148   0 #> 814  808.97974   3.295410   0 #> 815  516.04971   2.541917   0 #> 816  793.40996   3.035388   0 #> 817  565.60463   2.833896   0 #> 818  515.31252   2.537927   0 #> 819  502.63058   2.645716   0 #> 820  500.00224   2.890969   0 #> 821  500.03071   2.534694   0 #> 822  503.51803   2.738362   0 #> 823  500.22748   2.546124   0 #> 824  502.56565   2.900002   0 #> 825  606.57809   2.669397   0 #> 826  500.36652   3.367174   0 #> 827  500.37503   3.654295   0 #> 828  509.58159   2.513325   0 #> 829  502.47530   3.010521   0 #> 830  503.36046   2.763598   0 #> 831  509.77209   2.679214   0 #> 832  535.81647   4.052693   0 #> 833  711.49636   2.643572   0 #> 834  506.88846   3.247031   0 #> 835  610.37504   3.108084   0 #> 836  508.48667   2.680045   0 #> 837  500.07087   2.978531   0 #> 838  500.06263   2.600747   0 #> 839  680.85659   2.771697   0 #> 840  886.21072   2.830307   0 #> 841  523.43837   2.865870   0 #> 842  506.00339   2.760781   0 #> 843  504.82531   3.619319   0 #> 844  620.08727   2.540058   0 #> 845  500.53603   3.343444   0 #> 846  500.67674   2.768781   0 #> 847  502.97157   2.555398   0 #> 848  500.16037   2.608123   0 #> 849  521.04233   2.793686   0 #> 850  503.96302   3.759612   0 #> 851  509.76650   2.755986   0 #> 852  533.55490   2.941441   0 #> 853  500.17270   3.782382   0 #> 854  724.99738   4.417302   0 #> 855  500.37908   2.523576   0 #> 856  500.01966   4.112238   0 #> 857  503.75337   2.812947   0 #> 858  612.22766   3.126378   0 #> 859  501.98276   2.745164   0 #> 860  507.41439   2.697395   0 #> 861  515.09892   2.780528   0 #> 862  500.07160   2.673799   0 #> 863  500.92913   4.761094   0 #> 864  500.01604   3.094522   0 #> 865  623.73398   2.721876   0 #> 866  500.95037   3.302801   0 #> 867  503.47507   2.726078   0 #> 868  516.92245   2.637392   0 #> 869  526.57646   3.739523   0 #> 870  500.20040   2.555191   0 #> 871  575.58081   2.938657   0 #> 872  555.75582   3.653387   0 #> 873  500.07449   2.560314   0 #> 874  507.25509   2.928699   0 #> 875  991.75813   2.621892   0 #> 876  500.29055   3.274234   0 #> 877  853.48391   2.885656   0 #> 878  507.63877   2.734565   0 #> 879  501.57255   2.664500   0 #> 880  500.07947   2.548200   0 #> 881  501.04503   2.614180   0 #> 882  501.05275   3.064987   0 #> 883  506.24639   2.534094   0 #> 884  501.00453   2.575502   0 #> 885  500.04894   2.778729   0 #> 886  500.29035   2.923038   0 #> 887  500.38284   2.772293   0 #> 888  501.37859   3.038435   0 #> 889  925.48535   2.637338   0 #> 890  944.70030   2.681232   0 #> 891  500.15471   2.550146   0 #> 892  500.51761   2.522600   0 #> 893  500.68966   4.657965   0 #> 894  501.01574   3.006971   0 #> 895  517.23228   2.950280   0 #> 896  500.16025   2.908222   0 #> 897  500.13631   2.557592   0 #> 898  501.62366   3.312619   0 #> 899  501.19120   2.658963   0 #> 900  500.09676   2.899005   0 #> 901  501.51626   2.653930   0 #> 902  500.03846   2.816180   0 #> 903  501.18680   2.664904   0 #> 904  702.21641   2.858962   0 #> 905  500.71232   3.093866   0 #> 906  500.38799   2.852550   0 #> 907  500.12020   3.224016   0 #> 908  500.05514   2.680725   0 #> 909  505.26379   2.820202   0 #> 910  502.70656   2.767834   0 #> 911  500.28537   3.045796   0 #> 912  501.37742   2.802750   0 #> 913  500.08972   2.527986   0 #> 914  504.57665   2.785007   0 #> 915  313.77077   2.545585   1 #> 916  971.21660   2.508058   1 #> 917  214.89841   3.184241   1 #> 918  510.52565   2.638396   1 #> 919  573.05080   3.978608   1 #> 920  344.71973   3.620192   1 #> 921  369.44813   2.576416   1 #> 922   79.83907   2.761489   1 #> 923  120.11041   3.232773   1 #> 924  412.93890   2.537180   1 #> 925  987.40446   2.670606   1 #> 926  257.04167   2.587420   1 #> 927  865.62189   2.595507   1 #> 928  450.62066   2.618760   1 #> 929  246.59225   3.160408   1 #> 930   77.71988   2.800640   1 #> 931  910.64071   2.839969   1 #> 932  471.03300   2.604621   1 #> 933  979.78168   2.510821   1 #> 934  158.12707   2.928005   1 #> 935  608.01630   2.703386   1 #> 936   28.66977   2.665856   1 #> 937   94.99328   2.526507   1 #> 938  182.06348   4.001314   1 #> 939  731.30439   2.874199   1 #> 940  447.43827   3.750461   1 #> 941  770.50613   2.711688   1 #> 942  982.45505   2.580414   1 #> 943   92.46314   4.349903   1 #> 944  424.02706   2.816595   1 #> 945  666.65792   2.530649   1 #> 946  861.78146   2.761115   1 #> 947  233.68290   2.905611   1 #> 948  268.14546   2.696303   1 #> 949  779.86246   3.248109   1 #> 950  189.23945   3.397860   1 #> 951  259.58875   2.705940   1 #> 952  412.95822   2.577698   1 #> 953  869.33940   4.714969   1 #> 954  670.43419   2.778722   1 #> 955  281.74801   3.172643   1 #> 956  695.22911   2.511899   1 #> 957   70.21162   3.712064   1 #> 958  755.58859   3.285205   1 #> 959  657.14098   2.536812   1 #> 960   38.19990   2.989649   1 #> 961  195.48098   3.059009   1 #> 962  390.34093   2.581237   1 #> 963  468.47332   2.554947   1 #> 964  742.17377   2.595126   1 #> 965  226.13050   2.602791   1 #> 966  966.03266   2.507487   1 #> 967  430.82874   2.923273   1 #> 968  305.58980   3.307865   1 #> 969  427.49212   3.483782   1 #> 970  978.11048   2.680919   1 #> 971  173.92030   3.699874   1 #> 972  489.48285   3.117013   1 #> 973  334.98286   2.748474   1 #> 974  309.14598   3.531355   1 #> 975  954.11660   2.975808   1 #> 976  692.80194   3.287662   1 #> 977  740.44926   2.803624   1 #> 978  373.50060   2.504376   1 #> 979  326.75403   3.037510   1 #> 980  423.88659   3.759316   1 #> 981  374.72119   2.551736   1 #> 982  539.45543   2.823914   1 #> 983  911.90204   3.151716   1 #> 984  786.18411   2.586667   1 #> 985  341.94231   3.553738   1 #> 986  600.84265   2.767684   1 #> 987  924.03224   3.003366   1 #> 988  370.83010   2.665066   1 #> 989  575.25264   2.994002   1 #> 990  242.57612   2.664854   1 #> 991  427.22255   2.592385   1 #> 992  243.11818   2.562153   1 #> 993  663.60547   2.592146   1 #> 994  612.32290   3.900519   1 #> 995   88.86604   2.642284   1 #> 996  643.89496   2.815793   1 #> 997  839.04013   2.703457   1 #> 998  303.71649   2.525240   1 #> 999  387.93524   2.726937   1 #> 1000 552.66902   2.677940   1 #> 1001 615.41499   2.622132   1 #> 1002  84.03770   2.777332   1 #> 1003 531.39457   2.748449   1 #> 1004 818.25304   2.619842   1 #> 1005 316.07898   2.584923   1 #> 1006 664.85840   2.887547   1 #> 1007 992.12663   2.532580   1 #> 1008 740.52513   3.307760   1 #> 1009  73.70161   2.805866   1 #> 1010 305.15813   2.754835   1 #>  #> [[3]] #>            ts magnitudes gen #> 1   658.61734   2.794278   2 #> 2   520.89124   2.713637   2 #> 3   509.89681   3.325114   2 #> 4   597.54979   2.685864   2 #> 5   500.27657   3.165944   2 #> 6   508.37325   3.638548   2 #> 7   527.80818   3.062405   2 #> 8   503.82198   3.302094   2 #> 9   517.74680   2.949267   2 #> 10  539.25355   3.337886   2 #> 11  542.24914   2.538589   2 #> 12  500.18984   2.598170   2 #> 13  926.32821   2.843402   2 #> 14  504.49393   2.612011   2 #> 15  505.01306   3.097583   2 #> 16  509.56085   2.651036   2 #> 17  506.32941   2.812651   2 #> 18  723.37404   2.870790   2 #> 19  508.03465   2.554009   2 #> 20  501.81662   2.617768   2 #> 21  500.92910   2.785195   2 #> 22  506.97968   2.701741   2 #> 23  530.46374   2.841403   2 #> 24  509.53535   4.985067   2 #> 25  576.76719   2.642446   2 #> 26  718.96553   2.802477   2 #> 27  511.63708   2.680312   2 #> 28  507.61982   3.659324   2 #> 29  500.60387   3.057805   2 #> 30  583.48152   2.684642   2 #> 31  500.82001   2.692663   2 #> 32  557.47082   2.867493   2 #> 33  501.50778   2.674770   2 #> 34  532.24624   2.622718   2 #> 35  510.32504   3.553051   2 #> 36  521.91470   2.907470   2 #> 37  747.29733   2.966453   2 #> 38  993.76709   2.994369   2 #> 39  500.53643   2.905289   2 #> 40  566.68660   2.647423   2 #> 41  547.21566   2.571079   2 #> 42  547.57123   2.701385   2 #> 43  502.44816   3.057364   2 #> 44  501.82399   3.003486   2 #> 45  504.32427   2.679032   2 #> 46  520.56897   2.644149   2 #> 47  500.34034   3.639115   2 #> 48  500.69736   2.644112   2 #> 49  504.20058   2.579154   2 #> 50  988.79465   2.870854   2 #> 51  544.72536   2.661892   2 #> 52  523.89257   2.855316   2 #> 53  525.50150   2.613179   2 #> 54  526.30214   2.784685   2 #> 55  534.34071   2.766696   2 #> 56  535.54402   2.746100   2 #> 57  522.03645   2.982863   2 #> 58  521.99830   2.852559   2 #> 59  523.06250   2.914760   2 #> 60  829.03345   2.544598   2 #> 61  522.30068   3.423357   2 #> 62  550.19318   2.784677   2 #> 63  505.67967   4.162264   2 #> 64  659.35618   2.615836   2 #> 65  659.23022   2.596706   2 #> 66  538.79410   2.582648   2 #> 67  509.39504   3.327367   2 #> 68  548.73756   3.165897   2 #> 69  526.99140   3.343178   2 #> 70  524.70865   2.914148   2 #> 71  521.47483   2.784926   2 #> 72  505.87955   3.501560   2 #> 73  505.89708   2.760737   2 #> 74  505.76009   2.973656   2 #> 75  500.32505   4.171192   2 #> 76  500.67972   4.099409   2 #> 77  500.28983   3.377723   2 #> 78  503.89790   3.532794   2 #> 79  523.97054   2.530039   2 #> 80  504.77381   2.983495   2 #> 81  609.88642   2.975435   2 #> 82  819.04850   2.535182   2 #> 83  508.10774   2.943121   2 #> 84  776.92001   2.581512   2 #> 85  501.63242   3.079290   2 #> 86  509.37361   2.985210   2 #> 87  507.20330   2.943699   2 #> 88  592.86588   2.775506   2 #> 89  780.56822   2.685613   2 #> 90  519.90583   3.175162   2 #> 91  561.41023   2.569647   2 #> 92  580.70662   3.460807   2 #> 93  773.18895   3.038003   2 #> 94  524.13228   3.872257   2 #> 95  512.74255   2.963102   2 #> 96  553.10147   2.669896   2 #> 97  523.07855   3.190123   2 #> 98  835.15186   3.889708   2 #> 99  504.50398   3.777626   2 #> 100 510.59892   2.771129   2 #> 101 502.73337   2.943845   2 #> 102 501.27790   2.535880   2 #> 103 513.10291   3.721836   2 #> 104 500.54922   2.753286   2 #> 105 515.38663   2.689107   2 #> 106 919.12389   2.633836   2 #> 107 546.22160   3.583720   2 #> 108 502.86987   3.501465   2 #> 109 723.55436   2.893175   2 #> 110 787.25204   2.594121   2 #> 111 519.13632   3.275547   2 #> 112 735.21754   2.572354   2 #> 113 726.99812   2.892018   2 #> 114 507.36066   3.147912   2 #> 115 524.47853   2.844053   2 #> 116 659.54211   3.452943   2 #> 117 791.14564   2.545139   2 #> 118 504.97135   3.183539   2 #> 119 501.84280   2.970439   2 #> 120 516.58578   2.501169   2 #> 121 500.39920   2.536416   2 #> 122 955.61800   2.529162   2 #> 123 503.47419   2.658810   2 #> 124 516.05129   2.783457   2 #> 125 556.30880   2.710759   2 #> 126 526.93968   2.592778   2 #> 127 906.49496   2.821059   2 #> 128 562.71489   2.742400   2 #> 129 500.80620   2.507231   2 #> 130 573.10619   2.964191   2 #> 131 732.32859   3.577334   2 #> 132 731.91314   2.679739   2 #> 133 511.06948   3.430815   2 #> 134 524.97332   2.990573   2 #> 135 502.77931   2.586374   2 #> 136 500.16572   2.914560   2 #> 137 811.74943   3.116757   2 #> 138 507.79284   3.226744   2 #> 139 863.81005   2.527734   2 #> 140 500.41313   2.675787   2 #> 141 566.22367   2.670411   2 #> 142 583.39408   2.500396   2 #> 143 583.65603   2.595947   2 #> 144 595.94774   4.675001   2 #> 145 543.98828   3.476025   2 #> 146 550.77312   2.798310   2 #> 147 539.31974   2.720324   2 #> 148 544.22966   2.786320   2 #> 149 513.31197   2.577539   2 #> 150 500.29185   2.939627   2 #> 151 605.82937   2.815288   2 #> 152 512.83296   2.683357   2 #> 153 847.55209   3.896299   2 #> 154 525.36004   2.644408   2 #> 155 549.02351   2.557593   2 #> 156 544.58011   2.558170   2 #> 157 500.69696   2.765492   2 #> 158 557.44418   2.651490   2 #> 159 501.85665   3.205480   2 #> 160 606.82169   2.513041   2 #> 161 676.70949   2.831305   2 #> 162 563.11161   2.711217   2 #> 163 766.27635   3.148110   2 #> 164 642.14505   2.598525   2 #> 165 513.49071   3.006803   2 #> 166 518.12360   3.586177   2 #> 167 501.68194   2.564956   2 #> 168 500.34302   2.760673   2 #> 169 500.43436   4.083557   2 #> 170 508.64437   2.817615   2 #> 171 509.15816   2.961304   2 #> 172 500.59833   2.556488   2 #> 173 584.82810   3.139801   2 #> 174 585.35937   3.143984   2 #> 175 705.10202   2.563564   2 #> 176 584.94871   4.313874   2 #> 177 593.20223   3.191145   2 #> 178 617.41636   2.919753   2 #> 179 586.86170   3.712937   2 #> 180 500.69111   3.364129   2 #> 181 518.43556   3.567632   2 #> 182 552.20929   2.664571   2 #> 183 500.42781   3.680302   2 #> 184 751.89166   2.677430   2 #> 185 528.67609   2.737260   2 #> 186 768.67628   3.427744   2 #> 187 771.76133   2.555473   2 #> 188 547.80187   2.514431   2 #> 189 546.90166   2.624932   2 #> 190 546.54484   2.597771   2 #> 191 557.08348   2.565835   2 #> 192 547.06769   3.031363   2 #> 193 546.53443   3.066576   2 #> 194 742.77350   2.981205   2 #> 195 534.83205   3.128413   2 #> 196 500.35828   2.914469   2 #> 197 504.37055   4.902864   2 #> 198 720.13311   2.508526   2 #> 199 500.33453   2.578255   2 #> 200 500.21602   2.581691   2 #> 201 517.08359   2.794876   2 #> 202 517.78301   2.687155   2 #> 203 502.08209   2.620985   2 #> 204 501.55004   2.849251   2 #> 205 505.03349   2.822943   2 #> 206 517.08485   2.692444   2 #> 207 500.50381   3.558785   2 #> 208 536.43369   2.519376   2 #> 209 527.30324   3.062248   2 #> 210 749.42050   2.793395   2 #> 211 556.68251   3.071844   2 #> 212 504.58536   2.637823   2 #> 213 502.27409   2.872451   2 #> 214 502.39496   2.553357   2 #> 215 976.17086   2.663333   2 #> 216 509.36741   2.583676   2 #> 217 500.35559   2.766763   2 #> 218 517.01258   2.918756   2 #> 219 568.70335   2.559535   2 #> 220 503.43366   3.096690   2 #> 221 594.20175   2.537694   2 #> 222 574.36336   2.517657   2 #> 223 538.55820   3.364638   2 #> 224 501.52716   2.947911   2 #> 225 621.29088   3.126694   2 #> 226 621.33383   2.799804   2 #> 227 672.03159   3.372994   2 #> 228 644.49767   2.679616   2 #> 229 502.57541   2.543099   2 #> 230 706.99584   3.102259   2 #> 231 573.90834   3.178653   2 #> 232 500.26626   2.636602   2 #> 233 764.29610   2.606834   2 #> 234 505.02492   3.153542   2 #> 235 501.52117   3.599506   2 #> 236 505.33243   2.881469   2 #> 237 504.97735   2.950982   2 #> 238 543.18400   2.905714   2 #> 239 637.59136   4.999107   2 #> 240 502.41341   2.519132   2 #> 241 533.14707   4.178764   2 #> 242 502.17477   2.663282   2 #> 243 554.22873   3.238852   2 #> 244 514.96084   2.951511   2 #> 245 500.32972   3.301811   2 #> 246 585.98100   2.920021   2 #> 247 500.50900   3.006005   2 #> 248 501.33800   3.222240   2 #> 249 507.55173   3.549738   2 #> 250 613.06392   3.044207   2 #> 251 518.64376   2.669194   2 #> 252 514.01300   2.515130   2 #> 253 521.90093   2.734821   2 #> 254 500.47807   3.756002   2 #> 255 502.16266   2.998546   2 #> 256 500.24295   2.839881   2 #> 257 568.03327   2.780606   2 #> 258 509.96711   2.563922   2 #> 259 510.30533   3.163133   2 #> 260 613.18746   2.817983   2 #> 261 500.57490   3.076571   2 #> 262 881.14372   2.581000   2 #> 263 652.30141   2.561530   2 #> 264 500.95844   3.435973   2 #> 265 648.39812   2.722483   2 #> 266 500.93018   2.696263   2 #> 267 504.13493   3.217587   2 #> 268 500.93636   3.023148   2 #> 269 500.32293   3.232750   2 #> 270 563.61419   2.785801   2 #> 271 795.55567   2.806890   2 #> 272 726.52417   3.983736   2 #> 273 983.92588   2.644388   2 #> 274 502.02509   2.689485   2 #> 275 500.62630   3.074017   2 #> 276 500.45105   2.752935   2 #> 277 644.85874   3.886811   2 #> 278 572.28572   3.732455   2 #> 279 829.47140   3.643301   2 #> 280 531.36951   2.794844   2 #> 281 787.48430   2.806717   2 #> 282 504.13134   2.794990   2 #> 283 500.38215   2.514666   2 #> 284 537.34201   2.936619   2 #> 285 536.05706   2.607966   2 #> 286 594.59830   3.019958   2 #> 287 536.75184   2.659966   2 #> 288 594.35097   2.605405   2 #> 289 508.00850   2.943364   2 #> 290 683.55789   2.614660   2 #> 291 681.71362   3.059814   2 #> 292 621.14388   2.586410   2 #> 293 501.09025   4.652511   2 #> 294 933.23592   2.841228   2 #> 295 684.83227   3.006244   2 #> 296 726.15570   2.654112   2 #> 297 735.69499   4.428941   2 #> 298 725.31529   3.515832   2 #> 299 730.91241   2.593118   2 #> 300 727.03971   2.508613   2 #> 301 739.63221   2.750987   2 #> 302 501.22164   2.847626   2 #> 303 819.30397   3.156658   2 #> 304 506.52724   2.677606   2 #> 305 759.98391   2.697697   2 #> 306 501.92431   2.923699   2 #> 307 525.68056   3.299072   2 #> 308 501.48341   3.184445   2 #> 309 502.75764   3.325807   2 #> 310 632.64671   3.023302   2 #> 311 502.31274   2.750403   2 #> 312 507.90724   2.865316   2 #> 313 806.63756   2.511205   2 #> 314 592.82028   3.159594   2 #> 315 534.74274   2.699048   2 #> 316 536.19876   3.568928   2 #> 317 794.90568   2.699315   2 #> 318 527.94800   2.583011   2 #> 319 528.07987   3.750755   2 #> 320 556.07779   2.552663   2 #> 321 853.72884   2.889744   2 #> 322 575.32690   2.559401   2 #> 323 500.82237   2.544887   2 #> 324 701.76666   2.979056   2 #> 325 539.94092   2.895803   2 #> 326 501.39068   2.897116   2 #> 327 504.04915   3.017542   2 #> 328 507.74914   2.663584   2 #> 329 508.50084   2.564274   2 #> 330 501.44761   2.863620   2 #> 331 534.07036   3.754699   2 #> 332 528.29774   2.649828   2 #> 333 500.74331   3.918581   2 #> 334 528.15488   3.530019   2 #> 335 795.20443   2.720195   2 #> 336 500.17402   2.500260   2 #> 337 509.60012   2.995499   2 #> 338 215.01344   2.999669   2 #> 339 510.66961   2.572863   2 #> 340 575.73118   3.156163   2 #> 341 844.41894   2.974657   2 #> 342 440.63458   4.396899   2 #> 343 510.03284   2.736988   2 #> 344 182.23818   2.638062   2 #> 345 193.12104   3.182577   2 #> 346 182.14284   2.569257   2 #> 347 457.00888   3.110328   2 #> 348  92.50536   2.550219   2 #> 349  94.79667   3.496483   2 #> 350 116.19889   3.133680   2 #> 351 413.97492   3.783139   2 #> 352 123.75174   3.014485   2 #> 353  94.08135   3.113631   2 #> 354 135.28932   2.786884   2 #> 355 869.36523   2.989432   2 #> 356 887.67722   2.994092   2 #> 357 871.92358   3.040608   2 #> 358 911.85174   2.545832   2 #> 359 869.48252   2.651969   2 #> 360 873.66007   2.808678   2 #> 361 872.74017   2.819590   2 #> 362  71.28204   2.542187   2 #> 363 226.33328   2.829403   2 #> 364 430.99637   2.738569   2 #> 365 176.63921   2.838165   2 #> 366 183.76742   2.720717   2 #> 367 309.27648   3.130066   2 #> 368 954.20687   3.411580   2 #> 369 523.38683   3.594129   2 #> 370 430.18667   3.872084   2 #> 371 424.00999   3.112827   2 #> 372 426.71869   2.509855   2 #> 373 953.91960   2.811664   2 #> 374 930.53238   2.550250   2 #> 375 626.89094   3.787298   2 #> 376 630.42043   2.681997   2 #>  #> [[4]] #>            ts magnitudes gen #> 1   505.40621   2.606764   3 #> 2   579.36257   2.625845   3 #> 3   539.58540   2.663524   3 #> 4   505.94718   2.879376   3 #> 5   501.23314   2.708240   3 #> 6   628.69706   3.767857   3 #> 7   509.63776   3.744436   3 #> 8   929.68106   2.806943   3 #> 9   523.53448   2.618255   3 #> 10  509.53892   2.561199   3 #> 11  510.77537   2.903871   3 #> 12  555.73934   3.268375   3 #> 13  731.61328   2.926038   3 #> 14  510.43333   3.939482   3 #> 15  510.07453   2.565102   3 #> 16  544.18770   2.609891   3 #> 17  521.23891   2.825488   3 #> 18  518.11419   2.609121   3 #> 19  509.58994   2.871931   3 #> 20  509.68071   2.918930   3 #> 21  513.63596   2.596235   3 #> 22  523.01017   2.871456   3 #> 23  580.49059   2.785222   3 #> 24  507.62797   3.107947   3 #> 25  500.70389   2.747894   3 #> 26  582.97802   2.788160   3 #> 27  542.91247   2.622451   3 #> 28  524.63970   3.701011   3 #> 29  746.12858   3.130522   3 #> 30  506.20645   2.553274   3 #> 31  506.97784   3.031896   3 #> 32  505.84584   2.740177   3 #> 33  555.88587   2.650580   3 #> 34  506.27478   2.874098   3 #> 35  510.64928   2.886378   3 #> 36  635.44837   3.730695   3 #> 37  925.37840   2.695997   3 #> 38  500.97322   3.168902   3 #> 39  501.49680   2.791327   3 #> 40  546.72553   2.929344   3 #> 41  500.44137   3.315026   3 #> 42  500.74167   3.276163   3 #> 43  500.86027   2.989695   3 #> 44  500.71525   3.023221   3 #> 45  660.57321   2.730680   3 #> 46  889.18121   2.545746   3 #> 47  977.41853   2.690696   3 #> 48  525.05646   2.616681   3 #> 49  557.17982   2.716442   3 #> 50  527.09246   2.801124   3 #> 51  529.28405   4.136280   3 #> 52  568.07184   3.050293   3 #> 53  835.55843   3.206991   3 #> 54  794.83710   2.575899   3 #> 55  517.95871   2.569360   3 #> 56  517.49874   2.930678   3 #> 57  558.61542   2.563480   3 #> 58  517.02894   2.757704   3 #> 59  917.12358   2.800122   3 #> 60  736.14419   2.578651   3 #> 61  524.88685   2.768526   3 #> 62  732.85364   2.897276   3 #> 63  605.53048   2.615883   3 #> 64  811.98045   3.381192   3 #> 65  523.38411   3.322947   3 #> 66  595.94957   2.617687   3 #> 67  596.61158   2.918730   3 #> 68  596.01115   2.503497   3 #> 69  597.63358   2.547884   3 #> 70  623.80338   2.643531   3 #> 71  596.51231   3.206624   3 #> 72  598.13754   2.566386   3 #> 73  825.64247   2.558902   3 #> 74  595.96081   2.624322   3 #> 75  581.94078   2.574121   3 #> 76  911.68973   2.740535   3 #> 77  518.46953   2.899737   3 #> 78  610.53015   3.336882   3 #> 79  586.07968   2.958343   3 #> 80  585.82344   2.733425   3 #> 81  584.97469   2.514820   3 #> 82  623.40298   2.775394   3 #> 83  627.45717   2.631300   3 #> 84  606.98860   3.325828   3 #> 85  588.75287   2.515561   3 #> 86  842.85274   2.665030   3 #> 87  529.96239   2.633015   3 #> 88  528.91556   2.780004   3 #> 89  557.27676   2.525725   3 #> 90  546.99624   3.134827   3 #> 91  505.88145   3.163191   3 #> 92  622.09515   2.753395   3 #> 93  506.05684   3.846705   3 #> 94  775.97280   2.819573   3 #> 95  507.81899   4.146184   3 #> 96  504.88782   2.975124   3 #> 97  504.49620   2.525428   3 #> 98  513.40973   3.512903   3 #> 99  639.47290   3.017960   3 #> 100 527.28126   2.510147   3 #> 101 505.03535   2.506995   3 #> 102 695.24979   3.048499   3 #> 103 501.73817   3.044645   3 #> 104 505.11056   3.157270   3 #> 105 543.21927   2.616477   3 #> 106 639.28047   2.707112   3 #> 107 716.30145   2.726427   3 #> 108 649.14011   2.565989   3 #> 109 638.35021   3.835516   3 #> 110 659.27467   3.523438   3 #> 111 652.17785   2.989784   3 #> 112 637.83004   2.840718   3 #> 113 640.65167   2.708882   3 #> 114 673.58148   2.766041   3 #> 115 671.98296   3.090810   3 #> 116 639.06139   2.890851   3 #> 117 637.74999   4.442466   3 #> 118 638.49286   2.768574   3 #> 119 663.04302   2.552324   3 #> 120 637.88722   3.244084   3 #> 121 644.03018   3.344030   3 #> 122 798.88615   2.992032   3 #> 123 539.61996   2.700481   3 #> 124 533.91612   3.999198   3 #> 125 503.07230   2.770472   3 #> 126 634.12563   3.233524   3 #> 127 504.24843   4.146161   3 #> 128 741.91815   2.532474   3 #> 129 822.52368   2.554469   3 #> 130 954.42659   3.626922   3 #> 131 646.28240   2.586828   3 #> 132 572.31305   2.834537   3 #> 133 596.89223   2.922434   3 #> 134 501.25515   2.640454   3 #> 135 501.80142   2.914234   3 #> 136 509.49052   2.817767   3 #> 137 511.91491   2.701853   3 #> 138 501.75848   3.806942   3 #> 139 584.02932   2.699043   3 #> 140 505.63736   3.623967   3 #> 141 507.73087   3.311505   3 #> 142 506.27214   3.580516   3 #> 143 502.46953   3.958556   3 #> 144 502.18597   2.714479   3 #> 145 501.28593   2.631780   3 #> 146 760.45444   2.553121   3 #> 147 770.52317   3.320455   3 #> 148 739.97084   3.043149   3 #> 149 738.40210   2.615174   3 #> 150 750.94643   3.360001   3 #> 151 737.32183   2.689242   3 #> 152 745.24605   2.913350   3 #> 153 739.73966   2.732451   3 #> 154 536.72224   2.799628   3 #> 155 794.39082   2.798802   3 #> 156 537.55905   2.615121   3 #> 157 530.68470   3.412257   3 #> 158 862.38627   2.970951   3 #> 159 543.64495   2.889866   3 #> 160 546.29911   2.753122   3 #> 161 501.30766   3.153822   3 #> 162 839.96512   2.651662   3 #> 163 221.77514   3.068577   3 #> 164 548.19913   2.529042   3 #> 165 510.20015   2.907093   3 #> 166 440.93141   2.615859   3 #> 167 742.07194   3.551002   3 #> 168 445.63074   2.531975   3 #> 169 673.29018   2.504475   3 #> 170 627.47054   2.909928   3 #> 171 686.31078   2.926280   3 #> 172  94.21847   2.929602   3 #> 173 546.93590   2.544384   3 #> 174 434.92107   2.639771   3 #> 175 627.59052   3.072122   3 #> 176 626.94890   3.159120   3 #> 177 847.20807   2.567299   3 #> 178 653.80371   2.565867   3 #>  #> [[5]] #>          ts magnitudes gen #> 1  539.8292   4.147923   4 #> 2  511.8415   2.627613   4 #> 3  535.9052   2.959843   4 #> 4  634.0438   2.586320   4 #> 5  941.7034   2.704072   4 #> 6  520.6045   2.905439   4 #> 7  530.4890   2.572201   4 #> 8  523.1830   2.746128   4 #> 9  783.2202   2.700763   4 #> 10 764.9088   2.976063   4 #> 11 665.8369   2.857273   4 #> 12 724.1038   2.509989   4 #> 13 873.7490   3.525808   4 #> 14 535.7190   2.725167   4 #> 15 545.6389   2.637084   4 #> 16 938.3895   3.423765   4 #> 17 529.5527   3.829206   4 #> 18 836.6456   2.899135   4 #> 19 527.9906   4.373816   4 #> 20 613.9968   2.541853   4 #> 21 614.0547   2.526808   4 #> 22 510.0467   3.866396   4 #> 23 508.2755   2.684723   4 #> 24 510.5552   2.650822   4 #> 25 531.0693   3.637484   4 #> 26 594.5202   2.830131   4 #> 27 705.0915   2.838578   4 #> 28 932.5766   3.474516   4 #> 29 652.7302   3.177708   4 #> 30 791.7852   5.086492   4 #> 31 675.0006   3.560919   4 #> 32 675.2997   2.691698   4 #> 33 641.9458   3.448590   4 #> 34 739.0674   2.632026   4 #> 35 715.2689   2.620955   4 #> 36 663.1820   3.516841   4 #> 37 638.0430   2.971326   4 #> 38 912.8840   2.554658   4 #> 39 644.1511   2.580601   4 #> 40 535.3110   3.633712   4 #> 41 505.0866   2.974827   4 #> 42 505.0674   2.742964   4 #> 43 535.1096   3.790251   4 #> 44 867.3445   2.555142   4 #> 45 821.3657   2.918361   4 #> 46 506.3426   2.501483   4 #> 47 541.2545   2.657543   4 #> 48 502.5181   2.672598   4 #> 49 617.9060   2.712100   4 #> 50 505.8221   3.374560   4 #> 51 502.4743   2.907388   4 #> 52 648.5805   2.632513   4 #> 53 793.5347   3.533959   4 #> 54 751.2852   2.506399   4 #> 55 612.3324   2.895778   4 #> 56 612.7917   2.504976   4 #> 57 723.8683   2.955281   4 #> 58 645.1651   2.734676   4 #>  #> [[6]] #>          ts magnitudes gen #> 1  540.3287   2.502080   5 #> 2  552.5954   2.777946   5 #> 3  564.2850   3.182516   5 #> 4  783.3209   2.697383   5 #> 5  680.6241   2.722938   5 #> 6  869.2973   2.581166   5 #> 7  561.9036   2.509113   5 #> 8  531.2019   3.338442   5 #> 9  529.8931   2.584598   5 #> 10 681.2285   2.524364   5 #> 11 529.2246   2.573488   5 #> 12 577.1835   2.882775   5 #> 13 510.3545   2.647885   5 #> 14 521.9702   2.536415   5 #> 15 531.1083   2.580345   5 #> 16 532.1203   2.654742   5 #> 17 531.7669   2.858837   5 #> 18 932.5820   2.626063   5 #> 19 667.8655   2.622656   5 #> 20 654.9070   2.658758   5 #> 21 793.0621   2.802060   5 #> 22 794.9091   2.517282   5 #> 23 791.9578   2.984811   5 #> 24 807.5746   2.736320   5 #> 25 795.5927   2.549661   5 #> 26 791.8269   3.618342   5 #> 27 792.0311   2.588769   5 #> 28 802.7223   3.326565   5 #> 29 794.5501   2.735666   5 #> 30 791.8493   3.699690   5 #> 31 799.9453   2.635680   5 #> 32 891.5822   3.013940   5 #> 33 792.1563   3.177613   5 #> 34 792.3722   2.514401   5 #> 35 792.4264   2.533295   5 #> 36 791.9614   2.678242   5 #> 37 650.4068   3.658712   5 #> 38 664.4199   4.718892   5 #> 39 544.5471   3.136977   5 #> 40 505.9696   3.145309   5 #>  #> [[7]] #>          ts magnitudes gen #> 1  533.3926   3.091478   6 #> 2  799.2899   3.195485   6 #> 3  651.5971   2.674094   6 #> 4  696.3566   2.599603   6 #> 5  671.5910   2.561603   6 #> 6  664.4259   2.613134   6 #> 7  732.4933   2.566115   6 #> 8  665.3941   2.791021   6 #> 9  692.1771   2.660278   6 #> 10 680.5744   3.045305   6 #> 11 973.6878   2.539470   6 #> 12 777.5586   2.566335   6 #> 13 664.8980   2.743712   6 #>  #> [[8]] #>         ts magnitudes gen #> 1 535.0412   2.522188   7 #> 2 711.5634   2.530906   7 #> 3 672.0905   3.161499   7 #> 4 667.0547   2.551390   7 #> 5 905.3817   2.783263   7 #>"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_N.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the posterior distribution of the expected number of events — get_posterior_N","title":"Plot the posterior distribution of the expected number of events — get_posterior_N","text":"Plot posterior distribution expected number events","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_N.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the posterior distribution of the expected number of events — get_posterior_N","text":"","code":"get_posterior_N(input.list, domain.extension = 0.1)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_N.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the posterior distribution of the expected number of events — get_posterior_N","text":"input.list combined input file (link functions) bru output (marginals) domain.extension Percentage posterior quantiles extend domain specified scalar. Default set 0.10.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_N.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the posterior distribution of the expected number of events — get_posterior_N","text":"list three objects: post.df: data.frame containing posterior informations posterior distribution number events post.plot : ggplot object showing posterior distribution expected number events post.plot.shaded : ggplot object showing posterior distribution expected number events, shaded region corresponds 0.025 0.975 quantiles distribution distribution number events.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_param.html","id":null,"dir":"Reference","previous_headings":"","what":"Retrieve posterior distribution of ETAS parameters — get_posterior_param","title":"Retrieve posterior distribution of ETAS parameters — get_posterior_param","text":"Retrieve posterior distribution ETAS parameters","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_param.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Retrieve posterior distribution of ETAS parameters — get_posterior_param","text":"","code":"get_posterior_param(input.list)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_param.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Retrieve posterior distribution of ETAS parameters — get_posterior_param","text":"input.list input.list structured input list least two elements: model.fit: bru object used sample posterior ETAS parameters link.functions: list functions convert ETAS parameters INLA scale ETAS scale","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/get_posterior_param.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Retrieve posterior distribution of ETAS parameters — get_posterior_param","text":"list two elements: post.df : data.frame posterior distributions parameters columns x (value parameter), y (value posterior), param (parameter name) post.plot : ggplot object showing posterior distribution parameter","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gt.html","id":null,"dir":"Reference","previous_headings":"","what":"ETAS triggering function - used by inlabru — gt","title":"ETAS triggering function - used by inlabru — gt","text":"function returns value ETAS triggering function specified time t points history th, mh","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gt.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"ETAS triggering function - used by inlabru — gt","text":"","code":"gt(theta, t, th, mh, M0)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gt.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"ETAS triggering function - used by inlabru — gt","text":"theta ETAS parameters list names K, alpha, c, p t Time function calculated, scalar vector th Time events history [days, months,...], scalar vector mh Magnitude events history, scalar vector M0 Minimum magnitude threshold, scalar","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gt.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"ETAS triggering function - used by inlabru — gt","text":"value ETAS triggering function evaluated t history th, mh.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/gt.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"ETAS triggering function - used by inlabru — gt","text":"ETAS triggering function evaluated $$g(t - t_h | m_h) = K e^{\\alpha(m_h - M_0)} \\left( \\frac{t - t_h}{c} + 1\\right)^{-p}$$ \\(K, \\alpha, c > 0\\), \\(p \\geq 1\\) ETAS parameters, \\(t\\) (t) time function evaluated, considering past observation \\(t_h, m_h\\) (th, mh). function returns 0 \\(t_h > t\\). \\(t\\) scalar \\(t_h, m_h\\) vectors function returns vector, \\(t\\) vector \\(t_h, m_h\\) scalars, \\(t, t_h, m_h\\) vectors length. use \\(t\\) \\(t_h, m_h\\) vectors different lengths.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":null,"dir":"Reference","previous_headings":"","what":"HORUS Ita Catalogue — horus","title":"HORUS Ita Catalogue — horus","text":"HOmogenized instRUmental Seismic catalog (HORUS) Italy 1960 present, limited limited 1960-2019.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"HORUS Ita Catalogue — horus","text":"","code":"horus"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":"format","dir":"Reference","previous_headings":"","what":"Format","title":"HORUS Ita Catalogue — horus","text":"Original file format: Year: Origin Time (OT) year Mo: OT month Da: OT day Ho: OT hour Mi OT minute Se OT seconds fractions Lat epicenter N latitude (degrees) Lon epicenter E longitude (degrees) Depth hypocenter depth (km) Mw true proxy moment magnitude sigMw moment magnitude uncertainty Geo.Ita \"*\" indicates epicenter within Italian mainland territory, otherwise \" \" Geo.CPTI15 \"*\" indicates epicenter within spatial window CPTI15 catalog (Rovida et al., 2020, Bull Earth Eng, doi: 10.1007/s10518-020-00818-y) Ev..type \"x\" indicates event earthquake (e.g. explosion, eruption, landslide, ...) (since May 1st 2012) Iside.n. ISIDe id number (since April 16th 2005) ETAS.inlabru format: time_string: Data-time event, ISO 8601 format; format = \"%Y-%m-%dT%H:%M:%OS\" use .POSIXct() lon: Original Lon lat: Original Lat depth Original Depth M: Original Mw","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":"source","dir":"Reference","previous_headings":"","what":"Source","title":"HORUS Ita Catalogue — horus","text":"http://horus.bo.ingv./","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"HORUS Ita Catalogue — horus","text":"original entire HORUS catalog provided single tab separated ascii file: HORUS_Ita_Catalog.txt random second decimal digit added ML Md INGV bulletin (ISIDe) computing Mw proxies (Lolli et al., Seism. Res. Lett., 91, 3208-3222, doi: 10.1785/0220200148), HORUS_Ita_Catalog_o.txt original ML Md used compute Mw proxies. ETAS.inlabru includes reformatted version data HORUS_Ita_Catalog.txt data.frame, limited 1960-2019. data provided , express implied warranty given.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/horus.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"HORUS Ita Catalogue — horus","text":"Barbara Lolli(1), Daniele Randazzo(1), Gianfranco Vannucci(1) Paolo Gasperini (2),(1) (2020). Homogenized Instrumental Seismic Catalog (HORUS) Italy 1960 Present, Seismol. Res. Lett, doi: 10.1785/0220200148. (1) Istituto Nazionale di Geofisica e Vulcanologia, Sezione di Bologna (2) Dipartimento di Fisica e Astronomia, Università di Bologna","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_exp_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from an Exponential to a standard Normal distribution — inv_exp_t","title":"Copula transformation from an Exponential to a standard Normal distribution — inv_exp_t","text":"Copula transformation Exponential standard Normal distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_exp_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from an Exponential to a standard Normal distribution — inv_exp_t","text":"","code":"inv_exp_t(x, rate)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_exp_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from an Exponential to a standard Normal distribution — inv_exp_t","text":"x values Exponential distribution, vector. rate rate Exponential distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_exp_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from an Exponential to a standard Normal distribution — inv_exp_t","text":"values standard Normal distribution, vector length x","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_gamma_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from an Gamma to a standard Normal distribution — inv_gamma_t","title":"Copula transformation from an Gamma to a standard Normal distribution — inv_gamma_t","text":"Copula transformation Gamma standard Normal distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_gamma_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from an Gamma to a standard Normal distribution — inv_gamma_t","text":"","code":"inv_gamma_t(x, a, b)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_gamma_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from an Gamma to a standard Normal distribution — inv_gamma_t","text":"x values Gamma distribution, vector. shape parameter Gamma distribution, scalar. b rate parameter Gamma distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_gamma_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from an Gamma to a standard Normal distribution — inv_gamma_t","text":"values standard Normal distribution, vector length x","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_loggaus_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from an Log-Normal to a standard Normal distribution — inv_loggaus_t","title":"Copula transformation from an Log-Normal to a standard Normal distribution — inv_loggaus_t","text":"Copula transformation Log-Normal standard Normal distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_loggaus_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from an Log-Normal to a standard Normal distribution — inv_loggaus_t","text":"","code":"inv_loggaus_t(x, m, s)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_loggaus_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from an Log-Normal to a standard Normal distribution — inv_loggaus_t","text":"x values Log-Normal distribution, vector. m mean logarithm Log-Normal distribution, scalar. s standard deviation logarithm Log-Normal distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_loggaus_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from an Log-Normal to a standard Normal distribution — inv_loggaus_t","text":"values standard Normal distribution, vector length x","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_unif_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from an Uniform to a standard Normal distribution — inv_unif_t","title":"Copula transformation from an Uniform to a standard Normal distribution — inv_unif_t","text":"Copula transformation Uniform standard Normal distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_unif_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from an Uniform to a standard Normal distribution — inv_unif_t","text":"","code":"inv_unif_t(x, a, b)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_unif_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from an Uniform to a standard Normal distribution — inv_unif_t","text":"x values Uniform distribution, vector. minimum Uniform distribution, scalar. b maximum Uniform distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/inv_unif_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from an Uniform to a standard Normal distribution — inv_unif_t","text":"values standard Normal distribution, vector length x","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/lambda_N.html","id":null,"dir":"Reference","previous_headings":"","what":"Calculate the integral of the ETAS conditional intensity — lambda_N","title":"Calculate the integral of the ETAS conditional intensity — lambda_N","text":"Calculate number events time interval T1 T2 given imposed events ETAS","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/lambda_N.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Calculate the integral of the ETAS conditional intensity — lambda_N","text":"","code":"lambda_N(th.mu, th.K, th.alpha, th.c, th.p, T1, T2, M0, Ht, link.functions)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/lambda_N.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Calculate the integral of the ETAS conditional intensity — lambda_N","text":"th.mu Background rate, mu, internal parameter scale th.K ETAS triggering parameter K internal parameter scale th.alpha ETAS triggering parameter alpha internal parameter scale th.c ETAS triggering parameter c internal parameter scale th.p ETAS triggering parameter p internal parameter scale T1 Start temporal model domain. T2 End temporal model domain. M0 Minimum magnitude threshold Ht History process, set known events interval. must data.frame columns ts (time) magnitudes (magnitudes). link.functions list functions transform parameters internal scale ETAS scale","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/lambda_N.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Calculate the integral of the ETAS conditional intensity — lambda_N","text":"Integral ETAS conditional intensity T1 T2 minimum magnitude M0, .e. expected number events.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/log_Lambda_h.html","id":null,"dir":"Reference","previous_headings":"","what":"Logarithm of the integral of the ETAS triggering function — log_Lambda_h","title":"Logarithm of the integral of the ETAS triggering function — log_Lambda_h","text":"Logarithm integral ETAS triggering function","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/log_Lambda_h.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Logarithm of the integral of the ETAS triggering function — log_Lambda_h","text":"","code":"log_Lambda_h(theta, th, mh, M0, T1, T2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/log_Lambda_h.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Logarithm of the integral of the ETAS triggering function — log_Lambda_h","text":"theta ETAS parameters data.frame(mu=mu, K=K, alpha=alpha, c=c, p=p). th Time parent event. mh Magnitude parent event M0 Minimum magnitude threshold T1 Start temporal model domain. T2 End temporal model domain.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/log_Lambda_h.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Logarithm of the integral of the ETAS triggering function — log_Lambda_h","text":"Logarithm integral ETAS triggering function","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/loggaus_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from a standard Normal distribution to a Log-Normal distribution — loggaus_t","title":"Copula transformation from a standard Normal distribution to a Log-Normal distribution — loggaus_t","text":"Copula transformation standard Normal distribution Log-Normal distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/loggaus_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from a standard Normal distribution to a Log-Normal distribution — loggaus_t","text":"","code":"loggaus_t(x, m, s)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/loggaus_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from a standard Normal distribution to a Log-Normal distribution — loggaus_t","text":"x values standard Normal distribution, vector. m mean logarithm Log-Normal distribution, scalar. s standard deviation logarithm Log-Normal distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/loggaus_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from a standard Normal distribution to a Log-Normal distribution — loggaus_t","text":"Values Log-Normal distribution logarithmic mean m standard deviation s, vector length x.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to calculate Omori's law — omori","title":"Function to calculate Omori's law — omori","text":"Function calculate Omori's law","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to calculate Omori's law — omori","text":"","code":"omori(theta, t, ti)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to calculate Omori's law — omori","text":"theta ETAS parameters (list(mu = mu, K = K, alpha = alpha, c = c, p = p), parameters c p used t Time Omori's law evaluated ti Time event history","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to calculate Omori's law — omori","text":"Value Omori's law point t event happened ti","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_posterior.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to plot Omori's law corresponding to different posterior samples — omori_plot_posterior","title":"Function to plot Omori's law corresponding to different posterior samples — omori_plot_posterior","text":"Function plot Omori's law corresponding different posterior samples","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_posterior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to plot Omori's law corresponding to different posterior samples — omori_plot_posterior","text":"","code":"omori_plot_posterior(   input.list,   post.samp = NULL,   n.samp = 10,   t.end = 1,   n.breaks = 100 )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_posterior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to plot Omori's law corresponding to different posterior samples — omori_plot_posterior","text":"input.list structured input list least two elements: model.fit: bru object used sample posterior ETAS parameters link.functions: list functions convert ETAS parameters INLA scale ETAS scale post.samp data.frame containing posterior samples parameters. NULL, n.samp samples generated. n.samp different nrow(post.samp) n.samp rows uniformly sampled post.samp. Default NULL. n.samp Number posterior samples, integer (default = 10). t.end Upper bound x-axis, scalar (default = 1). n.breaks Number points 0 t.end calculate function, integer (default = 100).","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_posterior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to plot Omori's law corresponding to different posterior samples — omori_plot_posterior","text":"ggplot object","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to plot Omori's law corresponding to different prior samples — omori_plot_prior","title":"Function to plot Omori's law corresponding to different prior samples — omori_plot_prior","text":"Function plot Omori's law corresponding different prior samples","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to plot Omori's law corresponding to different prior samples — omori_plot_prior","text":"","code":"omori_plot_prior(input.list, n.samp = 10, t.end = 1, n.breaks = 100)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to plot Omori's law corresponding to different prior samples — omori_plot_prior","text":"input.list structured input list least one element: link.functions: list functions convert ETAS parameters INLA scale ETAS scale n.samp Number posterior samples, integer (default = 10). t.end Upper bound x-axis, scalar (default = 1). n.breaks Number points 0 t.end calculate function, integer (default = 100).","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/omori_plot_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to plot Omori's law corresponding to different prior samples — omori_plot_prior","text":"ggplot object","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_pairs_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Plot the posterior densities of the ETAS parameters — post_pairs_plot","title":"Plot the posterior densities of the ETAS parameters — post_pairs_plot","text":"Plot posterior densities ETAS parameters","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_pairs_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plot the posterior densities of the ETAS parameters — post_pairs_plot","text":"","code":"post_pairs_plot(   input.list = NULL,   n.samp = NULL,   post.samp = NULL,   max.batch = 1000 )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_pairs_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plot the posterior densities of the ETAS parameters — post_pairs_plot","text":"input.list structured input list least two elements: model.fit: bru object used sample posterior ETAS parameters link.functions: list functions convert ETAS parameters INLA scale ETAS scale n.samp number samples draw posteriors plot post.samp data.frame columns mu, K, alpha, c, p rows corresponding different posterior samples. NULL function samples joint posterior distribution n.samp times. default NULL. max.batch parameter post_sampling function used case post.samp = NULL","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_pairs_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plot the posterior densities of the ETAS parameters — post_pairs_plot","text":"list: elements post.samp.df:data.frame posterior samples nrow = n.samp columns mu, K, alpha, c, p corresponding ETAS parameters. post.samp NULL returns post.samp pair.plot: ggplot object reporting pair plot parameters samples. obtained using ggpairs function Ggally library","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_sampling.html","id":null,"dir":"Reference","previous_headings":"","what":"Sample from the posterior of the ETAS parameters — post_sampling","title":"Sample from the posterior of the ETAS parameters — post_sampling","text":"Sample posterior ETAS parameters","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_sampling.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sample from the posterior of the ETAS parameters — post_sampling","text":"","code":"post_sampling(input.list, n.samp, max.batch = 1000, ncore = 1)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_sampling.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sample from the posterior of the ETAS parameters — post_sampling","text":"input.list structured input list least two elements: model.fit: bru object used sample posterior ETAS parameters link.functions: list functions convert ETAS parameters INLA scale ETAS scale n.samp number samples draw posteriors max.batch Maximum number posterior samples generated simultaneously. Default 1000. ncore Number cores used n.samp exceeds max.batch. Default 1","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/post_sampling.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sample from the posterior of the ETAS parameters — post_sampling","text":"data.frame posterior samples nrow = n.samp columns mu, K, alpha, c, p corresponding ETAS parameters.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_GR_magnitudes.html","id":null,"dir":"Reference","previous_headings":"","what":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","title":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","text":"Return sample magnitudes drawn GR distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_GR_magnitudes.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","text":"","code":"sample_GR_magnitudes(n, beta.p, M0)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_GR_magnitudes.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","text":"n Number events sample. beta.p Related b-value via b ln(10). M0 Minimum magnitude sample.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_GR_magnitudes.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","text":"list magnitudes length n drawn GR distribution.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_GR_magnitudes.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Return a sample of magnitudes drawn from the GR distribution — sample_GR_magnitudes","text":"","code":"sample_GR_magnitudes(n = 100, beta.p = log(10), M0 = 2.5) #>   [1] 2.563625 3.044290 2.770117 2.848921 2.833841 2.527470 2.576935 3.216981 #>   [9] 3.307933 2.975841 2.913140 2.568385 3.792889 2.709000 2.818547 2.716959 #>  [17] 2.779336 2.559271 2.587460 2.523337 3.356719 4.549608 2.611074 2.708790 #>  [25] 3.256245 2.504656 2.561985 3.873829 2.765855 3.042014 2.529586 3.282631 #>  [33] 2.887395 2.750460 2.647841 2.503358 2.703423 2.763432 3.656803 2.857606 #>  [41] 2.501426 4.628313 2.545441 3.581096 2.820538 3.224139 2.737966 2.523516 #>  [49] 2.845871 3.934745 2.600856 2.624768 2.559385 3.227851 2.571346 2.543537 #>  [57] 2.688888 2.511312 2.745993 2.687224 2.749366 2.905425 2.964867 2.876985 #>  [65] 2.920979 4.115747 3.314977 4.817524 3.014441 2.880645 3.361048 2.968897 #>  [73] 3.512561 2.842806 2.614647 2.546635 2.671348 2.830045 2.890637 2.929516 #>  [81] 3.114020 4.038268 2.693748 2.506151 2.571463 2.767798 3.002019 3.195095 #>  [89] 2.613549 2.912089 2.516853 2.580288 2.890254 2.729211 2.733918 2.699733 #>  [97] 3.051525 3.583169 2.646968 3.277088"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_daughters.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a sample of new events data.frame(t_i, M_i) of length n.ev for one parent event occuring at time t_h using the ETAS model. — sample_temporal_ETAS_daughters","title":"Generate a sample of new events data.frame(t_i, M_i) of length n.ev for one parent event occuring at time t_h using the ETAS model. — sample_temporal_ETAS_daughters","text":"Generate sample new events data.frame(t_i, M_i) length n.ev one parent event occuring time t_h using ETAS model.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_daughters.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a sample of new events data.frame(t_i, M_i) of length n.ev for one parent event occuring at time t_h using the ETAS model. — sample_temporal_ETAS_daughters","text":"","code":"sample_temporal_ETAS_daughters(theta, beta.p, th, n.ev, M0, T1, T2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_daughters.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a sample of new events data.frame(t_i, M_i) of length n.ev for one parent event occuring at time t_h using the ETAS model. — sample_temporal_ETAS_daughters","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p). beta.p Slope GR relation: beta = b ln(10). th Time parent event [days]. n.ev number events placed. M0 Minimum magnitude synthetic catalogue. T1 Start time synthetic catalogue [days]. T2 End time synthetic catalogue [days].","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_daughters.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a sample of new events data.frame(t_i, M_i) of length n.ev for one parent event occuring at time t_h using the ETAS model. — sample_temporal_ETAS_daughters","text":"Generate sample new events data.frame(t_i, M_i) one parent","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_generation.html","id":null,"dir":"Reference","previous_headings":"","what":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","title":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","text":"Take previous parent events Ht=data.frame[ts, magnitudes] generates daughters events using ETAS model","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_generation.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","text":"","code":"sample_temporal_ETAS_generation(theta, beta.p, Ht, M0, T1, T2, ncore = 1)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_generation.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p). beta.p Slope GR relation: beta = b ln(10). Ht set parent events form data.frame[ts, magnitudes] M0 minimum earthquake magnitude synthetic catalogue. T1 start time synthetic catalogue [days]. T2 end time synthetic catalogue [days]. ncore number compute cores use","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_generation.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","text":"Return one generation daughters parents Ht form data.frame(t_i, M_i).","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_generation.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Take all previous parent events from Ht=data.frame[ts, magnitudes] and generates their daughters events using the ETAS model — sample_temporal_ETAS_generation","text":"","code":"# The parents are specified in Ht Ht <- data.frame(ts = c(500), magnitudes = c(6.7)) sample_temporal_ETAS_generation(   theta = list(mu = 0.1, K = 0.089, alpha = 2.29, c = 0.11, p = 1.08),   beta.p = log(10),   M0 = 2.5,   T1 = 0, T2 = 1000,   Ht = Ht ) #>           ts magnitudes #> 1   500.1015   2.750246 #> 2   500.0281   2.584738 #> 3   504.9414   3.443449 #> 4   500.2880   3.669596 #> 5   509.9570   2.585078 #> 6   500.3548   2.916276 #> 7   809.9623   2.767364 #> 8   542.1763   2.576170 #> 9   500.7494   3.385011 #> 10  971.2221   2.891319 #> 11  620.6130   3.327565 #> 12  501.1130   3.001727 #> 13  504.0457   3.074665 #> 14  500.6810   2.512749 #> 15  500.2466   2.619697 #> 16  555.1395   2.741263 #> 17  503.0386   3.189324 #> 18  500.4488   2.714058 #> 19  510.0144   2.739719 #> 20  525.7740   3.117974 #> 21  812.8784   2.759114 #> 22  917.7037   2.866731 #> 23  500.1858   2.719556 #> 24  507.2087   2.662111 #> 25  819.2437   2.905725 #> 26  689.5248   3.995237 #> 27  566.1242   2.691618 #> 28  720.2489   3.101058 #> 29  500.1246   2.741180 #> 30  571.0419   3.239979 #> 31  984.3579   2.656850 #> 32  547.6523   3.378622 #> 33  501.1448   2.631052 #> 34  612.5281   2.750608 #> 35  500.0256   2.697625 #> 36  522.2394   3.267267 #> 37  500.2342   2.567884 #> 38  796.0734   2.517406 #> 39  500.7300   3.742129 #> 40  500.0757   2.526443 #> 41  500.0291   2.908427 #> 42  500.7305   3.060176 #> 43  504.2055   2.649164 #> 44  500.6709   2.536099 #> 45  500.1907   2.726141 #> 46  500.2273   2.577117 #> 47  534.1098   2.544288 #> 48  513.8655   2.921214 #> 49  511.6555   2.655544 #> 50  500.0434   2.615207 #> 51  582.1097   2.691556 #> 52  507.1576   2.815088 #> 53  502.7685   2.521885 #> 54  500.5350   2.592492 #> 55  569.4163   3.221517 #> 56  507.1853   3.056150 #> 57  899.9334   3.256647 #> 58  500.0097   2.845636 #> 59  707.2295   3.154556 #> 60  511.7118   2.694007 #> 61  505.2846   2.940886 #> 62  500.0958   2.924882 #> 63  621.0772   2.893547 #> 64  611.5725   2.542582 #> 65  500.8311   2.549217 #> 66  548.4560   4.016520 #> 67  500.2889   4.061423 #> 68  519.4462   2.741049 #> 69  500.2375   2.562865 #> 70  502.3501   2.969610 #> 71  504.6558   2.728465 #> 72  934.7663   2.813222 #> 73  500.3375   2.618493 #> 74  553.7785   2.601782 #> 75  500.0712   2.623197 #> 76  502.7076   2.524778 #> 77  512.1314   2.702087 #> 78  500.1180   3.121342 #> 79  500.8435   2.911489 #> 80  502.9034   2.535221 #> 81  500.5905   3.488460 #> 82  568.7095   2.570312 #> 83  501.3573   2.774717 #> 84  502.6788   2.705019 #> 85  500.6858   2.643744 #> 86  764.5836   3.402051 #> 87  500.0108   3.164827 #> 88  510.1281   2.600395 #> 89  502.0456   2.589726 #> 90  622.2179   2.653619 #> 91  528.6920   2.635555 #> 92  501.9898   2.641729 #> 93  501.9831   2.911146 #> 94  500.0056   3.168967 #> 95  501.0912   2.783080 #> 96  715.5636   2.503121 #> 97  500.2195   2.652337 #> 98  546.2571   2.680546 #> 99  526.3649   2.945767 #> 100 500.5466   3.353490 #> 101 501.2936   3.108510 #> 102 500.4274   2.749166 #> 103 500.1754   2.656698 #> 104 532.2808   6.036101 #> 105 518.6508   2.719481 #> 106 503.0301   2.744544 #> 107 778.9656   2.918477 #> 108 805.1416   2.786283 #> 109 500.0321   2.751496 #> 110 504.3599   2.764571 #> 111 538.2423   2.937310 #> 112 502.4536   2.881805 #> 113 500.2623   2.559812 #> 114 506.6057   2.534132 #> 115 543.5908   2.632480 #> 116 512.3140   2.678885 #> 117 543.5055   3.461100 #> 118 500.3005   2.988210 #> 119 500.3507   2.511544 #> 120 500.0003   2.527252 #> 121 631.0861   3.055447 #> 122 500.0132   2.582417 #> 123 500.2172   2.805912 #> 124 503.1307   3.185648 #> 125 515.6333   2.728950 #> 126 517.8086   2.837072 #> 127 502.1292   2.633295 #> 128 507.4725   2.507238 #> 129 500.2236   2.586979 #> 130 503.4364   2.500297 #> 131 500.5084   2.880424 #> 132 682.6339   3.216074 #> 133 500.0736   3.002705 #> 134 558.7322   3.400874 #> 135 500.1057   2.551661 #> 136 500.1953   2.699902 #> 137 501.2590   2.517856 #> 138 510.2948   2.505017 #> 139 526.1478   4.346970 #> 140 500.2137   2.547937 #> 141 529.5672   2.601343 #> 142 787.1049   4.211495 #> 143 648.5572   2.778176 #> 144 501.0564   3.200496 #> 145 515.1209   2.688285 #> 146 501.1473   2.557858 #> 147 732.0353   2.600420 #> 148 500.2855   2.687449 #> 149 500.1528   2.578459 #> 150 500.0887   2.798536 #> 151 500.3897   2.612731 #> 152 502.0126   2.921924 #> 153 503.9133   2.890494 #> 154 500.1789   2.887483 #> 155 991.0204   2.743293 #> 156 500.0126   2.834017 #> 157 631.9365   2.974102 #> 158 524.5238   2.561476 #> 159 502.6473   2.654338 #> 160 502.0390   2.628689 #> 161 500.0444   2.586071 #> 162 504.0465   3.159208 #> 163 500.8125   3.447712 #> 164 591.7819   2.541301 #> 165 500.0383   3.087391 #> 166 500.0048   3.506161 #> 167 568.8941   3.798392 #> 168 873.1703   2.542983 #> 169 500.0567   3.062306 #> 170 678.9523   2.625211 #> 171 518.3107   2.655674 #> 172 500.6747   3.317800 #> 173 578.1218   3.104696 #> 174 505.4250   2.807487 #> 175 514.4499   2.643197 #> 176 500.2599   2.759917 #> 177 504.4213   2.695745 #> 178 500.1564   2.854137 #> 179 530.1384   3.243892 #> 180 500.7433   2.623813 #> 181 596.7280   2.585697 #> 182 500.0499   2.790728 #> 183 506.6826   2.520503 #> 184 500.1113   4.251736 #> 185 502.2506   3.301079 #> 186 508.7383   2.724347 #> 187 509.7489   2.726424 #> 188 500.1859   3.826505 #> 189 583.7496   2.807185 #> 190 873.0630   2.851209 #> 191 500.0045   2.714532 #> 192 500.2244   3.714064 #> 193 504.7677   2.527236 #> 194 500.0008   2.500313 #> 195 500.0890   2.770111 #> 196 500.4064   2.791976 #> 197 517.6211   3.918643 #> 198 509.0966   2.719440 #> 199 500.0173   2.572749 #> 200 622.0067   3.124243 #> 201 504.8242   2.685992 #> 202 500.3427   2.788576 #> 203 663.4903   2.552921 #> 204 508.2861   2.752119 #> 205 509.3134   2.537514 #> 206 500.0570   3.354063 #> 207 500.0559   2.520902 #> 208 548.3798   2.746468 #> 209 500.0390   2.580597 #> 210 503.0985   3.054992 #> 211 500.0517   2.682407 #> 212 603.5043   2.550675 #> 213 519.8736   2.817505 #> 214 500.0654   2.802911 #> 215 642.6058   4.343701 #> 216 500.5406   2.908293 #> 217 509.9259   2.542963 #> 218 969.1606   2.555862 #> 219 512.9304   2.737804 #> 220 656.6122   2.776013 #> 221 580.6057   3.101004 #> 222 501.2565   3.560043 #> 223 520.4295   2.708677 #> 224 500.1804   2.644359 #> 225 502.0848   3.048162 #> 226 500.0960   4.016051 #> 227 506.8509   2.570315 #> 228 500.4822   2.679599 #> 229 502.1991   2.934709 #> 230 509.0934   2.757199 #> 231 508.3737   3.060757 #> 232 506.2844   2.785513 #> 233 610.3285   3.172793 #> 234 500.0960   2.824196 #> 235 500.2499   4.561786 #> 236 598.3304   3.558659 #> 237 504.1093   3.514753 #> 238 500.4219   2.734894 #> 239 502.6741   3.506721 #> 240 500.0412   2.677067 #> 241 504.5144   2.716316 #> 242 500.4093   3.262625 #> 243 502.8366   2.927829 #> 244 500.5908   2.668108 #> 245 525.0617   2.543936 #> 246 500.1634   3.060274 #> 247 500.1693   3.061516 #> 248 501.4130   2.837507 #> 249 513.9688   2.760817 #> 250 501.3772   2.502423 #> 251 510.5908   2.783993 #> 252 503.1070   3.428513 #> 253 500.3030   2.604067 #> 254 614.2983   3.090714 #> 255 512.8197   2.786624 #> 256 501.0037   2.694679 #> 257 500.3217   2.566509 #> 258 500.3432   2.521349 #> 259 500.2118   2.547626 #> 260 509.1174   2.881838 #> 261 500.0184   2.692319 #> 262 623.6802   3.735415 #> 263 508.4031   2.678957 #> 264 501.0413   2.794304 #> 265 500.4381   2.679991 #> 266 500.9392   3.704813 #> 267 500.1753   2.634790 #> 268 506.4549   3.228371 #> 269 693.3128   3.647369 #> 270 500.4995   2.579126 #> 271 590.7393   2.875121 #> 272 980.9726   2.654133 #> 273 507.8658   2.887064 #> 274 500.5325   2.739591 #> 275 514.8083   2.500703 #> 276 500.2768   2.500333 #> 277 500.5645   2.913499 #> 278 509.5455   2.950411 #> 279 507.9477   2.693292 #> 280 500.0454   2.858860 #> 281 500.3371   2.691564 #> 282 541.7363   2.729136 #> 283 930.7826   2.800708 #> 284 505.1952   2.637856 #> 285 507.4901   2.622129 #> 286 500.0630   3.133236 #> 287 590.1887   2.867184 #> 288 570.7517   2.533742 #> 289 574.6124   2.595857 #> 290 506.5703   4.929288 #> 291 525.6326   2.690129 #> 292 518.5080   2.506044 #> 293 511.4040   3.184985 #> 294 500.1380   2.997039 #> 295 513.5726   2.971580 #> 296 516.6847   2.672892 #> 297 502.0985   2.921126 #> 298 506.9738   3.114500 #> 299 827.7484   2.545294 #> 300 503.8701   2.663250 #> 301 501.5207   2.538533 #> 302 502.6828   2.622666 #> 303 655.3763   2.661931 #> 304 724.9602   2.523300 #> 305 500.6113   3.574160 #> 306 500.1639   3.427164 #> 307 546.4744   2.576914 #> 308 722.8450   2.908421 #> 309 751.9061   2.763896 #> 310 588.4911   3.029235 #> 311 500.1921   2.521389 #> 312 524.3524   2.513015 #> 313 501.8045   2.544541 #> 314 554.2235   4.274627 #> 315 529.8649   3.554307 #> 316 522.6898   3.254260 #> 317 528.2416   2.889533 #> 318 879.0357   3.908654 #> 319 645.5917   2.588273 #> 320 500.7787   3.402876 #> 321 536.1104   2.952578 #> 322 553.3524   3.074472 #> 323 505.8712   2.501272 #> 324 900.7159   3.438427 #> 325 555.9118   4.080074 #> 326 504.3791   2.987125 #> 327 500.6696   2.744281 #> 328 501.3355   2.710217 #> 329 502.3113   3.185123 #> 330 503.1076   2.750165 #> 331 500.4311   2.722119 #> 332 501.5201   2.588474 #> 333 500.0258   2.829164 #> 334 500.0805   2.653995 #> 335 525.4251   3.125669 #> 336 561.2837   2.816486 #> 337 509.0854   2.729244 #> 338 532.9322   3.092257 #> 339 500.0601   2.534393 #> 340 505.2820   2.949771 #> 341 500.0256   2.824240 #> 342 502.3124   2.607187 #> 343 501.3254   2.530604 #> 344 528.7380   2.806511 #> 345 865.3573   2.713369 #> 346 501.3949   2.530504 #> 347 899.3890   2.861396 #> 348 500.4544   2.627833 #> 349 553.1159   3.179558 #> 350 500.7064   2.902594 #> 351 500.9495   2.535281 #> 352 502.4806   2.614171 #> 353 500.0427   3.242488 #> 354 500.9833   2.645871 #> 355 504.2617   2.654490 #> 356 606.7514   2.744194 #> 357 500.0276   2.941406 #> 358 730.0930   2.588055 #> 359 842.5394   2.884493 #> 360 501.9560   3.454133 #> 361 500.1832   3.229403 #> 362 516.3356   3.481275 #> 363 618.5805   2.588302 #> 364 728.9274   3.362547 #> 365 500.9163   2.760878 #> 366 500.2264   2.506266 #> 367 500.6165   2.685499 #> 368 502.6625   2.615395 #> 369 500.1354   2.501938 #> 370 742.9723   2.825732 #> 371 500.2078   3.346502 #> 372 519.5534   2.593437 #> 373 502.5173   2.959554 #> 374 513.4563   2.707161 #> 375 500.5664   3.015237 #> 376 663.3984   2.744668 #> 377 833.6447   2.686472 #> 378 500.0377   2.718827 #> 379 501.1246   2.764180 #> 380 506.3571   2.654793 #> 381 517.0098   2.660665 #> 382 501.9802   3.070940 #> 383 500.1529   3.452910 #> 384 575.9979   3.167518 #> 385 501.3644   3.339886 #> 386 503.2058   2.830000 #> 387 505.4663   2.519561 #> 388 500.1196   3.375297 #> 389 501.1383   2.823522 #> 390 506.2434   3.078337 #> 391 500.0744   3.032511 #> 392 972.9116   2.607340 #> 393 801.6632   3.172402 #> 394 508.3338   2.800230 #> 395 500.0564   2.525426 #> 396 512.4814   2.535891 #> 397 500.3089   2.985477 #> 398 651.7114   2.668550 #> 399 500.1211   3.078217 #> 400 850.8948   2.643739 #> 401 501.3576   2.754596 #> 402 500.5868   2.922503 #> 403 713.8365   2.624314 #> 404 583.9425   2.915189 #> 405 540.3615   2.501065 #> 406 520.7667   3.354212 #> 407 500.1942   2.550108 #> 408 564.5666   2.666021 #> 409 500.0570   2.969415 #> 410 595.4244   4.345995 #> 411 502.5155   2.574454 #> 412 500.0540   2.805314 #> 413 529.6242   3.043759 #> 414 500.1341   2.631361 #> 415 500.0183   3.035374 #> 416 530.0282   3.090748 #> 417 500.3006   3.142368 #> 418 500.3668   3.161614 #> 419 537.5752   2.648027 #> 420 501.4637   2.842271 #> 421 535.2752   3.444935 #> 422 500.2773   2.522180 #> 423 502.8647   3.298091 #> 424 521.4026   2.770636 #> 425 500.2034   3.343203 #> 426 512.5545   3.051633 #> 427 500.1717   3.524355 #> 428 500.2408   2.579794 #> 429 510.1327   3.609929 #> 430 500.7731   3.327765 #> 431 630.3120   2.989186 #> 432 504.4548   2.575764 #> 433 535.3678   3.568219 #> 434 500.9077   2.503268 #> 435 501.2451   2.761666 #> 436 670.6755   2.558039 #> 437 508.8368   2.770640 #> 438 530.2180   2.503006 #> 439 512.9331   3.369625 #> 440 509.3514   2.988169 #> 441 557.6919   3.929912 #> 442 501.6957   3.287441 #> 443 500.0184   3.387608 #> 444 502.2567   3.449858 #> 445 500.3538   2.608713 #> 446 503.7071   2.863496 #> 447 502.9398   2.608580 #> 448 507.2189   4.018596 #> 449 500.3286   2.752688 #> 450 588.7453   3.532290 #> 451 500.3221   3.206124 #> 452 918.4584   3.132772 #> 453 500.1406   2.979867 #> 454 507.7438   2.729587 #> 455 503.8822   3.408567 #> 456 500.0594   2.559221 #> 457 514.8779   2.759671 #> 458 545.8278   2.507570 #> 459 513.4121   2.785653 #> 460 512.5543   3.403199 #> 461 500.2611   2.839412 #> 462 503.7906   2.642603 #> 463 500.1485   2.657388 #> 464 526.9700   2.622485 #> 465 727.8507   2.524086 #> 466 502.6687   2.630088 #> 467 500.1888   2.846944 #> 468 501.3839   2.918530 #> 469 943.2428   3.782708 #> 470 500.8900   2.693026 #> 471 501.2110   2.667161 #> 472 500.0253   3.466914 #> 473 533.5646   3.175124 #> 474 501.7599   2.647953 #> 475 500.0405   2.947429 #> 476 500.0038   3.368347 #> 477 503.8847   2.503199 #> 478 500.0429   3.355887 #> 479 500.0723   2.912849 #> 480 537.8243   2.698781 #> 481 500.1417   2.716572 #> 482 500.1420   3.334787 #> 483 506.5561   2.651376 #> 484 514.4066   2.653071 #> 485 500.0829   3.002973 #> 486 516.4208   3.156788 #> 487 500.9040   2.893003 #> 488 536.7279   2.897655 #> 489 500.0088   2.749386 #> 490 509.7076   3.203470 #> 491 501.4261   3.076029 #> 492 506.9345   2.652134 #> 493 723.7732   2.729916 #> 494 500.8085   2.892154 #> 495 502.3086   2.695688 #> 496 504.3111   3.280373 #> 497 500.0919   2.967158 #> 498 502.9244   2.561133 #> 499 556.1115   2.944726 #> 500 533.4734   2.571294 #> 501 504.3438   2.667021 #> 502 500.0036   2.745481 #> 503 598.6639   2.733059 #> 504 718.5151   2.584740 #> 505 511.1602   2.977257 #> 506 602.6424   3.440290 #> 507 507.2797   2.732657 #> 508 580.2812   3.341959 #> 509 878.5377   2.990954 #> 510 500.6644   2.767570 #> 511 540.8097   2.920005 #> 512 655.3600   2.580470 #> 513 820.5870   2.818846 #> 514 574.1664   3.247093 #> 515 595.1988   2.620969 #> 516 500.4115   2.585971 #> 517 566.8779   2.807885 #> 518 500.1869   2.941398 #> 519 502.5759   3.072586 #> 520 500.7022   2.547877 #> 521 535.6365   3.493509 #> 522 600.4456   3.097760 #> 523 513.5284   2.881946 #> 524 500.0071   2.672325 #> 525 500.0181   2.930203 #> 526 502.2287   4.163326 #> 527 617.6224   2.644562 #> 528 927.6883   2.536479 #> 529 500.1623   2.669069 #> 530 500.6675   2.871055 #> 531 503.5228   3.070659 #> 532 502.2391   2.581134 #> 533 501.1069   2.720924 #> 534 676.9297   2.896842 #> 535 500.0977   3.009809 #> 536 501.3504   2.624906 #> 537 509.3685   2.906904 #> 538 500.0863   2.533554 #> 539 507.5999   4.435461 #> 540 500.4368   3.038973 #> 541 500.5463   2.787337 #> 542 500.2034   2.793383 #> 543 528.1744   2.679380 #> 544 500.6509   3.247311 #> 545 513.5055   2.788170 #> 546 501.1290   2.672998 #> 547 501.1131   2.779975 #> 548 529.3555   3.600674 #> 549 591.2866   2.617940 #> 550 501.1992   2.569734 #> 551 500.3247   3.652068 #> 552 500.0552   2.746182 #> 553 500.2569   3.936921 #> 554 500.1945   3.067838 #> 555 504.2464   3.398402 #> 556 992.4507   2.520336 #> 557 533.2395   2.857104 #> 558 506.1646   2.896013 #> 559 500.2259   3.003411 #> 560 500.1387   3.150223 #> 561 500.5216   2.544863 #> 562 500.0992   2.874824 #> 563 500.7238   2.984053 #> 564 503.1999   2.523370 #> 565 548.8095   3.029391 #> 566 559.3386   4.236732 #> 567 696.5249   2.603156 #> 568 500.1149   2.594162 #> 569 508.0531   4.370255 #> 570 923.1941   2.809199 #> 571 514.4093   3.598297 #> 572 500.3705   2.712971 #> 573 642.6284   2.528022 #> 574 500.0052   3.333756 #> 575 601.0929   2.768391 #> 576 502.1095   3.006716 #> 577 500.0286   2.682076 #> 578 500.4637   2.561799 #> 579 566.6704   2.522127 #> 580 505.7797   2.933187 #> 581 576.3840   2.978170 #> 582 500.0458   2.803484 #> 583 538.0750   3.381179 #> 584 523.6622   2.799253 #> 585 507.3969   2.596609 #> 586 500.7464   2.566740 #> 587 501.2238   2.778466 #> 588 501.0263   2.512667 #> 589 503.2092   2.591730 #> 590 501.6959   2.586523 #> 591 500.0590   2.521609 #> 592 503.2099   3.011835 #> 593 504.6929   2.902227 #> 594 632.7436   3.324343 #> 595 500.1163   2.620431 #> 596 595.0556   2.655824 #> 597 528.4282   2.830881 #> 598 500.0145   3.668858 #> 599 572.6639   2.501926 #> 600 500.4036   3.135585 #> 601 500.9242   3.640143 #> 602 510.4534   2.665422 #> 603 512.7289   2.711038 #> 604 510.2145   3.382064 #> 605 568.8720   2.840252 #> 606 509.0637   2.887069 #> 607 530.0629   2.938896 #> 608 500.4179   2.857457 #> 609 502.2600   2.694421 #> 610 682.0328   4.066328 #> 611 500.1216   2.575721 #> 612 964.8056   3.830990 #> 613 553.8599   3.031648 #> 614 662.2219   2.942862 #> 615 521.0171   2.728645 #> 616 501.4003   2.986621 #> 617 572.3356   2.940003 #> 618 500.4572   2.527699 #> 619 500.1829   2.974342 #> 620 501.7776   2.876064 #> 621 501.8462   3.693014 #> 622 551.9988   2.550636 #> 623 658.7194   2.961475 #> 624 994.3146   2.806462 #> 625 512.5224   2.701851 #> 626 511.8334   2.531781 #> 627 504.8757   3.548275 #> 628 503.4871   2.699542 #> 629 500.3930   3.183356 #> 630 500.3633   3.109655 #> 631 521.3541   2.559694 #> 632 502.4443   3.067399 #> 633 554.3020   3.413741 #> 634 500.0336   3.089718 #> 635 517.5010   4.381985 #> 636 506.0977   2.532211 #> 637 666.6334   2.863055 #> 638 500.4193   3.684381 #> 639 500.5154   2.541003 #> 640 544.5285   2.697772 #> 641 524.2326   3.067578 #> 642 520.0931   2.574508 #> 643 501.3829   3.105528 #> 644 500.1766   2.520267 #> 645 503.8317   3.188060 #> 646 565.0208   2.712217 #> 647 657.9539   3.129943 #> 648 502.6698   2.748337 #> 649 988.7555   2.557963 #> 650 500.6355   3.107316 #> 651 501.0324   2.973494 #> 652 500.8071   2.502921 #> 653 502.5489   4.629403 #> 654 509.0949   2.813634 #> 655 627.4430   2.798820 #> 656 500.0787   2.504649 #> 657 506.7383   2.587706 #> 658 500.5201   2.862731 #> 659 500.4153   2.671019 #> 660 573.4416   2.552229 #> 661 501.5082   2.982566 #> 662 510.4975   2.560359 #> 663 504.8127   2.507365 #> 664 590.9271   3.223165 #> 665 500.3749   2.892463 #> 666 503.7051   2.874337 #> 667 576.9294   2.910628 #> 668 503.1965   2.824307 #> 669 501.1135   3.264220 #> 670 500.8831   3.098487 #> 671 501.3186   3.880584 #> 672 512.5237   3.650517 #> 673 508.2332   2.642728 #> 674 504.6132   3.151442 #> 675 500.7798   2.661151 #> 676 500.0369   3.267876 #> 677 512.4310   4.548061 #> 678 502.1370   3.360017 #> 679 510.7692   2.810272 #> 680 500.1033   3.322431 #> 681 500.5689   2.741473 #> 682 504.8400   3.643147 #> 683 522.2039   3.742063 #> 684 690.0676   2.504004 #> 685 500.0008   3.652810 #> 686 540.0968   2.594550 #> 687 503.0388   2.605144 #> 688 501.9734   2.694036 #> 689 721.4908   2.560537 #> 690 500.9970   2.671471 #> 691 500.7067   3.522632 #> 692 500.5765   2.514552 #> 693 500.3015   3.920757 #> 694 501.3936   3.641575 #> 695 505.4762   2.580464 #> 696 500.1891   3.145627 #> 697 510.0988   2.613289 #> 698 578.1917   2.825905 #> 699 500.3860   3.277086 #> 700 502.8266   2.872614 #> 701 500.2012   2.982668 #> 702 522.6961   2.578204 #> 703 631.7898   3.262493 #> 704 502.0923   2.929935 #> 705 501.1157   2.509729 #> 706 539.2592   3.231477 #> 707 527.0769   2.545965 #> 708 500.2490   2.613351 #> 709 513.9185   3.220933 #> 710 503.2803   2.651320 #> 711 515.8384   3.271913 #> 712 545.8267   3.082657 #> 713 501.0176   3.105427 #> 714 507.5317   3.480096 #> 715 500.0611   3.494172 #> 716 500.7322   2.650152 #> 717 505.8289   2.799698 #> 718 500.7628   2.555969 #> 719 537.6191   3.011695 #> 720 510.7066   2.776906 #> 721 500.0419   2.839030 #> 722 962.8286   2.835098 #> 723 503.1393   3.042504 #> 724 500.1848   2.752813 #> 725 500.1744   2.528183 #> 726 583.2176   3.158260 #> 727 500.3813   2.852583 #> 728 501.5829   2.791527 #> 729 501.3219   3.651138 #> 730 514.2605   2.527446 #> 731 532.6172   3.469434 #> 732 500.0384   3.242890 #> 733 507.4489   2.568814 #> 734 500.5769   2.996896 #> 735 500.0248   2.595376 #> 736 501.6838   2.813786 #> 737 507.5481   2.612345 #> 738 501.3378   2.535792 #> 739 511.8409   3.328970 #> 740 524.5597   2.803458 #> 741 504.8921   2.563286 #> 742 500.0256   2.751902 #> 743 503.8190   3.165762 #> 744 656.0433   2.548575 #> 745 507.1809   2.973811 #> 746 500.1649   3.224932 #> 747 622.1152   2.885038 #> 748 501.0433   2.840154 #> 749 531.4058   3.621186 #> 750 666.2828   3.506248 #> 751 521.1034   4.221211 #> 752 500.2278   2.804183 #> 753 541.7039   2.516587 #> 754 500.1094   2.726304 #> 755 500.3149   2.895815 #> 756 631.6740   2.745141 #> 757 525.1878   2.507920 #> 758 528.4333   3.122694 #> 759 500.3483   4.707256 #> 760 500.0650   2.618239 #> 761 524.4358   2.715548 #> 762 500.0556   3.041346 #> 763 512.3772   2.622049 #> 764 540.8822   2.631229 #> 765 512.8048   3.629492 #> 766 573.5988   4.432379 #> 767 500.2199   2.504910 #> 768 501.3642   3.055788 #> 769 500.0283   2.633693 #> 770 557.0259   2.569707 #> 771 500.1374   2.836885 #> 772 608.1144   2.548778 #> 773 503.2165   3.106638 #> 774 500.4509   3.588692 #> 775 630.9791   2.572592 #> 776 500.1964   2.701700 #> 777 521.0582   2.614788 #> 778 568.1367   2.543613 #> 779 677.0612   2.678919 #> 780 500.1105   2.798338 #> 781 500.5645   2.710393 #> 782 524.9210   2.743681 #> 783 774.5150   2.643786 #> 784 500.5601   3.137519 #> 785 500.0240   2.985443 #> 786 503.9682   2.848009 #> 787 895.2767   2.676736 #> 788 500.0380   2.568381 #> 789 989.3625   3.106844 #> 790 556.4811   2.678475 #> 791 500.9085   3.741209 #> 792 500.6345   3.194345 #> 793 630.6082   2.533194 #> 794 508.6348   2.792179 #> 795 900.6378   2.814191 #> 796 572.1462   2.774215 #> 797 526.4586   2.603289 #> 798 500.7418   2.664173 #> 799 672.9711   2.782652 #> 800 533.0551   2.705955 #> 801 503.7143   3.371005 #> 802 632.0244   3.415164 #> 803 500.2990   3.440737 #> 804 501.5813   3.028573 #> 805 538.1505   3.033350 #> 806 582.9043   2.517886 #> 807 502.8931   2.898975 #> 808 779.1741   2.755867 #> 809 502.4202   2.890306 #> 810 504.9111   2.921254 #> 811 582.3552   2.575340 #> 812 500.0246   2.919924 #> 813 500.0405   2.566002 #> 814 506.7649   3.067070 #> 815 736.9907   2.586017 #> 816 634.7308   3.050938 #> 817 500.3797   3.041703 #> 818 579.3371   2.559583 #> 819 609.2400   2.504006 #> 820 605.5242   3.107318 #> 821 500.9991   2.784769 #> 822 500.0244   2.687066 #> 823 501.4745   2.637732 #> 824 501.0781   2.676805 #> 825 500.3599   2.931208 #> 826 501.4180   2.581096 #> 827 533.4579   2.918138 #> 828 500.9557   2.881234 #> 829 502.5939   2.884652 #> 830 502.1160   3.410603 #> 831 500.0067   2.975078 #> 832 510.3214   2.643155 #> 833 500.7136   3.627866 #> 834 743.4996   2.715359 #> 835 500.2154   3.308888 #> 836 500.0284   2.551464 #> 837 832.7441   2.838040 #> 838 511.6467   2.772953 #> 839 504.2109   3.042304 #> 840 500.0122   2.782495 #> 841 514.5742   2.776916 #> 842 508.5653   2.613346 #> 843 500.0706   3.042150 #> 844 500.4564   4.160332 #> 845 500.5232   2.563552 #> 846 923.3280   2.561336 #> 847 500.8079   4.527496 #> 848 508.4103   2.771826 #> 849 511.6998   2.584721 #> 850 500.6664   2.880297 #> 851 500.1509   2.576782 #> 852 502.7049   2.869281 #> 853 500.6524   2.865830 #> 854 500.3413   3.801164 #> 855 502.1860   2.521266 #> 856 502.4792   2.679289 #> 857 501.6984   2.890152"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_times.html","id":null,"dir":"Reference","previous_headings":"","what":"Sampling times for events triggered by a parent at th according to the ETAS triggering function — sample_temporal_ETAS_times","title":"Sampling times for events triggered by a parent at th according to the ETAS triggering function — sample_temporal_ETAS_times","text":"Sampling times events triggered parent th according ETAS triggering function","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_times.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sampling times for events triggered by a parent at th according to the ETAS triggering function — sample_temporal_ETAS_times","text":"","code":"sample_temporal_ETAS_times(theta, n.ev, th, T2)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_times.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sampling times for events triggered by a parent at th according to the ETAS triggering function — sample_temporal_ETAS_times","text":"theta ETAS parameters list(mu=mu, K=K, alpha=alpha, c=c, p=p). n.ev Number events return sample time domain (th, T2]. th Time parent event producing n.ev daughters. T2 End time model domain.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_ETAS_times.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Sampling times for events triggered by a parent at th according to the ETAS triggering function — sample_temporal_ETAS_times","text":"t.sample list times interval [0, T2] distributed according ETAS triggering function.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_injection_events.html","id":null,"dir":"Reference","previous_headings":"","what":"Title — sample_temporal_injection_events","title":"Title — sample_temporal_injection_events","text":"Title","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_injection_events.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Title — sample_temporal_injection_events","text":"","code":"sample_temporal_injection_events(   a = 50,   V.i = 1,   tau = 10,   beta.p,   M0,   T.i,   T2 )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_injection_events.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Title — sample_temporal_injection_events","text":"Induced event rate per unit volume. V.Injected volume tau Decay rate [days]. beta.p Related b-value via b ln(10). M0 Minimum magnitude threshold. T.Time injection [days]. T2 End temporal model domain [days].","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/sample_temporal_injection_events.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Title — sample_temporal_injection_events","text":"Catalogue parent events induced injection; data.frame(times, magnitudes)","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/time_grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Generate a set of time bins for a specific event. — time_grid","title":"Generate a set of time bins for a specific event. — time_grid","text":"Generate set time bins specific event.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/time_grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generate a set of time bins for a specific event. — time_grid","text":"","code":"time_grid(data.point, coef.t, delta.t, N.exp., T1., T2.)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/time_grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generate a set of time bins for a specific event. — time_grid","text":"data.point Point binning calculated, list elements time (ts, scalar), event index (idx.p, scalar). Names mandatory changed coef.t TimeBinning parameter: look breaks_exp() delta.t TimeBinning parameter: look breaks_exp() N.exp. TimeBinning parameter: look breaks_exp() T1. Start temporal domain, scalar T2. End temporal domain scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/time_grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Generate a set of time bins for a specific event. — time_grid","text":"data.frame many rows number bins fixed number columns. columns t.start : starting point bin (minimum = T1.). t.end : end point bin. (maximum = T2.). t.bin.name : unique bin identifier. t.ref_layer : bin identifier calculations ts : time provided data.point idx.p : identifier provided data.point bins T1. T2. containing T1.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/time_grid.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generate a set of time bins for a specific event. — time_grid","text":"","code":"## EXAMPLE 1 event <- list(ts = 0, idx.p = 1) time_grid(data.point = event, coef.t = 1, delta.t = 0.1, N.exp. = 8, T1. = 1, T2. = 20) #>   t.start t.end t.bin.name t.ref_layer ts idx.p #> 1     1.0   1.6    0.8-1.6   between-1  0     1 #> 2     1.6   3.2    1.6-3.2           6  0     1 #> 3     3.2   6.4    3.2-6.4           7  0     1 #> 4     6.4  12.8   6.4-12.8           8  0     1 #> 5    12.8  20.0    12.8-20      last-1  0     1"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to plot the ETAS triggering function corresponding to different posterior samples — triggering_fun_plot","title":"Function to plot the ETAS triggering function corresponding to different posterior samples — triggering_fun_plot","text":"Function plot ETAS triggering function corresponding different posterior samples","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to plot the ETAS triggering function corresponding to different posterior samples — triggering_fun_plot","text":"","code":"triggering_fun_plot(   input.list,   post.samp = NULL,   n.samp = 10,   magnitude = 4,   t.end = 1,   n.breaks = 100 )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to plot the ETAS triggering function corresponding to different posterior samples — triggering_fun_plot","text":"input.list structured input list least two elements: model.fit: bru object used sample posterior ETAS parameters link.functions: list functions convert ETAS parameters INLA scale ETAS scale post.samp data.frame containing posterior samples parameters. NULL, n.samp samples generated. n.samp different nrow(post.samp) n.samp rows uniformly sampled post.samp. Default NULL n.samp Number posterior samples, integer (default = 10). magnitude Magnitude event triggering function calculated, scalar (default = 4). t.end Upper bound x-axis, scalar (default = 1). n.breaks Number points 0 t.end calculate function, integer (default = 100)","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to plot the ETAS triggering function corresponding to different posterior samples — triggering_fun_plot","text":"ggplot object grey lines representing triggering function posterior sample. Black lines representing 0.025 0.975 quantiles function values calculated posterior sample. Horizontal red lines represents 0.025 0.975 quantiles sampled background rates.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot_prior.html","id":null,"dir":"Reference","previous_headings":"","what":"Function to plot the ETAS triggering function corresponding to different prior samples — triggering_fun_plot_prior","title":"Function to plot the ETAS triggering function corresponding to different prior samples — triggering_fun_plot_prior","text":"Function plot ETAS triggering function corresponding different prior samples","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot_prior.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Function to plot the ETAS triggering function corresponding to different prior samples — triggering_fun_plot_prior","text":"","code":"triggering_fun_plot_prior(   input.list,   magnitude = 4,   n.samp = 10,   t.end = 1,   n.breaks = 100 )"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot_prior.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Function to plot the ETAS triggering function corresponding to different prior samples — triggering_fun_plot_prior","text":"input.list structured input list least one element: link.functions: list functions convert ETAS parameters INLA scale ETAS scale magnitude Magnitude event triggering function calculated, scalar (default = 4). n.samp Number posterior samples, integer (default = 10). t.end Upper bound x-axis, scalar (default = 1). n.breaks Number points 0 t.end calculate function, integer (default = 100)","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/triggering_fun_plot_prior.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Function to plot the ETAS triggering function corresponding to different prior samples — triggering_fun_plot_prior","text":"ggplot object grey lines representing triggering function posterior sample. Black lines representing 0.025 0.975 quantiles function values calculated posterior sample. Horizontal red lines represents 0.025 0.975 quantiles sampled background rates.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/unif_t.html","id":null,"dir":"Reference","previous_headings":"","what":"Copula transformation from a standard Normal distribution to a Uniform distribution — unif_t","title":"Copula transformation from a standard Normal distribution to a Uniform distribution — unif_t","text":"Copula transformation standard Normal distribution Uniform distribution","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/unif_t.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Copula transformation from a standard Normal distribution to a Uniform distribution — unif_t","text":"","code":"unif_t(x, a, b)"},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/unif_t.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Copula transformation from a standard Normal distribution to a Uniform distribution — unif_t","text":"x values standard Normal distribution, vector. minimum value Uniform distribution, scalar. b maximum value Uniform distribution, scalar.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/reference/unif_t.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Copula transformation from a standard Normal distribution to a Uniform distribution — unif_t","text":"values Uniform distribution b, vector length x.","code":""},{"path":[]},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/news/index.html","id":"etasinlabru-development-version","dir":"Changelog","previous_headings":"","what":"ETAS.inlabru (development version)","title":"ETAS.inlabru (development version)","text":"Add format argument generate_temporal_ETAS_synthetic() simplify conversion data.frame.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/news/index.html","id":"etasinlabru-111","dir":"Changelog","previous_headings":"","what":"ETAS.inlabru 1.1.1","title":"ETAS.inlabru 1.1.1","text":"Cleaned R package structure Added vignettes package website Renamed functions avoid “.” non-S3-method function names. Temporal.ETAS.* functions retain “.”, now.","code":""},{"path":"https://edinburgh-seismicity-hub.github.io/ETAS.inlabru/news/index.html","id":"etasinlabru-101","dir":"Changelog","previous_headings":"","what":"ETAS.inlabru 1.0.1","title":"ETAS.inlabru 1.0.1","text":"Initial package version.","code":""}]
